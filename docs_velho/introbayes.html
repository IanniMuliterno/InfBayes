<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2 Introdução à Inferência Bayesiana | Fundamentos de Inferência Bayesiana</title>
  <meta name="description" content="Notas de aula de Infência Bayesiana" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="2 Introdução à Inferência Bayesiana | Fundamentos de Inferência Bayesiana" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Notas de aula de Infência Bayesiana" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2 Introdução à Inferência Bayesiana | Fundamentos de Inferência Bayesiana" />
  
  <meta name="twitter:description" content="Notas de aula de Infência Bayesiana" />
  

<meta name="author" content="Victor Fossaluza" />


<meta name="date" content="2020-08-11" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ProbSubj.html"/>
<link rel="next" href="ape.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>



<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Notas de Aula de Inferência Bayesiana</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="ProbSubj.html"><a href="ProbSubj.html"><i class="fa fa-check"></i><b>1</b> Probabilidade Subjetiva</a><ul>
<li class="chapter" data-level="1.1" data-path="ProbSubj.html"><a href="ProbSubj.html#definição-axiomática"><i class="fa fa-check"></i><b>1.1</b> Definição Axiomática</a></li>
<li class="chapter" data-level="1.2" data-path="ProbSubj.html"><a href="ProbSubj.html#interpretações-de-probabilidade"><i class="fa fa-check"></i><b>1.2</b> Interpretações de Probabilidade</a></li>
<li class="chapter" data-level="1.3" data-path="ProbSubj.html"><a href="ProbSubj.html#relação-de-crença-precsim"><i class="fa fa-check"></i><b>1.3</b> Relação de Crença <span class="math inline">\(\precsim\)</span></a></li>
<li class="chapter" data-level="1.4" data-path="ProbSubj.html"><a href="ProbSubj.html#suposições-sobre-precsim"><i class="fa fa-check"></i><b>1.4</b> Suposições sobre <span class="math inline">\(\precsim\)</span></a></li>
<li class="chapter" data-level="1.5" data-path="ProbSubj.html"><a href="ProbSubj.html#medida-de-probabilidade-que-representa-precsim"><i class="fa fa-check"></i><b>1.5</b> Medida de Probabilidade que “representa” <span class="math inline">\(\precsim\)</span></a></li>
<li class="chapter" data-level="1.6" data-path="ProbSubj.html"><a href="ProbSubj.html#medida-de-probabilidade-condicional"><i class="fa fa-check"></i><b>1.6</b> Medida de Probabilidade Condicional</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introbayes.html"><a href="introbayes.html"><i class="fa fa-check"></i><b>2</b> Introdução à Inferência Bayesiana</a><ul>
<li class="chapter" data-level="2.1" data-path="introbayes.html"><a href="introbayes.html#notação"><i class="fa fa-check"></i><b>2.1</b> Notação</a></li>
<li class="chapter" data-level="2.2" data-path="introbayes.html"><a href="introbayes.html#inferência-clássica-ou-frequentista"><i class="fa fa-check"></i><b>2.2</b> Inferência Clássica (ou Frequentista)</a></li>
<li class="chapter" data-level="2.3" data-path="introbayes.html"><a href="introbayes.html#inferência-bayesiana"><i class="fa fa-check"></i><b>2.3</b> Inferência Bayesiana</a></li>
<li class="chapter" data-level="2.4" data-path="introbayes.html"><a href="introbayes.html#distribuição-a-priori"><i class="fa fa-check"></i><b>2.4</b> Distribuição a Priori</a><ul>
<li class="chapter" data-level="2.4.1" data-path="introbayes.html"><a href="introbayes.html#prioris-baseada-na-opinião-de-um-especialista"><i class="fa fa-check"></i><b>2.4.1</b> Prioris Baseada na Opinião de um Especialista</a></li>
<li class="chapter" data-level="2.4.2" data-path="introbayes.html"><a href="introbayes.html#prioris-conjugadas"><i class="fa fa-check"></i><b>2.4.2</b> Prioris Conjugadas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ape.html"><a href="ape.html"><i class="fa fa-check"></i><b>3</b> Apendice: Breve Resumo de Medida e Probabilidade</a><ul>
<li class="chapter" data-level="3.1" data-path="ape.html"><a href="ape.html#breve-resumo-de-medida-e-probabilidade"><i class="fa fa-check"></i><b>3.1</b> Breve Resumo de Medida e Probabilidade</a></li>
<li class="chapter" data-level="3.2" data-path="ape.html"><a href="ape.html#valor-esperado-de-x-ou-uma-ideia-da-tal-integral-de-lebesgue"><i class="fa fa-check"></i><b>3.2</b> Valor Esperado de <span class="math inline">\(X\)</span> (OU uma ideia da tal Integral de Lebesgue)</a></li>
<li class="chapter" data-level="3.3" data-path="ape.html"><a href="ape.html#propriedades-da-integral-de-lebesque-de-x-v.a-em-relação-a-p"><i class="fa fa-check"></i><b>3.3</b> Propriedades da integral (<em>de Lebesque</em>) de <span class="math inline">\(X\)</span> (v.a) em relação a <span class="math inline">\(P\)</span></a></li>
<li class="chapter" data-level="3.4" data-path="ape.html"><a href="ape.html#funções-de-variáveis-aleatórias"><i class="fa fa-check"></i><b>3.4</b> Funções de Variáveis Aleatórias</a></li>
<li class="chapter" data-level="3.5" data-path="ape.html"><a href="ape.html#aula-6"><i class="fa fa-check"></i><b>3.5</b> Aula 6</a></li>
<li class="chapter" data-level="3.6" data-path="ape.html"><a href="ape.html#aula-7"><i class="fa fa-check"></i><b>3.6</b> Aula 7</a><ul>
<li class="chapter" data-level="3.6.1" data-path="ape.html"><a href="ape.html#probabilidade-condicional"><i class="fa fa-check"></i><b>3.6.1</b> Probabilidade Condicional</a></li>
<li class="chapter" data-level="3.6.2" data-path="ape.html"><a href="ape.html#teorema-da-medida-produto-para-medidas-de-probabilidade"><i class="fa fa-check"></i><b>3.6.2</b> Teorema da Medida Produto (para medidas de probabilidade)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Fundamentos de Inferência Bayesiana</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introbayes" class="section level1">
<h1><span class="header-section-number">2</span> Introdução à Inferência Bayesiana</h1>
<div id="notação" class="section level2">
<h2><span class="header-section-number">2.1</span> Notação</h2>
<ul>
<li><p><strong>Inferência Estatística:</strong> fazer afirmações sobre quantidades não observáveis em um determinado contexto.</p></li>
<li><p><span class="math inline">\(\theta\)</span> : <strong>parâmetro</strong> - quantidade desconhecida de interesse (não-observável em determinado contexto).</p></li>
<li><p><span class="math inline">\(\Theta\)</span> : <strong>espaço paramétrico</strong> - conjunto onde <span class="math inline">\(\theta\)</span> toma valores (supostamente conhecido).</p></li>
<li><p><span class="math inline">\(E=\left(\boldsymbol X, \theta, \left\{f(\boldsymbol x|\theta)\right\}\right)\)</span>: <strong>experimento</strong> - “<em>tornar visível algo que antes era invisível</em>” ou, mais especificamente no nosso contexto, observar uma realização <span class="math inline">\(\boldsymbol x \in \mathfrak{X}\)</span> de um vetor aleatório <span class="math inline">\(\boldsymbol X\)</span> com alguma distribuição <span class="math inline">\(f(\boldsymbol x|\theta)\)</span>. Essa distribuição pertence, na maioria dos casos, à uma família de distribuições fixada mas que depende do parâmetro desconhecido de interesse <span class="math inline">\(\theta\)</span>. Note que na grande maioria dos problemas do dia a dia de um estatístico ele se utiliza de resultados experimentais para fazer afirmações sobre <span class="math inline">\(\theta\)</span> e este, por sua vez, é não-observável em geral.</p></li>
<li><p><span class="math inline">\(\mathfrak{X}\)</span> : <strong>espaço amostral</strong> - conjunto onde <span class="math inline">\(\boldsymbol X\)</span> toma valores (supostamente conhecido).</p></li>
<li><p><span class="math inline">\(\mathcal{F}\)</span> : <span class="math inline">\(\sigma\)</span>-álgebra de (sub)conjuntos de <span class="math inline">\(\mathfrak{X}\)</span>.</p></li>
<li><p>Neste espaço amostral, defini-se uma família <span class="math inline">\(\mathcal{P}=\{P(\cdot|\theta): \theta \in \Theta\}\)</span>, isto é, um conjunto de distribuições (condicionais) para <span class="math inline">\(\boldsymbol X\)</span> indexadas por <span class="math inline">\(\theta\)</span>.</p></li>
<li><p><span class="math inline">\((\mathfrak{X},\mathcal{F},\mathcal{P})\)</span> : modelo estatístico (clássico).</p></li>
<li><p><span class="math inline">\(V_X(\theta)=f(\boldsymbol x |\theta)\)</span> : função de verossimilhança.</p></li>
</ul>
<p><span class="math inline">\(~\)</span></p>
</div>
<div id="inferência-clássica-ou-frequentista" class="section level2">
<h2><span class="header-section-number">2.2</span> Inferência Clássica (ou Frequentista)</h2>
<ul>
<li><p><span class="math inline">\(\theta\)</span> é considerado fixo (apesar de desconhecido) e, portanto, não recebe uma distribuição de probabilidade.</p></li>
<li><p>Baseia-se no " princípio" da amostragem repetida (interpretação frequentista de probabilidade), isto é, supõe que é possivel realizar infinitas vezes o experimento. Assim, o <span class="math inline">\(\boldsymbol x\)</span> é apenas um dos possiveis resultados (hipóteticos) do experimento.</p></li>
<li><p>Probabilidade somente é definida em (uma <span class="math inline">\(\sigma-álgebra\)</span> de) <span class="math inline">\(\mathfrak{X}\)</span>.</p></li>
</ul>
</div>
<div id="inferência-bayesiana" class="section level2">
<h2><span class="header-section-number">2.3</span> Inferência Bayesiana</h2>
<ul>
<li><p>Baseia-se na interpretação subjetivista de probabilidade, de modo que a <em>SUA</em> incerteza sobre algo desconhecido deve ser quantificada (traduzida) em termos de probabilidade.</p></li>
<li><p>Assim, Sua incerteza sobre o parâmetro (desconhecido) é representada por uma distribuição de probabilidade, <span class="math inline">\(\theta\)</span> é tratado como uma v.a. e <em>SUA</em> distribuição para <span class="math inline">\(\theta\)</span> antes da realização do experimento , <span class="math inline">\(f(\theta),\)</span> é chamada de <strong>distribuição a priori</strong>. Note que a atribuição de uma distribuição a prior para <span class="math inline">\(\theta\)</span> independe da natureza do parâmetro, ele pode ser a proporção de indivíduos que avalia positivamente o governo atual (quantidade essa que muda a todo instante) ou ainda a milésima casa do <span class="math inline">\(\pi\)</span> (algum número de 0 a 9, fixo porém desconhecido no momento dessa leitura).</p></li>
<li><p>A atualização de <em>SUA</em> incerteza sobre <span class="math inline">\(\theta,\)</span> incorporando uma nova informação trazida pelos dados <span class="math inline">\(\boldsymbol x\)</span> (representada por <span class="math inline">\(f(\boldsymbol x| \theta)\)</span>) é feita pelo <em>Teorema de Bayes</em>:</p></li>
<li><p><strong>Teorema de Bayes:</strong></p></li>
</ul>
<p><span class="math display">\[\underbrace{f(\theta| \boldsymbol x)}_{dist. posteriori}=\dfrac{f(\theta)f(\boldsymbol x|\theta)}{\displaystyle \int_{\Theta}f(\boldsymbol x|\theta)dP_\theta} \propto~ \underbrace{f(\theta)}_{priori}\overbrace{f(\boldsymbol x|\theta).}^{verossimilhança}\]</span></p>
<!-- $$\underbrace{f(\theta| \boldsymbol x)}_{dist. posteriori} = \dfrac{f(\boldsymbol{x}| \theta)}{\int_{\Theta}f(\boldsymbol x|\theta)dP_\theta} \propto f(\boldsymbol x|\theta).$$ -->
<ul>
<li>Toda a inferência sobre <span class="math inline">\(\theta\)</span> será baseada exclusivamente em <span class="math inline">\(f(\theta| \boldsymbol x)\)</span>, não sendo necessário considerar pontos amostrais que poderiam mas não foram observados (como é feito na inferência frequentista).</li>
</ul>
<p><span class="math inline">\(~\)</span></p>
<ul>
<li><strong>Observação:</strong> será utilizada a notação geral para integral (de Lebesgue): <span class="math display">\[\displaystyle \int_{\Theta}f(\boldsymbol x|\theta)dP_\theta
= \left\{ \begin{array}{ll} \displaystyle \int_{\Theta}f(\boldsymbol x|\theta) f(\theta) d\theta ~&amp;~ (caso~~contínuo)\\
\displaystyle \sum_{\Theta}f(\boldsymbol x|\theta) f(\theta) ~&amp;~ (caso~~discreto) \end{array}\right.\]</span></li>
</ul>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Exemplo 1.a:</strong> Suponha que existem duas moedas, uma delas tem <span class="math inline">\(\theta =1/2\)</span> (honesta) e a outra <span class="math inline">\(\theta=3/4\)</span> (viesada). Uma moeda é escolhida e é feito um lançamento da moeda selecionada. Nesse experimento, tem-se <span class="math inline">\(X|\theta \sim Ber(\theta)\)</span>, com <span class="math inline">\(\Theta=\{1/2,3/4\}\)</span> e <span class="math inline">\(\mathfrak{X}=\{0,1\}\)</span>. Como “chutar” o valor de <span class="math inline">\(\theta\)</span>?</p>
<p>Considere que não existe razão para você acreditar que há algum tipo de preferência na escolha de uma ou outra moeda, isto é, considere que a priori <span class="math inline">\(f(\theta=1/2)\)</span> <span class="math inline">\(=f(\theta=3/4)\)</span> <span class="math inline">\(=1/2\)</span>. Suponha que o lançamento resultou em cara (<span class="math inline">\(x=1\)</span>). Então</p>
<p><span class="math inline">\(f(\theta = 3/4|X=1)\)</span> <span class="math inline">\(=\dfrac{f(X=1|\theta=3/4)f(\theta=3/4)}{\sum_\theta f(X=1|\theta)f(\theta)}\)</span> <span class="math inline">\(=\dfrac{\dfrac{3}{4}\dfrac{1}{2}}{\dfrac{3}{4}~\dfrac{1}{2}+\dfrac{1}{2}~\dfrac{1}{2}}=\)</span> <span class="math inline">\(\dfrac{3/4}{5/4}=\dfrac{3}{5}\)</span> <span class="math inline">\(= 1-\underbrace{f(\theta=1/2|X=1)}_{2/5}\)</span></p>
<p>Se, no entando, o resultado do lançamento da moeda fosse coroa (<span class="math inline">\(x=0\)</span>), teríamos</p>
<p><span class="math inline">\(P(\theta=3/4|X=0)\)</span> <span class="math inline">\(=\dfrac{\dfrac{1}{4}~\dfrac{1}{2}}{\dfrac{1}{4}~\dfrac{1}{2}+\dfrac{1}{2}~\dfrac{1}{2}}\)</span> <span class="math inline">\(=\dfrac{1/2}{1/2+2/2}=\dfrac{1}{3}\)</span></p>
<p><img src="InfBayes_files/figure-html/unnamed-chunk-3-1.gif" width="70%" style="display: block; margin: auto;" />
Assim, se sua decisão for escolher o valor mais provável de <span class="math inline">\(\theta\)</span> após observar <span class="math inline">\(x\)</span>, a conclusão seria que a moeda é viesada <span class="math inline">\((\theta=3/4)\)</span> se for observado cara <span class="math inline">\((x=1)\)</span> e que a moeda é honesta <span class="math inline">\((\theta=1/2)\)</span> se o resultado for coroa <span class="math inline">\((x=0)\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Exemplo 1.b:</strong> Considere agora que serão realizados <span class="math inline">\(n\)</span> lançamentos da moeda, de modo que agora tem-se <span class="math inline">\(X|\theta \sim Bin(n,\theta)\)</span>, <span class="math inline">\(\theta \in \{1/2,3/4\}\)</span>, <span class="math inline">\(x \in \{0,1,\ldots,n\}\)</span>. Suponha que observa-se <span class="math inline">\(X=x\)</span>.</p>
<p><span class="math inline">\(f(\theta=3/4|X=x)\)</span> <span class="math inline">\(=\dfrac{f(x|\theta=3/4)f(\theta=3/4)}{\displaystyle \sum_{\theta\in \{1/2,3/4\}}f(x|\theta)f(\theta)}\)</span> <span class="math inline">\(=\dfrac{\displaystyle \binom{n}{x}\left(\dfrac{3}{4}\right)^x\left(\dfrac{1}{4}\right)^{n-x}\dfrac{1}{2}}{\displaystyle \binom{n}{x}\left(\dfrac{3}{4}\right)^x\left(\dfrac{1}{4}\right)^{n-x}\dfrac{1}{2}+\displaystyle\binom{n}{x}\left(\dfrac{1}{2}\right)^x\left(\dfrac{1}{2}\right)^{n-x}\dfrac{1}{2}}\)</span> <span class="math inline">\(=\dfrac{1}{1+\left(\dfrac{2^n}{3^x}\right)}\)</span> <span class="math inline">\(=\dfrac{3^x}{3^x + 2^n}\)</span>.</p>
<p><img src="InfBayes_files/figure-html/unnamed-chunk-5-1.gif" width="70%" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(~\)</span></p>
<p>Note que o Exemplo 1.a é um caso particular desse exemplo quando <span class="math inline">\(n=1\)</span>. Se novamente sua decisão é baseada no valor mais provável de <span class="math inline">\(\theta\)</span>, temos</p>
<p><span class="math inline">\(f(\theta=3/4|X=x) &gt; \dfrac{1}{2}\)</span> <span class="math inline">\(\Longleftrightarrow \dfrac{3^x}{3^x + 2^n} &gt; \dfrac{1}{2}\)</span> <span class="math inline">\(\Longleftrightarrow {3^x} &gt; {2^n}\)</span> <span class="math inline">\(\Longleftrightarrow \dfrac{x}{n} = \bar{x} &gt; \log_3{2}\approx 0,63\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Exemplo 1.c:</strong> Considere uma moeda será lançada <span class="math inline">\(n\)</span> vezes mas que <span class="math inline">\(\theta\)</span> é desconhecido, de modo que <span class="math inline">\(\Theta = [0,1]\)</span>. Para simplificar, vamos assumir <span class="math inline">\(f(\theta)=\mathbb{I}_{[0,1]}(\theta)\)</span>, isto é, <span class="math inline">\(\theta \sim Unif(0,1)\sim Beta(1,1)\)</span>. Essa priori corresponde ao caso onde você acredita que todos os valores possíveis para <span class="math inline">\(\theta\)</span> são igualmente “prováveis”, assim como nos exemplos anteriores. Novamente, <span class="math inline">\(X|\theta \sim Bin(n,\theta)\)</span></p>
<p><span class="math inline">\(f(\theta|x)=\)</span> <span class="math inline">\(\dfrac{f(x|\theta)f(\theta)}{\int_0^1 f(x|\theta)f(\theta)d\theta}=\)</span> <span class="math inline">\(\dfrac{\binom{n}{x}\theta^x(1-\theta)^{n-x} ~~\mathbb{I}_{[0,1]}(\theta)}{\int_0^1\binom{n}{x}\theta^x(1-\theta)^{n-x}d\theta}=\)</span> <span class="math inline">\(\dfrac{\dfrac{\Gamma(1+x+1+n-x)}{\Gamma(1+x)\Gamma(1+n-x)}~~\theta^x(1-\theta)^{n-x}~~\mathbb{I}_{[0,1]}(\theta)}{\underbrace{\displaystyle \int_0^1\dfrac{\Gamma(1+x+1+n-x)}{\Gamma(1+x)\Gamma(1+n-x)}~~\theta^x(1-\theta)^{n-x}d\theta}_{1}}\)</span> <span class="math inline">\(=\dfrac{\Gamma(1+x+1+n-x)}{\Gamma(1+x)\Gamma(1+n-x)}~~\theta^x(1-\theta)^{n-x}~~\mathbb{I}_{[0,1]}(\theta)\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p>Logo <span class="math inline">\(\theta|x \sim Beta(1+x,1+n-x)\)</span>. Nesse exemplo, o valor “mais provável” (com maior densidade a posteriori) para <span class="math inline">\(\theta\)</span> é a moda da distribuição, <span class="math inline">\(Moda(\theta|x)\)</span> <span class="math inline">\(= \dfrac{(1+x)-1}{(1+x)+(1+n-x)-2}\)</span> <span class="math inline">\(= \dfrac{x}{n}\)</span> <span class="math inline">\(=\bar{x}\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Exemplo 1.d</strong> Por fim, suponha que no exemplo anterior, sua opinião a priori é representada por uma distribuição beta qualquer com parâmetros <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span>, <span class="math inline">\(a,b &gt; 0\)</span>. Desta forma, <span class="math inline">\(X|\theta \sim Bin(n,\theta)\)</span> e <span class="math inline">\(\theta\sim Beta(a,b)\)</span>. Calculando a distribuição a posteriori de forma similar ao exemplo anterior, temos que <span class="math inline">\(\theta|X=x \sim Beta(a+x,b+n-x)\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p><img src="InfBayes_files/figure-html/unnamed-chunk-7-1.gif" width="70%" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(~\)</span></p>
<p>Suponha que <span class="math inline">\(a=b=1\)</span> (como no exemplo anterior), <span class="math inline">\(n=5\)</span> e <span class="math inline">\(x=2\)</span>, de modo que <span class="math inline">\(\theta|x=2 \sim Beta(3,4)\)</span>. Algumas medidas resumo da distribuição posterior para esse exemplo são</p>
<ul>
<li><p><span class="math inline">\(Moda(\theta|x)\)</span> <span class="math inline">\(=\dfrac{a+x-1}{a+b+n-2}\)</span> <span class="math inline">\(=\dfrac{2}{5}\)</span> <span class="math inline">\(=0,4\)</span>;</p></li>
<li><p><span class="math inline">\(E[\theta|x]\)</span> <span class="math inline">\(=\dfrac{a+x}{a+b+n}\)</span> <span class="math inline">\(=\dfrac{3}{7}\)</span> <span class="math inline">\(=0,43\)</span>;</p></li>
<li><p><span class="math inline">\(Med(\theta|x)\)</span> <span class="math inline">\(\approx \dfrac{a+x-1/3}{a+b+n-2/3}\)</span> <span class="math inline">\(=\dfrac{8/3}{19/3}\)</span> <span class="math inline">\(\approx 0,42\)</span>;</p></li>
<li><p><span class="math inline">\(Var(\theta|x)\)</span> <span class="math inline">\(=\dfrac{(a+x)(b+n-x)}{(a+b+n)^2(a+b+n+1)}\)</span> <span class="math inline">\(=\dfrac{12}{392}\)</span> <span class="math inline">\(\approx 0,031\)</span>.</p></li>
</ul>
<p><span class="math inline">\(~\)</span></p>
<!-- ## Aula 09  -->
</div>
<div id="distribuição-a-priori" class="section level2">
<h2><span class="header-section-number">2.4</span> Distribuição a Priori</h2>
<ul>
<li>A priori é sempre subjetiva (assim como a escolha do modelo estatístico)!
<ul>
<li>Por exemplo, dizer que os dados seguem uma distribuição normal, é uma escolha subjetiva, muitas vezes baeadas nas facilidades mathemáticas que essa distribuição proporciona.<br />
</li>
<li>Do mesmo modo, suponha que dois indivíduos que consideram que a distribuição do parêmetro é simétrica, com mesmas suposições sobre média e variância. O primeiro pode optar por representar sua distribuição usando uma distribuição Normal, enquanto o segundo pode utilizar uma distribuição T ou Cauchy.<br />
</li>
</ul></li>
<li>Não existe “opinião errada”, existem opiniões diferentes, dado o nível de conhecimento e as experiências prévias do indivíduo.<br />
</li>
<li>A priori deve ser sua opinião apenas sobre o parâmetro <span class="math inline">\(\theta\)</span> e não deve depender de fatores como o desenho do experimento ou o objetivo do estudo.</li>
</ul>
<div id="prioris-baseada-na-opinião-de-um-especialista" class="section level3">
<h3><span class="header-section-number">2.4.1</span> Prioris Baseada na Opinião de um Especialista</h3>
<div id="método-do-histograma" class="section level4">
<h4><span class="header-section-number">2.4.1.1</span> Método do Histograma</h4>
<ul>
<li><p>Muitas vezes, para “extrair” o conhecimento de um especialista, podemos dividir o espaço paramétrico em regiões e pedir para o especialista “ordenar” esses conjuntos, utilizando “pesos” que refletem a crença que o parâmetro esteja em cada uma daquelas regiões.</p></li>
<li><p><strong>Exemplo 1.</strong> (<em>Bayesian Computation with R</em>, Albert,J., pág 27)</p>
<ul>
<li>Seja <span class="math inline">\(\theta\)</span> uma proporção desconhecida <span class="math inline">\((\Theta=[0,1])\)</span>;<br />
</li>
<li>Considere a partição <span class="math inline">\(T = \left\{[0,0.1), [0.1,0.2), \ldots, [0.9,1] \right\}\)</span>;</li>
<li>Suponha que um especialistas atribui pesos <span class="math inline">\(p=(1, 5.2, 8, 7.2, 4.6, 2.1, 0.7, 0.1, 0, 0)\)</span> a esse intervalos;<br />
</li>
<li>A piori, nesse caso, é o histograma apresentado a seguir.</li>
</ul></li>
</ul>
<p><img src="InfBayes_files/figure-html/unnamed-chunk-8-1.png" width="70%" style="display: block; margin: auto;" /></p>
<ul>
<li>Voltando ao exemplo da moeda, suponha novamente que foram observados <span class="math inline">\(x=2\)</span> sucessos em <span class="math inline">\(n=5\)</span> lançamentos. A posteriori nesse caso pode ser obtida multiplicando a distribuição a priori pela verossimilhança e “padronizando” a função obtida. Assim:</li>
</ul>
<p><img src="InfBayes_files/figure-html/unnamed-chunk-9-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(~\)</span></p>
</div>
<div id="elicitação-de-hiperparâmetros" class="section level4">
<h4><span class="header-section-number">2.4.1.2</span> Elicitação de Hiperparâmetros</h4>
<ul>
<li>Nessa abordagem, a priori é obtida da seguinte maneira:
<ol style="list-style-type: decimal">
<li>Escolha uma família de distribuições conveniente. O conceito de “conveniência” aqui pode levar em conta, por exemplo, o suporte da distribuição, se é flexível o suficiente para acomodar diversos tipos de opinião, se permite a obtenção analítica da posteriori e assim por diante;<br />
</li>
<li>Obtenha um conjunto de medidas resumo (como média, variância, quantis, etc.);<br />
</li>
<li>Utilize as medidas resumo para calcular hiperparâmetros da distribuição escolhida.</li>
</ol></li>
</ul>
<p><span class="math inline">\(~\)</span></p>
<ul>
<li><p><strong>Exemplo:</strong> Na seção anterior, a priori dada pelo histograma tem média <span class="math inline">\(m=0.31\)</span> e variância aproximadamente <span class="math inline">\(v=0.02\)</span>. Podemos utilizar como priori, por exemplo, uma distribuiçaõ beta com essa média e variância, já que a beta tem um suporte conveniente e facilita as contas, como também já vimos. Assim, vamos considerar uma distribuição <span class="math inline">\(Beta(a,b)\)</span> e escolher <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span> satisfazendo:</p>
<ol style="list-style-type: lower-roman">
<li><span class="math inline">\(E[\theta]\)</span> <span class="math inline">\(=\dfrac{a}{a+b}\)</span> <span class="math inline">\(=m\)</span> <span class="math inline">\(\Longleftrightarrow b=\left(\dfrac{1-m}{m}\right)a\)</span></li>
<li><span class="math inline">\(Var(\theta)\)</span> <span class="math inline">\(=\dfrac{ab}{(a+b)^2(a+b+1)}\)</span> <span class="math inline">\(=0.02\)</span> <span class="math inline">\(\Longleftrightarrow a=\dfrac{m(m-m^2-v)}{v}\)</span></li>
</ol></li>
</ul>
<p>Resolvendo o sistema temos, de forma geral, que <span class="math inline">\(a=\dfrac{m(m-m^2-v)}{v}\)</span> e <span class="math inline">\(b=\dfrac{(1-m)(m-m^2-v)}{v}\)</span>.</p>
<p>Assim, no nosso exemplo, teríamos uma <span class="math inline">\(Beta(3,6.7)\)</span>. Além disso, já vimos que, nesse caso, a distribuição a posteriori é <span class="math inline">\(Beta(3+x,6.7+n-x)\)</span>. Considerando novamente <span class="math inline">\(n=5\)</span> e <span class="math inline">\(x=2\)</span>, temos:</p>
<p><img src="InfBayes_files/figure-html/unnamed-chunk-10-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(~\)</span></p>
</div>
</div>
<div id="prioris-conjugadas" class="section level3">
<h3><span class="header-section-number">2.4.2</span> Prioris Conjugadas</h3>
<p>Como visto no exemplo da moeda, quando distribuição a priori era <span class="math inline">\(Beta(a,b)\)</span>, a posteriori era facilmente obtida e também estava na classe das distribuições <span class="math inline">\(Beta\)</span>. Em particular, quando observa-se <span class="math inline">\(x\)</span> sucessos em <span class="math inline">\(n\)</span> realizações de ensaios de Bernoulli, a distribuição a posteriori é <span class="math inline">\(Beta(a+x,b+n-x)\)</span>. Isso ocorre pois essa distribuição pertence à uma classe bastante espefícica de distribuições a priori, chamadas distribuições conjugadas.</p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Definição</strong> Seja <span class="math inline">\(\mathcal{P}=\{f(x|\theta):\;\theta \in \Theta\}\)</span> uma família de distribuições (condicionais) para <span class="math inline">\(\boldsymbol{X}\)</span> e considere <span class="math inline">\(\mathcal{C}=\{h(\theta|a):\;a\in A\}\)</span> uma família de distribuições para <span class="math inline">\(\theta\)</span>. Dizemos que (a família) <span class="math inline">\(\mathcal{C}\)</span> é <strong>conjugada</strong> para <span class="math inline">\(\mathcal{P}\)</span> se, <span class="math inline">\(\forall \;h(\theta)\in \mathcal{C},\)</span> <span class="math inline">\(h(\theta|\boldsymbol{x})\propto f(\boldsymbol x|\theta)h(\theta) \in \mathcal{C},\forall \boldsymbol x \in \mathfrak{X}.\)</span></p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Resultado 1.</strong> Seja <span class="math inline">\(X\)</span> v.a. tal que, condicional ao conhecimento de <span class="math inline">\(\theta,\)</span> <span class="math inline">\(X|\theta \sim Bin(n,\theta).\)</span> Considere que, a priori, <span class="math inline">\(\theta \sim Beta(a,b).\)</span> Então, <span class="math inline">\(\theta|X=x \sim Beta(a+x,b+n-x).\)</span> Por tanto, a família <span class="math inline">\(\mathcal{C}=\{Beta(a_1,a_2):\;(a_1,a_2)\in \mathbb{R}^2_+\}\)</span> é conjugada para <span class="math inline">\(\mathcal{P}=\{Bin(n,\theta):\;\theta \in [0,1]\}.\)</span></p>
<p><span class="math inline">\(~\)</span></p>
<ul>
<li>Esse resultado também vale se
<ol style="list-style-type: decimal">
<li><span class="math inline">\(X_1,...,X_n\)</span> são v.a.s <em>condicionalmente independentes e identicamente distribuidas</em> (c.i.i.d.) com <span class="math inline">\(X_i|\theta \sim Ber(\theta)\)</span><br />
</li>
<li><span class="math inline">\(X_i|\theta\sim Geo(\theta),\)</span> <span class="math inline">\(i=1,...,n \; c.i.i.d.\)</span><br />
</li>
<li><span class="math inline">\(X_i|\theta \sim BinNeg(k,\theta)\)</span><br />
<span class="math inline">\(\theta\sim Beta(a,b)\Rightarrow\)</span> <span class="math inline">\(\theta|\boldsymbol X=\boldsymbol x \sim Beta(a+s,b+f)\)</span> onde <span class="math inline">\(s\)</span> é o número de sucessos e <span class="math inline">\(f\)</span> é o número de fracassos.</li>
</ol></li>
</ul>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Resultado 2.</strong> (<em>generalização do resultado anterior para o caso onde o número de categorias é maior que 2</em>)</p>
<p>Seja <span class="math inline">\(\boldsymbol X | \boldsymbol \theta \sim Multinomial(n,\boldsymbol \theta)\)</span>, isto é, sua função de probabilidade é dada por</p>
<p><span class="math display">\[f(\boldsymbol x| \boldsymbol \theta)= \binom{n}{x_1,x_2,...,x_k}~\prod_{i=1}^{k-1}\theta^i~\underbrace{\left(1-\sum_{i=1}^{k-1}\theta_i\right)^{\displaystyle n-\sum_{i=1}^{k-1}x_i}}_{\displaystyle \theta_k^{~~x_k}}\]</span></p>
<p>onde <span class="math inline">\(\theta_i\in [0,1]\)</span> com <span class="math inline">\(\sum_{i=1}^K\theta_i=1\)</span>, <span class="math inline">\(x_i \in \{0,1,...,n\}\)</span> com <span class="math inline">\(\sum_{i=1}^nx_i=n\)</span> e <span class="math inline">\(\displaystyle \binom{n}{x_1,x_2,...,x_k}=\dfrac{n!}{x_1!x_2!...x_k!}\)</span>.</p>
<p>Considere que, a priori, <span class="math inline">\(\boldsymbol \theta \sim Dirichlet(a_1,...,a_k),\)</span> <span class="math inline">\(a_i &gt; 0, i=1,...,k\)</span>, isto é, a f.d.p. a priori para <span class="math inline">\(\boldsymbol \theta\)</span> é dada por</p>
<p><span class="math display">\[f(\boldsymbol \theta) = \dfrac{\Gamma(\sum_{i=1}^K a_i)}{\Gamma(a_1)\Gamma(a_2)...\Gamma(a_k)}\prod_{i=1}^{k-1}\theta_i^{a_i-1}\bigg(\underbrace{1-\sum_{i=1}^{k-1}\theta_i}_{\theta_k}\bigg)^{a_k-1}.\]</span></p>
<p>Então, a distribuição a posteriori para <span class="math inline">\(\boldsymbol \theta\)</span> é
<span class="math inline">\(\boldsymbol \theta|\boldsymbol X = \boldsymbol x \sim Dirichlet (a_1+x_1,...,a_k+x_k)\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<blockquote>
<p><strong>Demo:</strong> Para verificar o resultado, basta ver que<br />
<span class="math inline">\(f(\boldsymbol\theta|\boldsymbol x)\)</span> <span class="math inline">\(=\dfrac{f(\boldsymbol x| \boldsymbol \theta)f(\boldsymbol \theta)}{\int_\Theta f(\boldsymbol x| \boldsymbol \theta)f(\boldsymbol \theta)d\boldsymbol \theta}\)</span> <span class="math inline">\(\propto f(\boldsymbol x| \boldsymbol \theta)f(\boldsymbol \theta)\)</span> <span class="math inline">\(\propto \prod_{i=1}^{k-1}\theta_i^{(a_i+x_i-1)}\left(1-\sum_{i=1}^{k-1}\theta_i\right)^{(a_k+x_k)-1}\)</span></p>
</blockquote>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Resultado 3.</strong> seja <span class="math inline">\(X_1,...,X_n\)</span> v.a. c.i.i.d tais que <span class="math inline">\(X_i|\theta \sim Unif(0,\theta)\)</span> e considere que, a priori,<span class="math inline">\(\theta \sim Pareto(a,b)\)</span>. Então <span class="math inline">\(\theta|\boldsymbol X = \boldsymbol x \sim Pareto\left(a+n,max\{b,x_{(n)}\}\right)\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<blockquote>
<p><strong>Demo:</strong><br />
<span class="math inline">\(f(\boldsymbol x|\theta)\)</span> <span class="math inline">\(\overset{ci}{=}\prod_{i=1}^nf(x_i|\theta)\)</span> <span class="math inline">\(\overset{id}{=}\prod_{i=1}^n\dfrac{1}{\theta}\mathbb{I}_{[0,\theta]}(x_i)\)</span> <span class="math inline">\(=\dfrac{1}{\theta^n}\mathbb{I}_{[0,\theta]}(x_{(n)})\)</span> <span class="math inline">\(=\dfrac{1}{\theta^n}\mathbb{I}_{[x_{(n)},+\infty)}(\theta)\)</span><br />
onde <span class="math inline">\(x_{(n)}=max\{x_1,...,x_n\}\)</span>.<br />
<span class="math inline">\(~\)</span><br />
<span class="math inline">\(f(\theta)=\dfrac{ab^a}{\theta^{a+1}}\mathbb{I}_{[b,+\infty]}(\theta)\)</span>.<br />
Então<br />
<span class="math inline">\(f(\theta| \boldsymbol x)\)</span> <span class="math inline">\(\propto f(\boldsymbol x|\theta)f(\theta)\)</span> <span class="math inline">\(=\dfrac{1}{\theta^{a+n+1}}\mathbb{I}_{[x_{(n)},+\infty)}(\theta)\mathbb{I}_{[b,+\infty)}(\theta)\)</span> <span class="math inline">\(=\dfrac{1}{\theta^{a+n+1}}\mathbb{I}_{[max\{b,x_{(n)}\},+\infty)}(\theta)\)</span><br />
<span class="math inline">\(~\)</span>
<span class="math inline">\(\Rightarrow \theta|\boldsymbol X = \boldsymbol x \sim Pareto(a+n,max\{b,x_{(n)}\})\)</span>.</p>
</blockquote>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Resultado 4.</strong> Seja <span class="math inline">\(X_1,...,X_n,Y_1,...,Y_m\)</span> v.a. condicionalmente independentes tais que <span class="math inline">\(X_i|\theta\sim Exp(\theta),i=1,...,n\)</span> e <span class="math inline">\(Y_j|\theta \sim Poisson(\theta),j=1,...,m\)</span>. Considere que, a priori, <span class="math inline">\(\theta \sim Gama(a,b)\)</span>. Então <span class="math inline">\(\theta| \boldsymbol x,\boldsymbol y \sim Gama(a+n+\sum_jy_j~,~b+m+\sum_ix_i)\)</span>.</p>
<blockquote>
<p><strong>Demo:</strong><br />
<span class="math inline">\(f(\boldsymbol x, \boldsymbol y|\theta)\overset{ci}{=}f(\boldsymbol x|\theta)f(\boldsymbol y|\theta)\overset{ci}{=}\)</span> <span class="math inline">\(\prod_{i=1}^nf(x_i|\theta)\prod_{j=1}^mf(y_i|\theta)=\)</span> <span class="math inline">\(\prod_{i=1}^n\theta e^{-\theta x_i}\prod_{j=1}^m\dfrac{\theta^{y_j}e^{-\theta}}{y_j!}=\)</span> <span class="math inline">\(\dfrac{1}{\prod_{j=1}^my_j!}\theta^{n+\sum_j y_j}e^{-(m+\sum_ix_i)\theta}\)</span><br />
<span class="math inline">\(~\)</span><br />
<span class="math inline">\(f(\theta)=\dfrac{b^a}{\Gamma(a)}\theta^{a-1}e^{-b\theta}\)</span>
<span class="math inline">\(~\)</span><br />
<span class="math inline">\(f(\theta| \boldsymbol{x,y})\propto f(\boldsymbol x, \boldsymbol y|\theta)f(\theta)\propto\)</span> <span class="math inline">\(\theta^{[a+n+\sum_jy_j]-1}e^{-[b+m+\sum_ix_i]\theta}\)</span>
<span class="math inline">\(~\)</span><br />
<span class="math inline">\(\Rightarrow \theta| \boldsymbol x,\boldsymbol y \sim Gama(a+n+\sum_jy_j,b+m+\sum_ix_i)\)</span></p>
</blockquote>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Resultado 5.</strong> Seja <span class="math inline">\(~\mathcal{P}=\{f(\boldsymbol x|\theta):\; \theta \in \Theta\}~\)</span> e <span class="math inline">\(~\mathcal{C}=\{h(\theta|a):\;a\in A\}~\)</span> uma <em>família conjugada</em> para <span class="math inline">\(\mathcal{P}\)</span>. Considere <span class="math inline">\(\mathcal{M}=\{h(\theta)=\sum_{i=1}^mw_ih_i(\theta):\)</span> <span class="math inline">\(h_i \in \mathcal{C} \; e \; w_i&gt;0,\; \sum_{i=1}^m w_i=1\}\)</span>. Então <span class="math inline">\(\mathcal{M}\)</span> é <em>família conjugada</em> para <span class="math inline">\(\mathcal{P}\)</span>.</p>
<blockquote>
<p><strong>Demo:</strong> Como <span class="math inline">\(\mathcal{C}\)</span> é conjugada para <span class="math inline">\(\mathcal{P}\)</span>, para toda função <span class="math inline">\(h_i \in \mathcal{C}\)</span>, temos que <span class="math inline">\(f_i(\theta|\boldsymbol x)\propto h_i(\theta)f(\boldsymbol x|\theta)\in \mathcal{C}\)</span>. Então<br />
<span class="math inline">\(~\)</span><br />
<span class="math inline">\(h\in \mathcal{M}\)</span> <span class="math inline">\(~\Rightarrow~ f(\theta|\boldsymbol x)\)</span> <span class="math inline">\(~\propto~ h(\theta)f(\boldsymbol x|\theta)\)</span> <span class="math inline">\(~\propto~\sum_{i=1}^m w_i\underbrace{h_i(\theta)f(\boldsymbol x|\theta)}_{\in \mathcal{C}}\)</span> <span class="math inline">\(~\propto~\sum_{i=1}^m w_i^*f_i(\theta|\boldsymbol x)\in \mathcal{M}\)</span>.</p>
</blockquote>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Exemplo.</strong> Seja <span class="math inline">\(X|\theta \sim Bin(n,\theta)\)</span> e <span class="math inline">\(f(\theta)\)</span> <span class="math inline">\(=wf_1(\theta)+(1-w)f_2(\theta)\)</span>, onde <span class="math inline">\(f_1\sim Beta(a_1,b_1)\)</span> e <span class="math inline">\(f_2\sim Beta(a_2,b_2)\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p><span class="math inline">\(f(\theta|x)\)</span> <span class="math inline">\(=\dfrac{f(x|\theta)f(\theta)}{\int_0^1f(x|\theta)f(\theta)}\)</span> <span class="math inline">\(=\dfrac{f(x|\theta)[wf_1(\theta)+(1-w)f_2(\theta)]}{w\int_0^1f_1(\theta)f(x|\theta)d\theta+(1-w)\int_0^1f_2(\theta)d\theta}\)</span></p>
<p><span class="math inline">\(\propto\dfrac{w\binom{n}{x}\frac{\Gamma(a_1+b_1)}{\Gamma(a_1)\Gamma(b_1)}\theta^{a_1+x-1}(1-\theta)^{b_1+n-x-1}+(1-w)\binom{n}{x}\frac{\Gamma(a_2+b_2)}{\Gamma(a_2)\Gamma(b_2)}\theta^{a_2+x-1}(1-\theta)^{b_2+n-x-1}}{\underbrace{w\binom{n}{x}\frac{\Gamma(a_1+b_1)}{\Gamma(a_1)\Gamma(b_1)}\frac{\Gamma(a_1+x)\Gamma(b_1+n-x)}{\Gamma(a_1+b_1+n)}}_{A}+\underbrace{(1-w)\binom{n}{x}\frac{\Gamma(a_2+b_2)}{\Gamma(a_2)\Gamma(b_2)}\frac{\Gamma(a_2+x)\Gamma(b_2+n-x)}{\Gamma(a_2+b_2+n)}}_{B}}\)</span></p>
<p><span class="math inline">\(\propto~\underbrace{\dfrac{A}{A+B}}_{w^*}Beta(a_1+x,b_1+n-x)+\underbrace{\dfrac{B}{A+B}}_{1-w^*}Beta(a_2+x,b_2+n-x)\)</span></p>
<p><span class="math inline">\(~\)</span></p>
<p>Primeiramente, suponha que <span class="math inline">\(n=5\)</span>, e temos uma mistura das distribuições <span class="math inline">\(Beta(5,12)\)</span> e <span class="math inline">\(Beta(10,3)\)</span>, com <span class="math inline">\(w=0.5\)</span>. O gráfico a seguir apresenta as distribuições a priori, a verossimilhança e a posteriori para cada possível valor de <span class="math inline">\(x\)</span> em <span class="math inline">\(\left\{0,1,\ldots,5\right\}\)</span>.</p>
<p><img src="InfBayes_files/figure-html/unnamed-chunk-12-1.gif" width="70%" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(~\)</span></p>
<p>Agora, suponha que <span class="math inline">\(n=5\)</span> e foi observado <span class="math inline">\(x=2\)</span>. Novamente, considere a mistura das distribuições <span class="math inline">\(Beta(5,12)\)</span> e <span class="math inline">\(Beta(10,3)\)</span> mas agora com pesos <span class="math inline">\(w\)</span> variando no conjunto <span class="math inline">\(\left\{0,0.1,\ldots,0.9,1\right\}\)</span>.</p>
<p><img src="InfBayes_files/figure-html/unnamed-chunk-14-1.gif" width="70%" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(~\)</span></p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ProbSubj.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ape.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["InfBayes.pdf", "InfBayes.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
