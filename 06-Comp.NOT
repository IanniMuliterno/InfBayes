# Métodos Computacionais {#Comp}

Como visto, a inferência Bayesiana é baseada na aplicação monótona do teorema de Bayes

$f(\theta|\boldsymbol x)=\dfrac{f(\boldsymbol x|\theta)f(\theta)}{\displaystyle\int_\Theta f(\boldsymbol x|\theta)f(\theta)d\theta}$ $= c(\boldsymbol x) f(\boldsymbol x|\theta)f(\theta)$ $\propto f(\boldsymbol x|\theta)f(\theta)$,

e na obtenção de medidas resumo dessa distribuição, como $E[\theta|\boldsymbol x]$, regiões HPD ou probabilidades a posteriori.

A maior dificuldade na aplicação de Inferência Bayesiana está justamente no cálculo das integrais envolvidas, tanto no cálculo de $f(\boldsymbol x)$ para a obtenção da posteriori, quanto na obtenção das medidas resumos citadas anteriormente. Devido a isso, a inferência bayesiana ganhou muito força com o avanço computacional das últimas décadas. A seguir, serão apresentados um breve resumo de alguns recursos que podem ser utilizados na prática Bayesiana.

Muitos dos métodos descritos baseiam-se na *Lei dos Grande Números* (LGN) e são uma bela aplicação de ideias frequentistas em um cenário controlado onde as suposições de *i.i.d.* são satisfeitas.

$~$

**Lei $\overset{\textbf{(Fraca)}}{\textbf{Forte}}$ dos Grande Números.** Seja $X_1,X_2...$ uma sequência de v.a. i.i.d com $E[X_1]=\mu$ e $Var[X_1]=\sigma^2<\infty$, então 

$\dfrac{1}{n}\displaystyle \sum_{i=1}^n X_i ~~\underset{q.c.}{\overset{(P)}{\longrightarrow}}~~ E[X_i]=\mu$.

$~$

As integrais de interesse aqui serão escritas como o valor esperado de funções de variáveis aleatórias, isto é,

$\displaystyle \int g(x) dP(x) = E\left[g(x)\right]$. 

Deste modo, suponha que $X_1,X_2...$ é uma sequência de v.a. i.i.d e $g:\mathbb{R} \longrightarrow\mathbb{R}$ é uma função (mensurável) tal que $Var\left[g(X_1)\right]<\infty$. Então, pela *LGN*,

$\dfrac{1}{n}\displaystyle \sum_{i=1}^n g(X_i) ~\longrightarrow~ E\left[g(X_i)\right]$

$~$



## Método de Monte Carlo

Suponha que deseja-se calcular $\displaystyle\int_\Theta g(\theta)f(\theta|\boldsymbol x)d\theta=E\left[g(\theta|\boldsymbol x)\right]$ e é possível simular realizações $\theta_1,...,\theta_m$ da distribuição de $\theta |\boldsymbol X=\boldsymbol x$ , $f(\theta | \boldsymbol x)$.

Então, a integral acima pode ser aproximada por $\displaystyle \dfrac{1}{m}\sum_{i=1}^m g(\theta_i)$

* A precisão da aproximação é usualmente estimada pelo erro padrão da estimativa  
$\displaystyle EP\left[\dfrac{1}{m}\sum_{i=1}^m g(X_i)\right]$ 
$\approx \displaystyle \sqrt{\dfrac{1}{m}\left(\dfrac{1}{m}\sum_{i=1}^m\Big[g(\theta_i)\Big]^2-\left[\dfrac{1}{m}\sum_{j=1}^mg(\theta_j)\right]^2\right)}$

$~$

**Exemplo 1.** Suponha que deseja-se estimar o número $\pi$ usando o método de Monte Carlo. Considere então que o v.a. $(X,Y)$ tem distribuição uniforme em um quadrado centrado na origem, $\mathfrak{X}=[-1,1]\times[-1,1]$, e um círculo $A$ de raio $1$ inscrito nesse quadrado, $x^2+y^2\leq 1$. Como a distribuição é uniforme no quadrado, a probabilidade de escolher um ponto no círculo é 

$P(A)$ $=\dfrac{\text{área da círculo}}{\text{área do quadrado}}$ $=\dfrac{\pi}{4}$ $= \displaystyle\int_A f(x,y) dxdy$ $= \displaystyle\int_\mathfrak{X} \mathbb{I}_A(x,y)~\dfrac{1}{4}~dxdy$ $=E\left[\mathbb{I}_A(x,y)\right]$.

Suponha que é possível gerar uma amostra $\left\{(x_1,y_1),\ldots,(x_m,y_m)\right\}$ de $(X,Y)$, de modo que podemos aproximar o valor de $\pi$ por

$\pi$ $=4~P(A)$ $=E\left[4~\mathbb{I}_A(x,y)\right]$ $\displaystyle \approx \dfrac{1}{m}\sum_{i=1}^m 4~\mathbb{I}_A(x_i,y_i)$,

e, denotando por $\displaystyle t=\sum_{i=1}^m ~\mathbb{I}_A(x_i,y_i)$, o erro estimado é 

$\displaystyle \sqrt{\dfrac{1}{m}\left(\dfrac{1}{m}\sum_{i=1}^m\Big[4~\mathbb{I}(x_i,y_i)\Big]^2-\left[\dfrac{1}{m}\sum_{j=1}^m 4~\mathbb{I}(x_i,y_i)\right]^2\right)}$
$=\displaystyle \sqrt{\dfrac{1}{m}\left(\dfrac{16}{m}~t-\left[\dfrac{4}{m}~t\right]^2\right)}$
$= \displaystyle \sqrt{\dfrac{16}{m} \dfrac{t}{m}\left(1-\dfrac{t}{m}\right)}$ 
$\leq \displaystyle \sqrt{\dfrac{16}{m}~\dfrac{1}{4}}$ 
$= \dfrac{2}{\sqrt{m}}$.

```{r, fig.asp = 1}
set.seed(666)
M = 1000 # número de iterações
df = tibble(t = 1:M, x = runif(length(t), -1, 1), 
            y = runif(length(t), -1, 1)) %>% 
  mutate(Circ=ifelse(x^2+y^2<=1,1,0), 
         pi_est=round(4*cumsum(Circ)/t,4),
         erro=round(abs(pi-pi_est),4),
         erro_est=round(sqrt((cumsum(16*Circ)/t-pi_est^2)/t),4))
p <- ggplot() + theme_bw() + 
        theme(panel.grid.major = element_blank(),
            panel.grid.minor = element_blank(),
            panel.border = element_blank(),
            panel.background = element_blank()) +
        ggforce::geom_circle(aes(x0 = 0, y0 = 0, r = 1), color = "black") +
        geom_rect(aes(xmin = -1, ymin = -1, xmax = 1, ymax = 1), 
                  color = "black", alpha = 0) + 
        guides(color = FALSE) +
        geom_point(data = df, aes(x = x, y = y, colour = Circ), size = 3) + 
        gganimate::transition_manual(t, cumulative = TRUE) 
p + labs(title = expression(paste("Método de Monte-Carlo para a estimação do ",pi)), subtitle = "m = {df$t[frame]}  ;   pi_est = 4 * ({cumsum(df$Circ)[frame]} / {df$t[frame]}) = {df$pi_est[frame]}  ;   erro = {df$erro[frame]}  ;   erro_est = {df$erro_est[frame]}")
```

```{r}
# Erro absoluto e estimado com o aumento do tamanho amostral
df %>% filter(t>5) %>% ggplot() + theme_bw() +
        geom_line(aes(x = t, y = erro, colour="Erro Absoluto"),lwd=1.1) +
        geom_line(aes(x = t, y = erro_est, colour="Erro Estimado"),lwd=1.1) +
        geom_line(aes(x = t, y = 2/sqrt(t), colour="Máximo EP"),lwd=1.1) +
        xlab("m") + ylab("Erro") + labs(colour="") +
        gganimate::transition_manual(t, cumulative = TRUE) 
```

```{r}
# Estimativas com o aumento do tamanho amostral
df %>% filter(t>5 & t<=700) %>% 
  ggplot(aes(x = t, y = pi_est)) + theme_bw() +
        geom_line() +
        geom_hline(yintercept = pi, linetype = "longdash") +
        geom_ribbon(aes(ymin=pi_est-erro_est,ymax=pi_est+erro_est),alpha=0.3) +
        xlab("m") +
        ylab(expression(paste("Estimativa do ", pi))) +
        gganimate::transition_manual(t, cumulative = TRUE)
```

$~$

**Exemplo 2.** Suponha que você não sabe que 

$$\displaystyle \int_0^1 x^3(1-x)^5e^xdx = 74046 - 27240e\approx0.0029928$$

e deseja estimar o resultado usando o método de Monte Carlo. Assim, considere as duas propostas a seguir 

1. $U \sim Unif (0,1)$ e a integral pode ser escrita como $E\left[U^3(1-U)^5e^U\right]$;

1. $Y \sim Beta(4,6)$ de modo que  
$\displaystyle \int_0^1 y^3(1-y)^5e^y dx$ $=\beta(4,6)\displaystyle \int_0^1 e^y~~\frac{y^{4-1}(1-x)^{6-1}}{\beta(4,6)}~dx$ $=\beta(4,6)E\left[e^Y\right]$.

```{r, fig.asp = 1}
set.seed(666)
M = 1000 # número de iterações
theta = 74046 - 27240*exp(1)
df = tibble(t = 1:M, u = runif(length(t), 0, 1), 
            y = rbeta(length(t), 4, 6)) %>% 
  mutate(est_u=cumsum(exp(u+3*log(u)+5*log(1-u)))/t, 
         est_y=cumsum(exp(lbeta(4,6)+y))/t,
         erro_u=abs(theta - est_u),
         erro_y=abs(theta - est_y),
         erro_est_u=sqrt((cumsum(exp(2*(u+3*log(u)+5*log(1-u))))/t-est_u^2)/t),
         erro_est_y=sqrt((cumsum(exp(2*(lbeta(4,6)+y)))/t-est_y^2)/t) )
# Erro absoluto e estimado com o aumento do tamanho amostral
df %>% filter(t>5) %>% ggplot() + theme_bw() +
        geom_line(aes(x = t, y = erro_u, colour="Uniforme",linetype="Absoluto"),lwd=1.1) +
        geom_line(aes(x = t, y = erro_est_u, colour="Uniforme", linetype="Estimado"),lwd=1.1) +
        geom_line(aes(x = t, y = erro_y, colour="Beta",linetype="Absoluto"),lwd=1.1) +
        geom_line(aes(x = t,y=erro_est_y,colour="Beta", linetype="Estimado"),lwd=1.1)+
        xlab("m") + ylab("Erro") + labs(colour="Proposta",linetype="Tipo de Erro")+
        gganimate::transition_manual(t, cumulative = TRUE) 
```

```{r}
# Estimativas com o aumento do tamanho amostral
df %>% filter(t>5 & t<=750) %>% 
  ggplot() + theme_bw() +
        geom_hline(yintercept = theta, linetype = "longdash") +
        geom_line(aes(x = t, y = est_u, colour="Uniforme")) +
        geom_ribbon(aes(x=t,y=est_u,ymin=est_u-erro_est_u,ymax=est_u+erro_est_u,fill="Uniforme"),alpha=0.4) +
        geom_line(aes(x = t, y = est_y, colour="Beta")) +
        geom_ribbon(aes(x=t,y=est_y,ymin=est_y-erro_est_y,ymax=est_y+erro_est_y,fill="Beta"),alpha=0.4) +
        xlab("m") + ylab("Estimativa") + 
        labs(fill="Proposta") + guides(colour = FALSE) +
        gganimate::transition_manual(t, cumulative = TRUE)
```


$~$

**Exemplo 3. Região HPD** Suponha que $\boldsymbol \theta=(\mu,\sigma^2) \sim \textit{Normal-Inv.Gama}(m,v,a,b)$ e deseja-se obter estimativas pontuais e por região para $\boldsymbol \theta$. 

Se não houver um simulador da distribuição Normal-Inv.Gamma diretamente, é possível gerar um ponto $\boldsymbol \theta_i=(\mu_i,\sigma_i)$ tomando ${\sigma}_i^2 \sim \textit{Inv.Gama}(a,b)$ (ou $\tau_i \sim \textit{Gama}(a,b)$ e fazer ${\sigma}_i^2=1/\tau_i$) e $\mu_i \sim \textit{Normal}(m,{\sigma}_i^2/v)$. Nesse exemplo é fácil simular uma amostra da distribuição posterior e é possível obter estimativas pontuais simplesmente obtendo estatística resumo da amostra simulada, como média, moda, mediana, variância e desvio padrão. 

Para construir a região HPD, primeiramente note que

$R=\left\{\theta\in\Theta :~f(\theta | \boldsymbol x)\geq h)\right\}=\left\{\theta\in\Theta:~f(\boldsymbol x|\theta)f(\theta)\geq h^*=c\cdot h\right\}$,

de modo que não é necessário conhecer a constante $c=f(\boldsymbol x)$ para realizar essa tarefa. Como nesse exemplo a distribuição a posteriori é conhecida e fácil de ser simulada, considere o algorítmo a seguir para estimar a região HPD de probabilidade $\gamma$.

1. Simular $\theta_1,...,\theta_m$ de $f(\theta|\boldsymbol x)$;

2. Encontrar $h$ tal que $\displaystyle \dfrac{1}{m}\sum_{i=1}^m\mathbb{I}_{R}(\theta_i)=\dfrac{1}{m}\sum_{i=1}^m\mathbb{I}(f(\theta_i|\boldsymbol x)\geq h)\approx \gamma$
    1. Calcule $f(\boldsymbol \theta_i|\boldsymbol x)$, $i=1,\ldots,m$;
    2. Ordene esses valores e tome $h$ como o percentil de ordem $\gamma$.

3. Fazer o gráfico da curva de nível $f(\boldsymbol\theta |\boldsymbol x)=h$.


```{r, results ='asis'}
set.seed(666)
a=7; b=7; m=0; v=0.5 # parametros da posteriori
M=10000 # No. de simulações
dpost=Vectorize(function(t1,t2){ #densidade posterior
  extraDistr::dinvgamma(t2,a,b)*dnorm(t1,m,sqrt(t2/v))})
# simulações
df = tibble(sigma2=extraDistr::rinvgamma(M,a,b)) %>%  
  mutate(mu=rnorm(M,m,sqrt(sigma2/v)))
#summarytools::dfSummary(df, graph.magnif = 0.75, valid.col = FALSE, na.col = FALSE)
summarytools::dfSummary(df, plain.ascii = FALSE, style = "grid", 
          graph.magnif = 0.75, valid.col = FALSE, na.col = FALSE, 
          headings = FALSE, tmp.img.dir = "./tmp")
```


```{r}
df = df %>% mutate(post=dpost(mu,sigma2))
# variáveis para os gráficos
gama=c(0.99,0.95,0.9,0.8,0.5,0.3,0.1) # prob das regiões
l=quantile(df$post,1-gama)
d=100
x=seq(-4*extraDistr::qinvgamma(0.5,a,b)/v,4*extraDistr::qinvgamma(0.5,a,b)/v,
      length.out = d)
y=seq(0,extraDistr::qinvgamma(0.996,a,b),length.out = d)
z=matrix(apply(cbind(rep(x,d),rep(y,each=d)),1,function(t){dpost(t[1],t[2])}),ncol=d)
# gráfico da posteriori
plotly::plot_ly(alpha=0.1) %>% 
  plotly::add_surface(x=x, y=y, z=t(z), colorscale = list(c(0,'#BA52ED'), c(1,'#FCB040')), showscale = FALSE)
```

```{r}
# gráfico das regiões HPD de prob. gama=c(0.99,0.95,0.9,0.8,0.5,0.3,0.1)
tibble(x1=rep(x,d),y1=rep(y,each=d),z1=as.vector(z)) %>%
  arrange(z1) %>% mutate(p=1-(cumsum(z1)/sum(z1))) %>% 
  ggplot(aes(x1,y1,z=z1,fill = p)) +
  geom_raster(interpolate = TRUE) +
  scale_fill_distiller(palette = "YlOrRd") +
  geom_contour(breaks=l,col="black") +
  xlab(expression(mu)) + ylab(expression(sigma^2))
```
<!-- plot(df$mu,df$sigma2,col="darkgrey",xlim=c(-6,6),ylim=c(0.3,4.5)) -->
<!-- contour(x=x,y=y,z=z,levels=l,labels=gama,#col=viridisLite::plasma(length(l)), -->
<!--           xlab=expression(mu),ylab=expression(sigma^2),lwd=1.5,add=TRUE) -->

$~$

## Monte Carlo com Amostragem de Importância

Considere $f(\theta|\boldsymbol x)\propto f(\boldsymbol x| \theta)f(\theta)$ e suponha que não se sabe simular observações desta distribuição mas tem-se interesse na quantidade $E\left[g(\theta)|\boldsymbol x\right]=\displaystyle\int_\Theta g(\theta)f(\theta| \boldsymbol x)d\theta$.

Suponha também que existe uma distribuição $h(\theta)$ que seja uma aproximação para $f(\theta|\boldsymbol x)$ (preferencialmente com caudas mais pesadas) da qual sabe-se simular. Então,

$E\left[g(\theta)| \boldsymbol x\right]$ 
$=\displaystyle\int_\Theta g(\theta)f(\theta|\boldsymbol x)d\theta$
$=\dfrac{\displaystyle \int_\Theta g(\theta)f(\boldsymbol x|\theta)f(\theta)d\theta}{\displaystyle\int_\theta f(\boldsymbol x|\theta)f(\theta)d\theta}$ 
$=\dfrac{\displaystyle \int g(\theta)\left(\frac{f(\boldsymbol x|\theta)f(\theta)}{h(\theta)}\right)h(\theta)d\theta}{\displaystyle\int\left(\frac{f(\boldsymbol x|\theta)f(\theta)}{h(\theta)}\right)h(\theta)d\theta}$ $=\dfrac{\displaystyle\int g(\theta)w(\theta)h(\theta)d\theta}{\displaystyle\int w(\theta)h(\theta)d\theta}$ 
$\approx \displaystyle\sum_{i=1}^m \dfrac{w_i}{\sum_{j=1}^mw_j}~g(\theta_i)$, 

onde $w_i=w(\theta_i)=\dfrac{f(\boldsymbol x|\theta_i)f(\theta_i)}{h(\theta_i)}$. 

$~$

## Método de Rejeição

Considere novamente que o objetivo é simular observações de $f(\theta|\boldsymbol x)$ mas não é possível fazer isso diretamente. Por outro lado, sabe-se simular dados  de uma "distribuição candidata", $h(\theta)$, tal que $f(\theta|\boldsymbol x)\leq Mh(\theta)$, $\forall \theta \in \Theta$ e para alguma constante $M$. A ideia do método é rejeitar pontos gerados em regiões em que $h$ atribui maior probabilidade que $f$ com probabilidade $1-\left[f(\theta|\boldsymbol x)~/~Mh(\theta)\right]$. Para que a afirmação anterior faça sentido, $M$ deve ser tal que $f(\theta|\boldsymbol x)~/~ Mh(\theta) \leq 1$, $\forall \theta \in \Theta$, de modo que a melhor escolha para $M$ é $M^*=\underset{\Theta}{\sup}\dfrac{f(\theta|\boldsymbol x)}{h(\theta)}$.

```{r}
r = function(t){dbeta(t,4,2)/dbeta(t,1,1)}
M = optimize(r,c(0,1),maximum = TRUE)
tibble(t = seq(0,1,length.out = 1000)) %>% 
  mutate(f=dbeta(t,4,2), h=dbeta(t,1,1),
         Mh=M$objective*dbeta(t,1,1)) %>% 
  ggplot() + theme_bw() +
  geom_line(aes(x=t,y=f,colour="'Dist. Interesse' f"),lwd=1.1) +
  geom_line(aes(x=t,y=h,colour="'Dist. Candidata' h"),lwd=1.1) +
  geom_line(aes(x=t,y=Mh,colour="M.h"),lwd=1.1) +
  geom_segment(x=0.5,xend=0.5,y=dbeta(0.5,4,2),yend=M$objective*dbeta(0.5,1,1),col="darkgrey") +
  geom_segment(x=0.5,xend=0.5,y=0,yend=dbeta(0.5,4,2)) +
  geom_segment(x=0.25,xend=0.25,y=dbeta(0.25,4,2),yend=M$objective*dbeta(0.25,1,1),col="darkgrey") +
  geom_segment(x=0.25,xend=0.25,y=0,yend=dbeta(0.25,4,2)) +
  geom_segment(x=0.75,xend=0.75,y=dbeta(0.75,4,2),yend=M$objective*dbeta(0.75,1,1),col="darkgrey") +
  geom_segment(x=0.75,xend=0.75,y=0,yend=dbeta(0.75,4,2)) +
  labs(colour="")
```

No exemplo apresentado no gráfico acima, suponha que foram gerados os "candidatos" $0.25$, $0.5$ e $0.75$. É possível notar que o ponto $0.75$ deve ser aceito, o ponto $0.5$ dever ser aceito com probabilidade $0.59$ e o ponto $0.25$ deve ser aceito com probabilidade $0.11$. A seguir é apresentado o pseudo-algorítmo do método da rejeição.

>**Para** $i=1,...,m$  
$~~~$ **Repita**  
$~~~~~~$ Simule $u\sim Unif(0,1)$  
$~~~~~~$ Simule $\theta^\prime$ da distribuição candidata $h(\theta)$  
$~~~$ **Até** $u \leq \frac{f(\theta^\prime|\boldsymbol x)}{Mh(\theta^\prime)}$  
$~~~$ $\theta_i=\theta^\prime$  
**Fim_Para**.


```{r}
r = function(t){(0.4*dnorm(t,-1,1/2)+0.6*dt(t,5,1))/dt(t,1)}
M = optimize(r,c(-8,10),maximum = TRUE)
tibble(t = seq(-5,6,length.out = 1000)) %>% 
  mutate(f=(0.4*dnorm(t,-1,1/2)+0.6*dt(t,5,1)), h=dt(t,1),
         Mh=M$objective*dt(t,1)) %>% 
  ggplot() + theme_bw() +
  geom_line(aes(x=t,y=f,colour="'Dist. Interesse' f"),lwd=1.1) +
  geom_line(aes(x=t,y=h,colour="'Dist. Candidata' h"),lwd=1.1) +
  geom_line(aes(x=t,y=Mh,colour="M.h"),lwd=1.1) +
  geom_vline(xintercept=M$maximum,linetype="longdash",col="darkgrey") +
  labs(colour="")
```

A linha tracejada representa o ponto na escolha ótima para $M$. Nesse exemplo é possível notar que na região central, onde é mais "provável" gerar observações de $h$, a razão $f(\theta|\boldsymbol x)~/~Mh(\theta)$ é menor que $0.25$, de modo que há uma grande probabilidade de rejeição. Isso justifica a escolha de distribuições candidatas com caudas pesadas. No caso geral, a *probabilidade de aceitação* do método é 

$P\left(\left\{(U,\theta) : U \leq \dfrac{f(\theta|\boldsymbol x)}{Mh(\theta)}\right\}\right)$ $=E_{U,\theta}\left[\mathbb{I}\left(U \leq \dfrac{f(\theta|\boldsymbol x)}{Mh(\theta)}\right)\right]$ $=E_{\theta}\left[{E_{U|\theta}\left[\mathbb{I}\left(U \leq \dfrac{f(\theta|\boldsymbol x)}{Mh(\theta)}\right)\right]}\right]$
$=E_{\theta}\left[P\left(U \leq \dfrac{f(\theta|\boldsymbol x)}{Mh(\theta)}~\Big|~\theta\right)\right]$
$=E_\theta\left[\dfrac{f(\theta|\boldsymbol x)}{Mh(\theta)}\right]$ $=\displaystyle\int_\Theta\dfrac{f(\theta|\boldsymbol x)}{Mh(\theta)}h(\theta)d\theta$ $=\dfrac{1}{M}\displaystyle\int_\Theta f(\theta|\boldsymbol x)d\theta=\dfrac{1}{M}$.

$~$

No exemplo, a probabilidade de aceitação é $1/2.434 = 0.41$, ou seja, mais de metade das observações geradas seriam descartadas.

$~$



## ABC (Aproximated Bayesian Computation)

O método ABC é uma forma bastante simples de gerar pontos da distribuição a posteriori. Para sua utilização é suficiente saber gerar pontos da distribuição dos dados e da priori, de modo que a verossimilhança nem precisa ser analiticamente conhecida, fato esse que faz com que o método seja dito ser "*likelihood-free*".

Suponha o caso em que $\boldsymbol X$ é **discreto** com função de verossimilhança $f(\boldsymbol x|\theta)$, a priori é $f(\theta)$ e foi observado $\boldsymbol X=\boldsymbol x_o$. Abaixo é apresentado o *pseudo-algorítmo* para simular observaçoes da posteriori $f(\theta |\boldsymbol x_o)$ usando o método ABC.


>**Algorítmo ABC ($\boldsymbol X$ discreto)**  
$~$  
**Para** $i=1,...,m$  
$~~~$ **Repita**  
$~~~~~~$ Gere $\theta^\prime$ de $f(\theta)$ (*priori*)  
$~~~~~~$ Gere $\boldsymbol y = (y_1,...,y_n)$ de $f(\boldsymbol x|\theta^\prime)$ (*verossimilhança*)  
$~~~$ **Até** $\boldsymbol y =\boldsymbol x_o$  
$~~~$ $\theta_i = \theta^\prime$  
**Fim_Para**

Para verificar que o método funciona no caso discreto, basta ver que

$f(\theta_i)$ $=\displaystyle \sum_{y\in \mathfrak{X}}f(\theta_i)f(\boldsymbol y|\theta_i)\mathbb{I}(\boldsymbol y = \boldsymbol x_o)$ 
$=f(\theta_i)f(\boldsymbol x_o|\theta_i)$ 
$\propto f(\theta |\boldsymbol x_o)$.

$~$

No caso em que $\boldsymbol X$ é contínuo, a probabilidade de gerar uma nova amostra $\boldsymbol Y$ exatamente igual ao ponto observado $\boldsymbol x_o$ é zero, $P(\boldsymbol Y=\boldsymbol x_o)=0$. Nesse caso, o algorítmo é adaptado de modo que são aceitos pontos gerados com $\Delta\left(\eta(\boldsymbol y),\eta(\boldsymbol x_o)\right) \leq \varepsilon$, onde $\Delta$ é uma medida de distância conveniente, $\eta$ é uma estatística (que pode não ser suficiente para $\theta$) e $\varepsilon$ é uma constante de tolerância. O *pseudo-algorítmo* é apresentado a seguir.


>**Algorítmo ABC ($\boldsymbol X$ qualquer)**  
$~$  
**Para** $i=1,...,m$  
$~~~$ **Repita**  
$~~~~~~$ Gere $\theta^\prime$ de $f(\theta)$  
$~~~~~~$ Gere $\boldsymbol y$ de $f(\boldsymbol x|\theta^\prime)$  
$~~~$ **Até** $\Delta(\eta(\boldsymbol x),\eta(\boldsymbol y))\leq \varepsilon$  
$~~~$ $\theta_i=\theta^\prime$  
**Fim_Para**  

$~$


$~$

## MCMC - Monte Carlo via Cadeias de Markov

### Pequena Introdução às Cadeias de Markov

**Definição** Um *processo estocástico* (em tempo discreto) é uma sequência de v.a. $X_0,X_1,X_2,...$ indexada em $\mathbb{N}$ (os indices podem indicar, por exemplo, tempo ou espaço ou ?). O conjunto $E$ onde $X_i$ toma valores é chamado de *espaço de estados*.

$~$

**Definição** Um processo estocásticos é dito uma *Cadeia de Markov* (em tempo discreto) se, $\forall n \geq 1$ e $\forall A \subseteq E$,

$P(X_{n+1}\in A|X_{n}=x_{n},...,X_1=x_1,X_0=x_0)$ $=P(X_{n+1}\in A|X_{n}=x_{n})$

$~$

**Exemplo 1.** Suponha uma sequência de v.a. $\left(X_n\right)_{n\geq 1}$ i.i.d. tais que $p=P(X_1=1)=1-P(X_1=-1)$. Defina $S_n=\displaystyle \sum_{i=1}^n X_i$ e $X_0=c$. O processo estocástico $(S_n)_{n\geq 0}$ é uma Cadeia de Markov. De fato,

$P\left(S_n=s_n|S_{n-1}=s_{n-1},\ldots,S_0=s_0\right)$ 
$=\displaystyle P\left(X_n+S_{n-1}=s_{n}|S_{n-1}=s_{n-1},\ldots,S_0=s_0\right)$
<!-- $=\displaystyle P\left(X_n=s_n-s_{n-1},S_{n-1}=s_{n-1}|S_{n-1}=s_{n-1},\ldots,S_0=s_0\right)$ -->
$=\displaystyle P\left(X_n=s_n-s_{n-1}|S_{n-1}=s_{n-1},\ldots,S_0=s_0\right)$
$=\displaystyle P\left(X_n=s_n-s_{n-1}|S_{n-1}=s_{n-1}\right)$
$=\displaystyle P\left(S_n=s_n|S_{n-1}=s_{n-1}\right)$

```{r}
set.seed(666)
N=200
p=0.5; s0=0
t=seq(0,N)
X=2*rbinom(N,1,p)-1
Sn=c(s0,s0+cumsum(X))
tibble(t,Sn) %>% 
  ggplot() + theme_bw() + geom_point(aes(t,Sn)) + geom_line(aes(t,Sn))
```

$~$

Uma Cadeia de Markov é caracterizada pela distribuição do *estado inicial* $X_0$ e pelas *probabilidades de transição* $Q(x,A)=P(X_n\in A|X_{n-1}=x)$. Se $Q(x,A)$ não depende de $n$, dizemos que  é *homogênea no tempo*.

$~$

Para cada $n$, a cadeia pode

1. Continuar no estado anterior $x$, ou seja, $X_{n+1}=x,$ com probabilidade $r(x),~ 0\leq r<1$, ou

2. Saltar para um estado $y$ segundo uma função de densidade de probabilidade $q(x,y)$, onde $0<\displaystyle\int_E q(x,y)dy=1-r(x)\leq 1$ (sub-probabilidade). No caso discreto vamos considerar $q(x,x)=0$.

Assim, $Q(x,A)$ $=P(X_{n+1}\in A|X_{n}=x)$ $=\displaystyle\int_A q(x,y)dy+r(x)\mathbb{I}_A(x)$.

$~$ 

Suponha que para um dado $n$, $X_n$ tem densidade $\lambda$, isto é, $P(X_n\in A)=\displaystyle\int_A\lambda(x)dx$. Então, a densidade de $X_{n+1}$ pode ser obtida por

$P(X_{n+1}\in A)\overset{\text{regra da}\\\text{prob. total}}{=} \displaystyle\int_E \lambda(x)~Q(x,A)dx$ $=\displaystyle\int_E\lambda(x)\left[\int_A q(x,y)dy+r(x)\mathbb{I}_A(x)\right]dx$ $=\displaystyle\int_A\int_E\lambda(x)q(x,y)dxdy+\int_E\lambda(x)r(x)\mathbb{I}_A(x)dx$ $=\displaystyle\int_A\int_E\lambda(x)q(x,y)dxdy+\int_A\lambda(y)r(y)dy$ 
$\displaystyle \int_A\underbrace{\left[\int_E\lambda(x)q(x,y)dx+\lambda(y)r(y)\right]}_{f.d.p\;de\;X_{n+1}}dy$.

Assim, a f.d.p de $X_{n+1}$ é $\lambda Q(y)= \displaystyle\int_E\lambda(x)q(x,y)dx+\lambda(y)r(y)$

$~$

Dizemos que a densidade $\pi$ é *invariante* (*estacionária*) se as densidades de $X_{n}$ e $X_{n+1}$ são iguais (q.c), isto é, $\pi=\pi Q$ ou $\int_A \pi(x)dx=\int_E \pi(x)Q(x,A)dx$.

$~$

**Resultado 1.** A afirmação anterior é equivalente a $\int\pi(x)q(x,y)dx=(1-r(x))\pi(y)$.

$~$

**Resultado 2.** Se a função $q(x,y)$ satisfaz a condição de *reversibilidade*, isto é, $\pi(x)q(x,y)=\pi(y)q(y,x)$, então $\pi$ é uma *medida invariante* da cadeia com função de transição $Q(x,\cdot)$. 

$~$

**Demo 1.** 

$\displaystyle\int_E\pi(x)q(x,y)dx$ 
$=\displaystyle\int_E\pi(y)q(y,x)dx$ $=\displaystyle\pi(y)\underbrace{\int_Eq(y,x)dx}_{1-r(y)}$

$~$

**Demo(2).**

$\displaystyle\int_E \pi(x)Q(x,A)dx$ 
$=\displaystyle\int_E\pi(x)\left[\int_Aq(x,y)dy\right]dx+\int_E \pi(x) r(x)\mathbb{I}_A(x)dx$ $=\displaystyle\int_A\left[\int_E\pi(x)q(x,y)dx\right]dy+\int_A\pi(x)r(x)dx$ 
$=\displaystyle\int_A\left[\int_E\pi(y)q(y,x)dx\right]dy+\int_A\pi(y)r(y)dx$ 
$=\displaystyle\int_A\pi(y)\left[\int_Eq(y,x)dx\right]dy+\int_A\pi(y)r(y)dy$ 
$=\displaystyle\int_A\pi(y)\Big[1-r(y)\Big]dy+\int_A\pi(y)r(y)dy$
$=\displaystyle\int_A\pi(y)\Big[1-r(y)+r(y)\Big]dy$ 
$=\displaystyle\int_A\pi(y)dy$.

$~$


### O algoritmo de **Metrópolis-Hastings**
<!-- Metropolis et al. (1953) e Hastings (1970) -->

Suponha que deseja-se gerar observações de $\pi(\theta)\propto f(\boldsymbol x|\theta)f(\theta)\propto f(\theta|\boldsymbol x)$. Defina uma Cadeia de Markov $(Y_n)_{n\geq 1}$ tal que, no instante $n$, $Y_n=y$. No instante $n+1$, um candidato $z$ é gerado segundo a densidade $q(y,z)$ e é aceito com probabilidade $\alpha(y,z)$. Isto é, se $Y_n=y$,

$Y_{n+1}=\left\{\begin{array}{rcl}
z,& \text{com probabilidade}& \alpha(y,z)\\
y,& \text{com probabilidade}& 1-\alpha(y,z)\end{array}\right.$,

em que $\alpha$ é dado por

$\alpha(y,z)=\left\{\begin{array}{cl}
min\left\{
\dfrac{\pi(z)q(z,y)}{\pi(y)q(y,z)}~,~1\right\},& \text{ se }~ \pi(y)q(y,z)>0\\
1,& \text{c.c.}\end{array}\right.$

$~$

**Resultado:** O algoritmo de M-H gera uma cadeia reversível com respeito a $\pi$ e, portanto, tem $\pi$ como distribuição estacionária.

$~$

**Demo.** Deve-se mostrar que $\pi(y)\underbrace{q(y,z)\alpha(y,z)}_{p(y,z)}=\pi(z)\underbrace{q(z,y)\alpha(z,y)}_{p(z,y)}$

Suponha $\pi(z)q(z,y)\geq \pi(y)q(y,z)$ (o caso $\leq$ é análogo)

i) Se $\pi(z)q(z,y)=0\Rightarrow\pi(y)q(y,z)=0$ e vale a reversibilidade.

ii) $\pi(z)q(z,y)>0 ~\Rightarrow~ \alpha(y,z)=1$ e $\alpha(z,y)=\dfrac{\pi(y)q(y,z)}{\pi(z)q(z,y)}$.

Nesse caso, $\pi(z)q(z,y)\alpha(z,y)=$ $\pi(z)q(z,y)\dfrac{\pi(y)q(y,z)}{\pi(z)q(z,y)}$ $=\pi(y)q(y,z)$ $=\pi(y)q(y,z)\alpha(y,z)$

$~$

$~$

### Amostrador de Gibbs

Suponha que a $dim(\Theta)>1$ e deseja-se amostrar $f(\boldsymbol \theta| \boldsymbol x)$ e suponha que é possível obter amostras das distribuições *condicionais completas*, isto é, de $f(\theta_i| \boldsymbol \theta_{-i},\boldsymbol x)$, onde $\boldsymbol \theta_{-i}=(\theta_1,...,\theta_{i-1},\theta_{i+1},\theta_k)$. Note que $f(\theta_i| \boldsymbol \theta_{-i},\boldsymbol x)\propto f(\boldsymbol \theta| \boldsymbol x)=f(\boldsymbol  x|\boldsymbol \theta)f(\boldsymbol \theta)$. O método do *Amostrador de Gibbs* é um caso particular do algorítmo de Metrópolis-Hastings em que é gerada uma cadeia $\left(\boldsymbol \theta^{(n)}\right)_{n\geq 1}$ com $\alpha(\boldsymbol{y},\boldsymbol{z})=1$ e $q(\boldsymbol{y},z)=f\left({\theta}_j=\boldsymbol{z}~ \big|~ \boldsymbol{\theta}_{-j}=\boldsymbol{y},~\boldsymbol{x}\right)$, gerada segundo o algorítmo a seguir.

>**Algorítmo - Amostrador de Gibbs**  
$~$  
$~~~$ Defina uma "chute inicial" $\boldsymbol \theta^{(0)}$ (por exemplo, gerado da priori $f(\boldsymbol  \theta)$ ou fixado)  
**Para** $i=1,...,m$  
$~~~$ Gere $\theta_1^{(i)}$ de $f(\theta_1| \boldsymbol \theta_{-1}^{(i-1)},\boldsymbol x)$  
$~~~$ Gere $\theta_2^{(i)}$ de $f(\theta_2| \theta_{1}^{(i)}, \theta_{3}^{(i-1)},\ldots, \theta_{k}^{(i-1)} ,\boldsymbol x)$  
$~~~$ $~~~\vdots$  
$~~~$ Gere $\theta_{k-1}^{(i)}$ de $f(\theta_{k-1}| \theta_{1}^{(i)},\ldots, \theta_{k-2}^{(i)}, \theta_{k}^{(i-1)} ,\boldsymbol x)$  
$~~~$ Gere $\theta_k^{(i)}$ de $f(\theta_k| \boldsymbol \theta_{-k}^{(i)} ,\boldsymbol x)$  
**Fim_Para**

$~$

Os métodos de Metropolis-Hastings descritos anteriormente geram observações de cadeias de Markov com distribuição estacionária que coincide com a posteriori. Contudo, deve-se tomar dois cuidados para a utilização de métodos de Monte Carlo usando essas observalções. O primeiro é que é necessário verificar se a cadeia já atingiu a estacionariedade. Essa verificação é feita, em geral, observando os gráficos das cadeias geradas e, em geral, as primeiras $b$ observações são descartadas (*burn-in*). Outra possibilidade para verificar a estacionariedade da cadeia, bem como a influência do chute inicial, é gerar duas ou mais cadeias iniciando-se de pontos distintos. Outro problema é a dependência entre as observações geradas. Para contornar esse problema, normalmente uma distância $k$ entre as observações que serão consideradas na amostra final (*thin*) e as observações entre estas são descartadas. Assim, a amostra final é formada pelos pontos $\boldsymbol \theta_b, \boldsymbol \theta_{b+k}, \boldsymbol \theta_{b+2k},\ldots,\boldsymbol \theta_{M}$.

$~$

<!-- $~$ -->

<!-- **Exemplo 2:** $f(x,y)\propto\binom{n}{x}y^{a+x-1}(1-y)^{b+n-x-1}$ -->

<!-- $f(x|y)\propto f(x,y)\propto$ $\binom{n}{x}y^{x}(1-y)^{n-x}\sim X|Y=y\sim Bin(n,y)$ -->

<!-- $f(x|y)\propto y^{a+x-1(1-y)^{b+n-x-1}}$ $\sim Beta(a+x,b+n-x)$ -->

<!-- $f(x)$, $X\sim Beta-Binomial(n,a,b)$ ($n$ conhecido) -->

<!-- $~$ -->

<!-- **Exemplo 3:** $N\sim Poisson(\lambda)$ -->

<!-- $f(x,y,n)\propto \binom{n}{x}y^{a+x-1}(1-y)^{b+n-x-1}\dfrac{e^{-\lambda}\lambda^n}{n!}$ -->

<!-- $x\in\{0,...,n\},$ $y\in[0,1]$, $n\in\{0,1,...\}$, $n\geq x$. -->

<!-- $f(x|y,n)\sim Bin(n,y)$ e $f(y|x,n)\sim Beta(a+x,b+n-x)$ -->

<!-- $f(n|x,y)\propto \dfrac{n!}{(n-x)!}(1-y)^n\dfrac{\lambda^n}{n!}$ $\propto\dfrac{e^{-(1-y)\lambda}[(1-y)\lambda]^{(n-x)}}{(n-x)!},$ $n\in\{x,x+1,...\}$ -->

<!-- $~$ -->

<!-- **Lição de Casa**  -->

<!-- 1) Implementar os dois exemplos usando Gibbs para obter uma estimativa de $f(x)$ e compará-las. -->

<!-- 2) Implemetar esses exemplos usando uma biblioteca (STAN, LaplacesDemon, ....) -->

<!-- ```{r} -->
<!-- a=1; b=1; l=1000 -->
<!-- M=1000 -->
<!-- p=vector(length = M) -->
<!-- x=vector(length = M) -->
<!-- n=vector(length = M) -->
<!-- p[1] = 0.5 -->
<!-- n[1] = 1000 -->
<!-- x[1] = 600 -->
<!-- for(i in 2:M){ -->
<!--   p[i] = rbeta(1,a+x[i-1],b+n[i-1]-x[i-1]) -->
<!--   n[i] = x[i-1]+rpois(1,(1-p[i])*l) -->
<!--   x[i] = rbinom(1,n[i],p[i]) -->
<!-- } -->
<!-- ts.plot(n[100:M]) -->
<!-- ts.plot(p[100:M]) -->
<!-- ts.plot(x[100:M]) -->
<!-- plot(n[100:M],p[100:M]) -->
<!-- plot(n[100:M],x[100:M]) -->
<!-- plot(x[100:M],p[100:M]) -->
<!-- hist(n[100:M],prob=TRUE) -->
<!-- hist(p[100:M],prob=TRUE) -->
<!-- hist(x[100:M],prob=TRUE) -->
<!-- ``` -->

**Exemplo 1.** Seja $X_1,\ldots,X_n$ c.i.i.d. tais que $X_i~|~\theta_1,\theta_2 \sim \textit{Exp}\left(\theta_1\theta_2\right)$ e considere que a priori $\theta_i \sim \textit{Gama}\left(a_1,b_i\right)$, $i=1,2$. Assim,

$f(\boldsymbol \theta|\boldsymbol x)$ 
$\propto f(\boldsymbol x|\boldsymbol \theta) f(\theta_1)f(\theta_2)$ 
$\propto (\theta_1 \theta_2)^n~e^{-\theta_1\theta_2\sum x_i}~~\theta_1^{a_1-1}e^{-b_1\theta_1}~~\theta_2^{a_2-1}e^{-b_2\theta_2}$ 
$\propto \theta_1^{a_1+n-1}~\theta_2^{a_2+n-1}~~e^{-b_1\theta_1-b_2\theta_2 -\theta_1\theta_2\sum x_i}$.

Essa distribuição não é conhecida mas é possível obter as distribuições condicionais completas

$f(\theta_i|\theta_j,\boldsymbol x) \propto \theta_i^{a_i+n-1}~e^{-\left[b_i \theta_j\sum x_i\right]\theta_i}$ $\Longrightarrow \theta_i~|~\theta_j,\boldsymbol x \sim \textit{Gama}\left(a_i+n,b_i+\theta_j\sum x_i\right)$,

e, portanto, é possível simular observações da posteriori usando o amostrador de Gibbs.

```{r}
set.seed(666)
a1=2; b1=3
a2=3; b2=2
n=8
sumx=4
M=1000
theta1=vector(length = M)
theta2=vector(length = M)
theta1[1] = 4
theta2[1] = 4
for(i in 2:M){
  theta1[i] = rgamma(1,a1+n,b1+theta2[i-1]*sumx)
  theta2[i] = rgamma(1,a2+n,b2+theta1[i]*sumx)
}
tibble(theta1=theta1[1:M],theta2=theta2[1:M],t=seq(1,length(theta1))) %>% 
  ggplot() + theme_bw() +
  geom_path(aes(theta1,theta2),col="darkgrey") +
  geom_point(aes(theta1,theta2)) +
  gganimate::transition_manual(t, cumulative = TRUE) 
```


A seguir, são apresentados os gráficos das cadeias geradas e das autocorrelações.

```{r, echo=FALSE}
par(mfrow=c(2,2))
ts.plot(theta1)
ts.plot(theta2)
acf(theta1,main="")
acf(theta2,main="")
par(mfrow=c(1,1))
```

Aparentemente, a cadeia converge rapidamente para a distribuição estacionária mas as autocorrelações entre observações consecutivas é alta. Assim, vamos descartar as 10 primeiras observações e considerar saltos de tamanho 5. Os novo gráficos são apresentados abaixo.

```{r, echo=FALSE}
sel=seq(10,M,5)
par(mfrow=c(2,2))
ts.plot(theta1[sel],ylab="theta1")
ts.plot(theta2[sel],ylab="theta2")
acf(theta1[sel],main="")
acf(theta2[sel],main="")
par(mfrow=c(1,1))
```

Por fim são apresentadas as estimativas das densidades marginais e as regiões HPD.

```{r}
tibble(t=c(theta1,theta2),
       theta=c(rep(c("theta1","theta2"),each=length(t)/2))) %>% 
  ggplot() + theme_bw() +
  #geom_histogram(aes(t,fill=theta),alpha=0.5) + 
  geom_density(aes(t,colour=theta),lwd=1.3) + 
  facet_wrap(~theta)
```

```{r}
dpost=Vectorize(function(t1,t2){ #densidade posterior
  exp((n-1)*log(t1*t2)+dexp(sumx,t1*t2,log=TRUE)+dgamma(t1,a1,b1,log=TRUE)+dgamma(t2,a2,b2,log=TRUE))})
# simulações
df = tibble(theta1=theta1,theta2=theta2) %>% mutate(post=dpost(theta2,theta2))
# variáveis para os gráficos
gama=c(0.99,0.95,0.9,0.8,0.5,0.3,0.1) # prob das regiões
l=quantile(df$post,1-gama)
d=500
x=seq(0,15,length.out = d)
y=seq(0,15,length.out = d)
z=matrix(apply(cbind(rep(x,d),rep(y,each=d)),1,function(t){dpost(t[1],t[2])}),ncol=d)
# gráfico das regiões HPD de prob. gama=c(0.99,0.95,0.9,0.8,0.5,0.3,0.1)
tibble(x1=rep(x,d),y1=rep(y,each=d),z1=as.vector(z)) %>%
  arrange(z1) %>% mutate(p=1-(cumsum(z1)/sum(z1))) %>% 
  ggplot(aes(x1,y1,z=z1,fill = p)) +
  geom_raster(interpolate = TRUE) +
  scale_fill_distiller(palette = "YlOrRd") +
  geom_contour(breaks=l,col="black") +
  xlab(expression(theta[1])) + ylab(expression(theta[2]))
```


<!-- ***Referência*** -->

<!-- 1) [Explaining the Gibbs Sampler (1992). G. Casella, E.I. George. TAS](https://www.jstor.org/stable/pdf/2685208.pdf) -->

<!-- 2) [Understanding the Metropolis-Hastings Algorithm (1995). S. Chib, E. Greenberg. TAS ](https://www.jstor.org/stable/pdf/2684568.pdf) -->

```{r, echo=FALSE}
# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)
  
  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)
  numPlots = length(plots)
  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                     ncol = cols, nrow = ceiling(numPlots/cols))
  }
  if (numPlots==1) {
    print(plots[[1]])
  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
    
    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```

## Bibliotecas de R para Inferência Bayesiana

Nessa seção serão apresentadas algumas bibliotecas do R para inferência Bayesiana, em especial, `LaplacesDemon` e `Stan`, que são bibliotecas utilizadas para simular dados da posteriori. Para isso, será apresentado como exemplo o modelo de regressão linear, possivelmente um dos métodos mais usados nas aplicações de inferência estatística.

### O Modelo de Regressão Linear

Considere $n$ observações de uma variável aleatória de interesse (chamada de *variável dependente* ou *variável resposta*) e de $p-1$ características associadas a cada uma dessas observações (chamadas de *variáveis dependentes* ou *explicativas* ou *covariáveis*), supostamente fixadas. Um modelo de regressão linear pode ser escrito como

$$\boldsymbol{Y} = \boldsymbol{X}\boldsymbol{\beta} + \boldsymbol{\epsilon}$$
com 
$~\boldsymbol{Y} = \left[\begin{array}{c} Y_1\\ Y_2\\ \vdots\\ Y_n \end{array}\right]~~$;
$~~~\boldsymbol{X} = \left[\begin{array}{cccc} 1 & x_{11} & \cdots & x_{1,p-1}\\ 1 & x_{21} & \cdots & x_{2,p-1}\\ \vdots & \vdots & \ddots & \vdots \\ 1 & x_{n1} & \cdots & x_{n,p-1} \end{array}\right]~~$;
$~~~\boldsymbol{\beta} = \left[\begin{array}{c} \beta_1\\ \beta_2\\ \vdots\\ \beta_p \end{array}\right]~~$;
$~~~\boldsymbol{\epsilon} = \left[\begin{array}{c} \epsilon_1\\ \epsilon_2\\ \vdots\\ \epsilon_n \end{array}\right]~~$;
$~~~\boldsymbol{Z} = \left[\boldsymbol{X,Y}\right]~~$,

em que $\boldsymbol{Z}$ é a matriz de dados (observada), $\boldsymbol{\beta}$ é o vetor de parâmetros e $\epsilon_i$ é o *"erro aleatório"* associado a $i$-ésima observação, supostamente c.i.i.d. com distribuição $\textit{Normal}(0,\sigma^2)$. 

De forma equivalente, o modelo pode ser escrito como $\boldsymbol{Y}|\boldsymbol{X},\boldsymbol{\beta},\sigma \sim \textit{Normal}_{~n}(\boldsymbol{\mu},\boldsymbol{\Sigma})$ com $\boldsymbol{\mu}=\boldsymbol{X}\boldsymbol{\beta}$ e $\boldsymbol{\Sigma}=\sigma^2\boldsymbol{I}$. 

$~$

Na abordagem *frequentista*, se $\boldsymbol{X}'\boldsymbol{X}$ é não singular, os estimadores de máxima verossimilhança para os parâmetros $(\boldsymbol{\beta},\sigma^2)$ são, respectivamente,  $\hat{\boldsymbol{\beta}} = (\boldsymbol{X}'\boldsymbol{X})^{-1}\boldsymbol{X}'\boldsymbol{Y}$ e $s^2 = \dfrac{(\boldsymbol{Y}-\boldsymbol{X}\hat{\boldsymbol{\beta}})'(\boldsymbol{Y}-\boldsymbol{X}\hat{\boldsymbol{\beta}})}{n-p}$.

$~$

**Exemplo.** Vamos considerar um simples exemplo de regressão linear, com apenas uma covariável. Para isso, considere as variáveis `speed` e `dist` do conjunto de dados `cars`, disponível no R. Um ajuste usando a abordagem frequentista é apresentado a seguir.

```{r}
# a boring regression
fit = lm(speed ~ 1 + dist, data = cars)
coef(summary(fit)) # estimativa dos betas
(summary(fit)$sigma)**2 # estimativa do sigma^2
ggplot(cars, aes(y=speed, x=dist)) + theme_bw() +
  geom_point() + geom_smooth(method=lm)
```

$~$

---

$~$

Sob a abordagem *bayesiana*, a distribuição Normal-Inversa Gama (*NIG*) é uma priori conjugada para $\boldsymbol{\theta} = (\boldsymbol{\beta},\sigma^2)$ neste modelo. Assim,
$$(\boldsymbol{\beta},\sigma^2) \sim \textit{NIG}(\boldsymbol{\beta}_0, \boldsymbol{V}_0, a_0, b_0)~.$$

Isto é,
$\boldsymbol{\beta} | \sigma^2 \sim Normal_p\left(\boldsymbol{\beta}_0,\sigma^2\boldsymbol{V}_0\right)~~$; $~~ \sigma^2 \sim InvGamma\left(a_0,b_0\right)$

ou, equivalentemente,

$\boldsymbol{\beta} \sim T_p\left(2a_0; \boldsymbol{\beta}_0,\frac{b_0 \boldsymbol{V}_0}{a_0}\right)  ~~$; $~~  \sigma^2 | \boldsymbol{\beta} \sim InvGamma\left(a_0 + \frac{p}{2},b_0 + \frac{\left(\boldsymbol{\beta}-\boldsymbol{\beta}_0\right)^T \boldsymbol{V}_0^{-1} \left(\boldsymbol{\beta}-\boldsymbol{\beta}_0\right) }{2}\right)~~$,

com $\boldsymbol{\beta}_0 \in \mathbb{R}^p$, $\boldsymbol{V}_0$ matriz simétrica positiva definida e $a_0, b_0 \in \mathbb{R}_+$.

$~$

Então:
$$(\boldsymbol{\beta},\sigma^2)|\boldsymbol{Z} \sim \textit{NIG}(\boldsymbol{\beta}_1, \boldsymbol{V}_1, a_1, b_1)$$

com
$\boldsymbol{\beta}_1 = \boldsymbol{V}_1\left(\boldsymbol{V}_0^{-1}\boldsymbol{\beta}_0 + \boldsymbol{X}^T\boldsymbol{X} \hat{\boldsymbol{\beta}}\right) ~~$; $~~ \boldsymbol{V}_1 = \left(\boldsymbol{V}_0^{-1} + \boldsymbol{X}^T\boldsymbol{X}\right)^{-1}~~$;
$a_1 = a_0+\frac{n}{2} ~~$; $~~ b_1 = b_0 + \frac{\boldsymbol{\beta}_0^T\boldsymbol{V}_0^{-1}\boldsymbol{\beta}_0 + \boldsymbol{Y}^T\boldsymbol{Y} - \boldsymbol{\beta}_1^T\boldsymbol{V}_1^{-1}\boldsymbol{\beta}_1}{2}$.

$~$

| Observação: |  
|-----|
| Uma das maneiras de representar falta de informação nesse contexto é utilizar a priori de Jeffreys, $f(\boldsymbol \theta) = \Big|~\mathcal{I}(\boldsymbol \theta)~\Big|^{1/2} \propto 1/\sigma^2$. Nesse caso, distribuição a posteriori é $(\boldsymbol{\beta},\sigma^2)\Big|\boldsymbol{Z} \sim \textit{NIG}\left(\hat{\boldsymbol{\beta}}, \left(\boldsymbol{X}^T\boldsymbol{X}\right)^{-1}, \dfrac{n-p}{2}, \dfrac{(n-p)s^2}{2}\right)$. |  
| |  

$~$

---

$~$


**Exemplo.** Considere que, a priori, $(\boldsymbol{\beta},\sigma^2) \sim \textit{NIG}\left(\boldsymbol{\beta}_0, \boldsymbol{V}_0, a_0, b_0\right)$, com $~\boldsymbol{\beta}_0 = \left[\begin{array}{c} 0\\0\end{array}\right]~$; 
$~\boldsymbol{V}_0 = \left[\begin{array}{cc} 100 & 0\\ 0 & 100\end{array}\right] ~$; $~a_0 = 3~$; $~b_0 = 100~$.

A seguir são apresentadas as distribuições marginais dos parâmetros, a distribuição marginal e as regiões HPD bivariadas do parâmetro $\boldsymbol{\beta}$.

```{r}
x = cars$dist   # variável resposta
y = cars$speed  # variável explicativa
n = length(x)   # n=50
X = cbind(1,x)  # Matrix de planejamento
p = ncol(X)     # p=2
g = n-p         # gl=48
beta_est = solve(t(X)%*%X)%*%(t(X)%*%y) # (-17.6, 3.9)
sigma_est = 
  as.double(t(y-X%*%beta_est)%*%(y-X%*%beta_est)/(n-p)) #236.5
beta0 = c(0,0)                     # média priori betas
V0 = matrix(c(100,0,0,100),ncol=2) # matriz de escala beta
a0 = 3                             # priori sigma
b0 = 100                           # priori sigma
# parâmetros da posteriori
V1 = solve(solve(V0) + t(X)%*%X)
beta1 = V1%*%(solve(V0)%*%beta0 + t(X)%*%X%*%beta_est)
a1 = a0 + n/2
b1 = as.double(b0 + (t(beta0)%*%solve(V0)%*%beta0 + t(y)%*%y - t(beta1)%*%solve(V1)%*%beta1)/2)
V = b1*V1/a1 # Matrix de escala da posteriori marginal de beta

beta1lim=c(beta1[1]-qt(0.9999,2*a1)*sqrt(V[1,1]),beta1[1]+qt(0.9999,2*a1)*sqrt(V[1,1]))
beta2lim=c(beta1[2]-qt(0.9999,2*a1)*sqrt(V[2,2]),beta1[2]+qt(0.9999,2*a1)*sqrt(V[2,2]))
sigma2lim=c(extraDistr::qinvgamma(0.0001,a1,b1),extraDistr::qinvgamma(0.9999,a1,b1))

b1plot <- ggplot(data.frame(x=beta1lim), aes(x=x), colour = "0.Posterior") + 
  stat_function(fun = mnormt::dmt,args = list(mean = beta1[1], S = V[1,1], df=2*a1)) + 
  theme_bw() + xlab(expression(beta[1])) + ylab("Posterior")  
b2plot <- ggplot(data.frame(x=beta2lim), aes(x=x), colour = "0.Posterior") + 
  stat_function(fun = mnormt::dmt, args = list(mean = beta1[2], S = V[2,2], df=2*a1)) +
  theme_bw() + xlab(expression(beta[2])) + ylab("Posterior")
s2plot <- ggplot(data.frame(x=sigma2lim),aes(x=x), colour = "0.Posterior")+ 
  stat_function(fun = extraDistr::dinvgamma, args = list(alpha = a1, beta = b1)) +
  theme_bw() + xlab(expression(sigma^2)) + ylab("Posterior")
multiplot(b1plot,b2plot,s2plot)
```


```{r}
# posteriori marginal bivariada dos betas
posterior <- function(theta0,theta1) { apply(cbind(theta0,theta1),1,function(w){ mnormt::dmt(w, mean=c(beta1), S=V, df=2*a1)  }) }
# Gráfico da posteriori marginal bivariada dos betas
grx <- seq(beta1lim[1], beta1lim[2],length.out=200)
gry <- seq(beta2lim[1], beta2lim[2],length.out=200)
z1 <- outer(grx,gry,posterior)
#persp(grx,gry,z1)
plotly::plot_ly(alpha=0.1) %>% 
  plotly::add_surface(x=grx, y=gry, z=t(z1), colorscale = list(c(0,'#BA52ED'), c(1,'#FCB040')), showscale = FALSE)
```



```{r}
# Curvas de Probabilidade
l = c(0.1,0.3,0.5,0.8,0.9,0.95,0.99)
z1v = sort(as.vector(z1),decreasing = TRUE)
v1 <- z1v/sum(z1v)
a=0; j=1; l1=NULL
for(i in 1:length(v1)) {
  a <- a+v1[i]
  if(j<=length(l) & a>l[j]) {
    l1 <- c(l1,z1v[i-1])
    j <- j+1 
  }
}
contour(grx,gry,z1,col=colors()[455],main="Regiões HPD para os Betas",xlab=expression(beta[1]),ylab=expression(beta[2]),levels=l1,labels=l)
points(beta1[1],beta1[2],col="darkred",pch=16,cex=0.5)
```

$~$

---

$~$


### Laplace's Demon

LaplacesDemon é uma biblioteca do R que oferece diversos algoritimos implementados de MCMC, permitindo fazer Inferência Bayesiana aproximada. Os algoritimos de MCMC disponíveis são

1.  Automated Factor Slice Sampler (AFSS)
1.  Adaptive Directional Metropolis-within-Gibbs (ADMG)
1.  Adaptive Griddy-Gibbs (AGG)
1.  Adaptive Hamiltonian Monte Carlo (AHMC)
1.  Adaptive Metropolis (AM)
1.  Adaptive Metropolis-within-Gibbs (AMWG)
1.  Adaptive-Mixture Metropolis (AMM)
1.  Affine-Invariant Ensemble Sampler (AIES)
1.  Componentwise Hit-And-Run Metropolis (CHARM)
1.  Delayed Rejection Adaptive Metropolis (DRAM)
1.  Delayed Rejection Metropolis (DRM)
1.  Differential Evolution Markov Chain (DEMC)
1.  Elliptical Slice Sampler (ESS)
1.  Gibbs Sampler (Gibbs)
1.  Griddy-Gibbs (GG)
1.  Hamiltonian Monte Carlo (HMC)
1.  Hamiltonian Monte Carlo with Dual-Averaging (HMCDA)
1.  Hit-And-Run Metropolis (HARM)
1.  Independence Metropolis (IM)
1.  Interchain Adaptation (INCA)
1.  Metropolis-Adjusted Langevin Algorithm (MALA)
1.  Metropolis-Coupled Markov Chain Monte Carlo (MCMCMC)
1.  Metropolis-within-Gibbs (MWG)
1.  Multiple-Try Metropolis (MTM)
1.  No-U-Turn Sampler (NUTS)
1.  Oblique Hyperrectangle Slice Sampler (OHSS)
1.  Preconditioned Crank-Nicolson (pCN)
1.  Random Dive Metropolis-Hastings (RDMH)
1.  Random-Walk Metropolis (RWM)
1.  Reflective Slice Sampler (RSS)
1.  Refractive Sampler (Refractive)
1.  Reversible-Jump (RJ)
1.  Robust Adaptive Metropolis (RAM)    
1.  Sequential Adaptive Metropolis-within-Gibbs (SAMWG)
1.  Sequential Metropolis-within-Gibbs (SMWG)
1.  Slice Sampler (Slice)
1.  Stochastic Gradient Langevin Dynamics (SGLD)
1.  Tempered Hamiltonian Monte Carlo (THMC)
1.  t-walk (twalk)
1.  Univariate Eigenvector Slice Sampler (UESS)
1.  Updating Sequential Adaptive Metropolis-within-Gibbs (USAMWG)
1.  Updating Sequential Metropolis-within-Gibbs (USMWG)

https://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf

https://cran.r-project.org/web/packages/LaplacesDemon/vignettes/LaplacesDemonTutorial.pdf

https://cran.r-project.org/web/packages/LaplacesDemon/vignettes/Examples.pdf

https://cran.r-project.org/web/packages/LaplacesDemon/LaplacesDemon.pdf


$~$

+ Especificação do modelo

```{r}
require(LaplacesDemon)

parm.names=as.parm.names(list(beta=rep(0,p), sigma2=0))
pos.beta=grep("beta", parm.names)
pos.sigma=grep("sigma2", parm.names)

MyData <- list(J=p, X=X, y=y, mon.names="LP",
  parm.names=parm.names,pos.beta=pos.beta,pos.sigma=pos.sigma)

Model <- function(parm, Data)
{
  ### Parameters
  beta <- parm[Data$pos.beta]
  sigma2 <- interval(parm[Data$pos.sigma], 1e-100, Inf)
  parm[Data$pos.sigma] <- sigma2
  ### Log-Prior
  sigma.prior <- dinvgamma(sigma2, a0, b0, log=TRUE)
  beta.prior <- dmvn(beta, beta0, sigma2*V0, log=TRUE)
  ### Log-Likelihood
  mu <- tcrossprod(Data$X, t(beta))
  LL <- sum(dnormv(Data$y, mu, sigma2, log=TRUE))
  ### Log-Posterior
  LP <- LL + beta.prior + sigma.prior
  Modelout <- list(LP=LP, Dev=-2*LL, Monitor=LP,
                   yhat=rnorm(length(mu), mu, sigma2), parm=parm)
  return(Modelout)
}

Initial.Values <- c(beta_est,sigma_est)

burnin <- 2000
thin <- 3
N=(2000+burnin)*thin
```

---

+ **Exemplo 1:** Metropolis-within-Gibbs (MWG)

```{r}
set.seed(666)
Fit1 <- LaplacesDemon(Model, Data=MyData, Initial.Values,
  Covar=NULL, Iterations=N, Status=N/5, Thinning=thin,
  Algorithm="MWG", Specs=NULL)
#names(Fit1)
print(Fit1)

Post1 <- data.frame(Fit1$Posterior1,Algorithm="1.MWG")
colnames(Post1) <- c("beta1","beta2","sigma2","Algorithm")
#head(Post1)

#plot(Fit1, BurnIn=burnin, MyData, PDF=FALSE, Parms=NULL)
plot(Fit1, BurnIn=0, MyData, PDF=FALSE, Parms=NULL)
```


---

+ **Exemplo 2:** Adaptative Metropolis-within-Gibbs (MWG)

```{r}
set.seed(666)
Fit2 <- LaplacesDemon(Model, Data=MyData, Initial.Values,
  Covar=NULL, Iterations=N, Status=N/5, Thinning=thin,
  Algorithm="AMWG", Specs=NULL)
#names(Fit2)
#print(Fit2)

Post2 <- data.frame(Fit2$Posterior1,Algorithm="2.AMWG")
colnames(Post2) <- c("beta1","beta2","sigma2","Algorithm")
#head(Post2)

#plot(Fit2, BurnIn=burnin, MyData, PDF=FALSE, Parms=NULL)
plot(Fit2, BurnIn=0, MyData, PDF=FALSE, Parms=NULL)
```

```{r}
Post <- rbind(Post1,Post2)
b1plot <- ggplot(Post) + 
  stat_function(aes(colour="0.Posterior"), fun = mnormt::dmt,args = list(mean = beta1[1], S = V[1,1], df=2*a1)) +
  geom_density(aes(beta1, colour = Algorithm)) + theme_bw() +
  xlab(expression(beta[1])) + ylab("Posterior") + labs(colour = "Method")
b2plot <- ggplot(Post) + 
  stat_function(aes(colour="0.Posterior"), fun = mnormt::dmt, args = list(mean = beta1[2], S = V[2,2], df=2*a1)) +
  geom_density(aes(beta2, colour = Algorithm)) + theme_bw() +
  xlab(expression(beta[2])) + ylab("Posterior") + labs(colour = "Method")
s2plot <- ggplot(Post)+ 
  stat_function(aes(colour="0.Posterior"), fun = extraDistr::dinvgamma, args = list(alpha = a1, beta = b1)) +
  geom_density(aes(sigma2, colour = Algorithm)) + theme_bw() +
  xlab(expression(sigma^2)) + ylab("Posterior") + labs(colour = "Method")
multiplot(b1plot,b2plot,s2plot)
```

---

+ **Exemplo 3:** Consort e Automated Factor Slice Sampler (AFSS)

```{r}
Consort(Fit2)
Initial.Values <- as.initial.values(Fit2)

set.seed(666)
Fit3 <- LaplacesDemon(Model, Data=MyData, Initial.Values,
     Covar=NULL, Iterations=N, Status=N/5, Thinning=thin,
     Algorithm="AFSS", Specs=list(A=Inf, B=NULL, m=100,n=0, w=1))
Post3 <- data.frame(Fit3$Posterior1,Algorithm="3.AFSS")
colnames(Post3) <- c("beta1","beta2","sigma2","Algorithm")
plot(Fit3, BurnIn=0, MyData, PDF=FALSE, Parms=NULL)
```

```{r}
Post <- rbind(Post1,Post2,Post3)
b1plot <- ggplot(Post) + 
  stat_function(aes(colour="0.Posterior"), fun = mnormt::dmt,args = list(mean = beta1[1], S = V[1,1], df=2*a1)) +
  geom_density(aes(beta1, colour = Algorithm)) + theme_bw() +
  xlab(expression(beta[1])) + ylab("Posterior") + labs(colour = "Method")
b2plot <- ggplot(Post) + 
  stat_function(aes(colour="0.Posterior"), fun = mnormt::dmt, args = list(mean = beta1[2], S = V[2,2], df=2*a1)) +
  geom_density(aes(beta2, colour = Algorithm)) + theme_bw() +
  xlab(expression(beta[2])) + ylab("Posterior") + labs(colour = "Method")
s2plot <- ggplot(Post)+ 
  stat_function(aes(colour="0.Posterior"), fun = extraDistr::dinvgamma, args = list(alpha = a1, beta = b1)) +
  geom_density(aes(sigma2, colour = Algorithm)) + theme_bw() +
  xlab(expression(sigma^2)) + ylab("Posterior") + labs(colour = "Method")
multiplot(b1plot,b2plot,s2plot)
```


```{r}
p.interval(Post3$beta1, HPD=FALSE, MM=FALSE, plot=TRUE)


set.seed(666)
S0 <- as.matrix(extraDistr::rinvgamma(N/thin-burnin,a1,b1))
M0 <- apply(S0,1,function(s){mnormt::rmnorm(1,mean=beta1,varcov=s*V1)})
Post0 <- data.frame(t(M0),S0,"0.Posterior")
colnames(Post0) <- c("beta1","beta2","sigma2","Algorithm")
Post = rbind(Post0,Post1,Post2,Post3)
ggplot(Post) + theme_bw() +
  geom_point(aes(beta1,beta2,colour=Algorithm), shape=1) + 
  facet_wrap(Algorithm ~ .)
```

---

### Stan

O Stan é uma plataforma de modelagem estatística de alto desempenho. Em particular, permite fazer inferência bayesiana usando o método de Monte Carlo Hamiltoniano (HMC) e a variação No-U-Turn Sampler (NUTS). Esses recursos convergem para distribuições alvo de altas dimensões muito mais rapidamente que métodos mais simples, como o amostrador de Gibbs ou outras variações do método de Metropolis-Hastings. A da linguagem utilizada é independente da plataforma e existem bibliotecas para R (`rstan`) e Python.

https://mc-stan.org/


$~$

**Voltando ao Exemplo**

```{r}
library(rstan)
# Parametros do método
Initial.Values <- c(beta_est,sigma_est)
burnin <- 2000
thin <- 3
N=(2000+burnin)*thin
# Conjunto de dados
stan_data <- list(N = n, J = p, y = y, x = X)

# Especificação do modelo 
rs_code <- '
  data {
    int<lower=1> N;
    int<lower=1> J;
    matrix[N,J] x;
    vector[N] y;
  }
  parameters {
    vector[J] beta;
    real<lower=0> sigma2;
  }
  model {
    sigma2 ~ inv_gamma(3, 100);
    beta ~ normal(0, sqrt(sigma2*100));
    y ~ normal(x * beta, sqrt(sigma2));
}'

stan_mod <- stan(model_code = rs_code, data = stan_data, init=Initial.Values,
            chains = 1, iter = N, warmup = burnin, thin = thin)
```

```{r}
posterior <- extract(stan_mod)
Post4 <- data.frame(posterior$beta[,1],posterior$beta[,2],posterior$sigma2,Algorithm="4.RStan")
colnames(Post4) <- c("beta1","beta2","sigma2","Algorithm")

# gráficos posterioris marginais
Post <- rbind(Post3,Post4) %>%
  mutate(Algorithm=ifelse(Algorithm=="3.AFSS","1.LaplacesDemons","2.RStan"))
b1plot <- ggplot(Post) + 
  stat_function(aes(colour="0.Posterior"), fun = mnormt::dmt,args = list(mean = beta1[1], S = V[1,1], df=2*a1)) +
  geom_density(aes(beta1, colour = Algorithm)) + theme_bw() +
  xlab(expression(beta[1])) + ylab("Posterior") + labs(colour = "Method")
b2plot <- ggplot(Post) + 
  stat_function(aes(colour="0.Posterior"), fun = mnormt::dmt, args = list(mean = beta1[2], S = V[2,2], df=2*a1)) +
  geom_density(aes(beta2, colour = Algorithm)) + theme_bw() +
  xlab(expression(beta[2])) + ylab("Posterior") + labs(colour = "Method")
s2plot <- ggplot(Post)+ 
  stat_function(aes(colour="0.Posterior"), fun = extraDistr::dinvgamma, args = list(alpha = a1, beta = b1)) +
  geom_density(aes(sigma2, colour = Algorithm)) + theme_bw() +
  xlab(expression(sigma^2)) + ylab("Posterior") + labs(colour = "Method")
multiplot(b1plot,b2plot,s2plot)
```

```{r}
Post = rbind(Post0,Post4) %>% 
  mutate(Algorithm=ifelse(Algorithm=="4.RStan","1.RStan","0.Posterior"))
ggplot(Post) + theme_bw() +
  geom_point(aes(beta1,beta2,colour=Algorithm), shape=1) + 
  facet_wrap(Algorithm ~ .)
```




$~$

```{r}
stan_mod2 <- stan(model_code = rs_code, data = stan_data, init=Initial.Values,
            chains = 2, iter = N, warmup = burnin, thin = thin)
library(ggmcmc)
#ggs(stan_mod2) %>% ggmcmc(., file = "ggmcmc.html")
```

$~$

[**Gráficos ggmcmc**](ggmcmc.html)

$~$

```{r}
ggs(stan_mod2) %>% ggs_pairs(., lower = list(continuous = "density"))
```


$~$

$~$

<!-- <!-- https://datascienceplus.com/bayesian-regression-with-stan-part-1-normal-regression/ -->


### Aplicações

#### MLG


O modelos lineares generalizados (MLG) são uma extensão natural dos modelos lineares para casos em que a distribuição da variável resposta não é normal. Como exemplo, vamos considerar o particular caso onde a resposta é binária, conhecido como *regressão logística*. 

Considere $Y_1,\ldots,Y_n$ condicionalmente independentes tais que $Y_i|\theta_i \sim \textit{Ber}(\theta_i)$, em que $\theta_i$ é tal que $\log\left(\dfrac{\theta_i}{1-\theta_i}\right) = \boldsymbol x_i' \boldsymbol\beta$ ou, em outras palavras, $\theta_i = \dfrac{1}{1+e^{\boldsymbol x_i' \boldsymbol\beta}} = \dfrac{e^{-\boldsymbol x_i' \boldsymbol\beta}}{1+e^{-\boldsymbol x_i' \boldsymbol\beta}}$ com $\boldsymbol x_i$ as covariáveis da $i$-ésima observação e o vetor de parâmetros $\boldsymbol\beta=(\beta_1,\ldots,\beta_p)$. 

$~$

**Exemplo.** Considere as variáveis *vs* (0 = motor em forma de V, 1 = motor reto) e *mpg* (milhas/galão(EUA)) do conjunto de dados `mtcars` do R. Suponha um modelo de regressão logística para a variável resposta *vs* com a covariável *mpg* em que, a priori, $\beta_i \sim \textit{Laplace}(0,b_i)$, $i=1,2$, independentes. Deste modo, a posteriori é dada por  

$f(\boldsymbol\beta | \boldsymbol{y},\boldsymbol{x})$ 
$\propto f(\boldsymbol{y}|\boldsymbol\beta,\boldsymbol{x})f(\boldsymbol\beta)$ 
$\propto \displaystyle\prod_{i=1}^{n} \left(\dfrac{1}{1+e^{\boldsymbol x_i' \boldsymbol\beta}}\right)^{y_i}\left(\dfrac{e^{\boldsymbol x_i' \boldsymbol\beta}}{1+e^{\boldsymbol x_i' \boldsymbol\beta}}\right)^{1-y_i} \prod_{j=1}^{p} \dfrac{1}{2b_i} e^{-\frac{|\beta_i|}{b_i}}$. 


```{r}
library(rstan)

dados <- as_tibble(mtcars) 
# mpg:	Miles/(US)gallon ;  vs: Engine(0=V-shaped,1=straight)
dados %>% ggplot(aes(group=as.factor(vs),y=mpg,fill=as.factor(vs))) +
        geom_boxplot() + scale_fill_discrete(name="vs") + theme_bw()

y <- dados %>% select(vs) %>% pull()
x <- dados %>% select(mpg) %>% pull()
n <- length(y)
X <- as.matrix(cbind(1,x))
p <- ncol(X)

stan_data <- list(N = n, J = p, y = y, x = X)

rs_code <- '
  data {
    int<lower=1> N;
    int<lower=1> J;
    int<lower=0,upper=1> y[N];
    matrix[N,J] x;
  }
  parameters {
    vector[J] beta;
  }
  model {
    beta ~ double_exponential(0, 100);
    y ~ bernoulli_logit(x * beta);
  }'

N=2000
thin=10
burnin=1000

stan_log <- stan(model_code = rs_code, data = stan_data, init = c(0,0),
  chains = 1, iter = N*thin, warmup = burnin, thin = thin)

print(stan_log)

library(bayesplot)

post_log <- extract(stan_log, inc_warmup = TRUE, permuted = FALSE)

color_scheme_set("mix-brightblue-gray")
mcmc_trace(post_log,  pars = c("beta[1]", "beta[2]"), n_warmup = 0,
                facet_args = list(nrow = 2, labeller = label_parsed))

mcmc_acf(post_log, pars = c("beta[1]", "beta[2]"))

mcmc_areas(post_log,pars = c("beta[1]", "beta[2]"),prob=0.9)

multiplot(mcmc_areas(post_log,pars = c("beta[1]"),prob=0.9), 
          mcmc_areas(post_log,pars = c("beta[2]"),prob=0.9))

library(ggmcmc)
#ggs(stan_log) %>% ggmcmc(., file = "ggmcmc_log.html")
ggs(stan_log) %>% ggs_pairs(., lower = list(continuous = "density"))
```
<!-- [**Gráficos ggmcmc**](ggmcmc_log.html) -->


$~$

* Existe uma biblioteca para modelos lineares bayesianos usando o Stan chamada `rstanarm`. Nesta biblioteca, a função `stan_glm` pode ser utilizada para o ajuste de MLGs sob o ponto de vista bayesiano.

  - https://cran.r-project.org/web/packages/rstanarm/

  
$~$

$~$


### Biblioteca **walker** para Modelos Dinâmicos

* Bilbioteca do R que usa o RStan para fazer inferência bayesiana em modelos lineares com coeficientes variando no tempo (modelos dinâmicos).

* Modelo de Regressão Dinâmico Bayesiano

$$y_t = \boldsymbol x_t~\boldsymbol\beta_t + \epsilon_t ~,~~ \epsilon_t \sim \textit{Normal}(0,\sigma_y^2)$$  
$$\boldsymbol\beta_{t+1} = \boldsymbol\beta_t + \boldsymbol\eta_t ~,~~ \boldsymbol\eta_t \sim \textit{Normal}_k(0,D)$$  

onde  

  - $y_t$: variável resposta no instante $t$;  
  
  - $\boldsymbol x_t$: vetor com $k$ variáveis preditoras no instante $t$;  
  
  - $\epsilon_t$ e $\boldsymbol\eta_t$: ruídos brancos;  
  
  - $\boldsymbol\beta_t$: vetor dos $k$ coeficientes de regressão no instante $t$;  
  
  - $D=\textit{diag}({\sigma}_{\eta_i})$;  
  
  - $\boldsymbol\sigma=\left(\sigma_y,{\sigma}_{\eta_1},\ldots,{\sigma}_{\eta_k}\right)$: vetor de parâmetros de variância.  

As distribuição a piori são dadas por  
$$\beta_1 \sim \textit{Normal}(m_\beta,{s}_\beta^2)$$  
$$\sigma_i^2 \sim \textit{NormalTrunc}({m}_{\sigma_i},{s}_{\sigma_i}^2)$$  

* Sobre a biblioteca `walker`:  
  - https://cran.r-project.org/web/packages/walker/vignettes/walker.html  
  - https://rdrr.io/cran/walker/man/walker.html  
$~$  

#### Dados de Covid-19

* Dados de Covid-19: https://brasil.io/  

* Dados de Mobilidade: https://www.google.com/covid19/mobility/  

* Agradeço à *Renata Massami Hirota* pela compilação dos dados!  

```{r}
dados = read_csv("G:/Meu Drive/Lenovo Ideapad 310/IME - Disciplinas/2020-1_MAE-0524/Aulas_MAE0524-2020/RMD/covid_sp.csv") %>% 
  arrange(date)
#names(dados) 
#[12] "retail_and_recreation_percent_change_from_baseline"
#[13] "grocery_and_pharmacy_percent_change_from_baseline" 
#[14] "parks_percent_change_from_baseline"                
#[15] "transit_stations_percent_change_from_baseline"     
#[16] "workplaces_percent_change_from_baseline"           
#[17] "residential_percent_change_from_baseline" 
ds =  dados %>% 
  mutate(y=confirmed_per_100k_inhabitants/10,x1=retail_and_recreation_percent_change_from_baseline,x2=grocery_and_pharmacy_percent_change_from_baseline,x3=parks_percent_change_from_baseline,x4=dados$transit_stations_percent_change_from_baseline,x5=workplaces_percent_change_from_baseline, x6=residential_percent_change_from_baseline, t=date) %>% 
  arrange(date) %>% 
  select(t,y,x1,x2,x3,x4,x5,x6) %>% 
  filter(t>="2020-03-23") %>% # uma semana após início da quarentena
  mutate(x=x6-x3-x4)          # "taxa de isolamento" (inventei!)
FS=(max(ds$y)-min(ds$y))/(max(ds$x)-min(ds$x)) # aux para eixo secundário
ggplot(ds, aes(x = t)) + theme_bw() + 
  geom_line(aes(y = y, colour = "Mortes/Milhão Hab.")) +
  geom_line(aes(y = (x-min(x))*FS+min(y), colour = "Taxa de Isolamento")) +
  scale_y_continuous(sec.axis = sec_axis(~./FS-min(ds$y)/FS+min(ds$x), name = "Taxa de Isolamento")) +
  labs(y="Mortes/Milhão Hab.",colour="") + theme(legend.position = "bottom")
```

```{r}
library(walker)
ds = ds %>% filter(t>="2020-03-23")
fit1 <- ds %>% mutate(x=x-mean(x),y=y-mean(y)) %>% 
  walker(data=., formula = y ~ 1+rw1(~ -1+x,beta=c(0,100), sigma=c(0,100)), 
    beta=c(0,100),sigma_y_prior = c(0,100), chain=1)
        #Default: chain=4, iter=2000, warmup=1000, thin=1

multiplot(
  mcmc_areas(as.matrix(fit1$stanfit), regex_pars = c("beta_fixed"), prob=0.9),
  mcmc_areas(as.matrix(fit1$stanfit), regex_pars = c("sigma_rw1"), prob=0.9),
  mcmc_areas(as.matrix(fit1$stanfit), regex_pars = c("sigma_y"), prob=0.9))

plot_coefs(fit1, scales = "free", alpha=0.8) + theme_bw() +
  scale_x_continuous(breaks=c(1,16,46,77,107),labels=c("mar","abr","mai","jun","jul"))

pp_check(fit1, alpha=0.8) + theme_bw() +
  scale_x_continuous(breaks=c(1,16,46,77,107),labels=c("mar","abr","mai","jun","jul"))

new_data <- data.frame(x=seq(-28,0,length.out=10))
pred1 <- predict(fit1, new_data)
plot_predict(pred1, alpha=0.8) + 
  scale_x_continuous(breaks=c(1,16,46,77,107),labels=c("mar","abr","mai","jun","jul"))

new_data <- data.frame(x=seq(-28,-56,length.out=10))
pred1 <- predict(fit1, new_data)
plot_predict(pred1, alpha=0.8) +
  scale_x_continuous(breaks=c(1,16,46,77,107),labels=c("mar","abr","mai","jun","jul"))
```

#### Extensões: Efeitos mais suaves e modelos não gaussianos

Ao modelar os coeficientes de regressão como uma passeio aleatório simples, as estimativas posteriores desses coeficientes podem ter grandes variações de curto prazo que podem não ser realistas na prática. Uma maneira de impor mais suavidade às estimativas é alternar dos coeficientes do passeio aleatório para coeficientes de passeio aleatório de segunda ordem integrados:
$$\boldsymbol\beta_{t+1} = \boldsymbol\beta_t + \boldsymbol\nu_t$$  
$$\boldsymbol\nu_{t+1} = \boldsymbol\nu_t + \boldsymbol\eta_t ~,~~ \boldsymbol\eta_t \sim \textit{Normal}_k(0,D)$$  


```{r}
fit2 <- ds %>% mutate(x=x-mean(x),y=y-mean(y)) %>%  
  walker(data=., formula = y ~ rw2(~ -1+x, beta=c(0,100), sigma=c(0,100),
        nu=c(0,100)), beta=c(0,100),sigma_y_prior=c(0,100), chain=1)
        #Default: chain=4, iter=2000, warmup=1000, thin=1

multiplot(
  mcmc_areas(as.matrix(fit2$stanfit), regex_pars = c("beta_fixed"), prob=0.9),
  mcmc_areas(as.matrix(fit2$stanfit), regex_pars = c("sigma_rw2"), prob=0.9),
  mcmc_areas(as.matrix(fit2$stanfit), regex_pars = c("sigma_y"), prob=0.9))

plot_coefs(fit2, scales = "free", alpha=0.8) + theme_bw() +
  scale_x_continuous(breaks=c(1,16,46,77,107),labels=c("mar","abr","mai","jun","jul"))

pp_check(fit2, alpha=0.8) + theme_bw() +
  scale_x_continuous(breaks=c(1,16,46,77,107),labels=c("mar","abr","mai","jun","jul"))

new_data <- data.frame(x=seq(-28,0,length.out=10))
pred2 <- predict(fit2, new_data)
plot_predict(pred2, alpha=0.8) + 
  scale_x_continuous(breaks=c(1,16,46,77,107),labels=c("mar","abr","mai","jun","jul"))

new_data <- data.frame(x=seq(-28,-56,length.out=10))
pred2 <- predict(fit2, new_data)
plot_predict(pred2, alpha=0.8) + 
  scale_x_continuous(breaks=c(1,16,46,77,107),labels=c("mar","abr","mai","jun","jul"))
```
$~$  

* A função `walker_glm` estende o pacote para lidar com observações de com distribuição de *Poisson* e *Binomial*, usando a metodologia similar à mencionada acima.  

$~$  

$~$  
