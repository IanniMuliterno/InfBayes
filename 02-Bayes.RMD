# Introdução à Inferência Bayesiana {#Bayes}

## Conceitos Básicos {#BasBayes}

* **Inferência Estatística:** fazer afirmações sobre quantidades não observáveis em um determinado contexto.

* $\theta$ : **parâmetro** - quantidade desconhecida de interesse (não-observável em determinado contexto). 

* $\Theta$ : **espaço paramétrico** - conjunto onde $\theta$ toma valores (supostamente conhecido).

* $E=\left(\boldsymbol X, \theta, \left\{f(\boldsymbol x|\theta)\right\}\right)$: **experimento** - "*tornar visível algo que antes era invisível*" ou, mais especificamente no nosso contexto, observar uma realização $\boldsymbol x \in \mathfrak{X}$ de um vetor aleatório $\boldsymbol X$ com alguma distribuição $f(\boldsymbol x|\theta)$. Essa distribuição pertence, na maioria dos casos, à uma família de distribuições fixada mas que depende do parâmetro desconhecido de interesse $\theta$. Note que na grande maioria dos problemas do dia a dia de um estatístico ele se utiliza de resultados experimentais para fazer afirmações sobre $\theta$ e este, por sua vez, é não-observável em geral.

* $\mathfrak{X}$ : **espaço amostral** - conjunto onde $\boldsymbol X$ toma valores (supostamente conhecido).

* $\mathcal{F}$ : $\sigma$-álgebra de (sub)conjuntos de $\mathfrak{X}$.

* Neste espaço amostral, defini-se uma família $\mathcal{P}=\{P(\cdot|\theta): \theta \in \Theta\}$, isto é, um conjunto de distribuições (condicionais) para $\boldsymbol X$ indexadas por $\theta$.  

* $(\mathfrak{X},\mathcal{F},\mathcal{P})$ : modelo estatístico (clássico).

* $V_x(\theta)=f(\boldsymbol x |\theta)$ : função de verossimilhança.

$~$ 

### Inferência Frequentista (ou Clássica)

* $\theta$ é considerado fixo (apesar de desconhecido) e, portanto, não recebe uma distribuição de probabilidade.

* Baseia-se no " princípio" da amostragem repetida (interpretação frequentista de probabilidade), isto é, supõe que é possivel realizar infinitas vezes o experimento. Assim, o $\boldsymbol x$ é apenas um dos possiveis resultados (hipóteticos) do experimento.

* Probabilidade somente é definida em (uma $\sigma-álgebra$ de) $\mathfrak{X}$.

### Inferência Bayesiana 

* Baseia-se na interpretação subjetivista de probabilidade, de modo que a *SUA* incerteza sobre algo desconhecido deve ser quantificada (traduzida) em termos de probabilidade.

* Assim, *SUA* incerteza sobre o parâmetro (desconhecido) é representada por uma distribuição de probabilidade, $\theta$ é tratado como uma variável aleatória (v.a.) e *SUA* distribuição para $\theta$ antes da realização do experimento, $f(\theta),$ é chamada de **distribuição a priori**. Note que a atribuição de uma distribuição a prior para $\theta$ independe da natureza do parâmetro, ele pode ser a proporção de indivíduos que avalia positivamente o governo atual (quantidade essa que muda a todo instante) ou ainda a milésima casa do $\pi$ (algum número de 0 a 9, fixo porém desconhecido no momento dessa leitura).

* A atualização de *SUA* incerteza sobre $\theta,$ incorporando uma nova informação trazida pelos dados $\boldsymbol x$ (representada por $f(\boldsymbol x| \theta)$) é feita pelo *Teorema de Bayes*:

* **Teorema de Bayes:**

$$\underbrace{f(\theta| \boldsymbol x)}_{dist. posteriori}=~~\dfrac{f(\theta)f(\boldsymbol x|\theta)}{\displaystyle \int_{\Theta}f(\boldsymbol x|\theta)dP_\theta} ~\propto~ \underbrace{f(\theta)}_{priori}\overbrace{f(\boldsymbol x|\theta)}^{verossimilhança}.$$

<!-- $$\underbrace{f(\theta| \boldsymbol x)}_{dist. posteriori} = \dfrac{f(\boldsymbol{x}| \theta)}{\int_{\Theta}f(\boldsymbol x|\theta)dP_\theta} \propto f(\boldsymbol x|\theta).$$ -->

* Toda a inferência sobre $\theta$ será baseada exclusivamente em $f(\theta| \boldsymbol x)$, não sendo necessário considerar pontos amostrais que poderiam mas não foram observados (como é feito na inferência frequentista).

$~$

* **Observação:** será utilizada a notação geral para integral (de Lebesgue): $$\displaystyle \int_{\Theta}f(\boldsymbol x|\theta)dP_\theta
= \left\{ \begin{array}{ll} \displaystyle \int_{\Theta}f(\boldsymbol x|\theta) f(\theta) d\theta ~&~ (caso~~contínuo)\\
\displaystyle \sum_{\Theta}f(\boldsymbol x|\theta) f(\theta) ~&~ (caso~~discreto) \end{array}\right.$$  

$~$

**Exemplo 1.a:** Suponha que existem duas moedas, uma delas tem $\theta =1/2$ (honesta) e a outra $\theta=3/4$ (viesada). Uma moeda é escolhida e é feito um lançamento da moeda selecionada. Nesse experimento, tem-se $X|\theta \sim Ber(\theta)$, com $\Theta=\{1/2,3/4\}$ e $\mathfrak{X}=\{0,1\}$. Como "chutar" o valor de $\theta$?  

Considere que não existe razão para você acreditar que há algum tipo de preferência na escolha de uma ou outra moeda, isto é, considere que a priori $f(\theta=1/2)$ $=f(\theta=3/4)$ $=1/2$. Suponha que o lançamento resultou em cara ($x=1$). Então  

$f(\theta = 3/4|X=1)$ $=\dfrac{f(X=1|\theta=3/4)f(\theta=3/4)}{\sum_\theta f(X=1|\theta)f(\theta)}$ $=\dfrac{\dfrac{3}{4}\dfrac{1}{2}}{\dfrac{3}{4}~\dfrac{1}{2}+\dfrac{1}{2}~\dfrac{1}{2}}=$ $\dfrac{3/4}{5/4}=\dfrac{3}{5}$ $= 1-\underbrace{f(\theta=1/2|X=1)}_{2/5}$. 

Se, no entando, o resultado do lançamento da moeda fosse coroa ($x=0$), teríamos

$P(\theta=3/4|X=0)$ $=\dfrac{\dfrac{1}{4}~\dfrac{1}{2}}{\dfrac{1}{4}~\dfrac{1}{2}+\dfrac{1}{2}~\dfrac{1}{2}}$ $=\dfrac{1/2}{1/2+2/2}=\dfrac{1}{3}$.

```{r, echo=FALSE, include=knitr::is_latex_output()}
theta = c(0.5,0.75)
prior=0.5 # priori P(theta[1]) = 1-P(theta[2])
n=1;
post = function(x){ 
  (prior * dbinom(x,n,theta)) / sum(prior * dbinom(x,n,theta)) }
tibble(x=as.factor(rep(seq(0,n),each=length(theta))),
       x1=rep(theta,(n+1)),x2=rep(theta,(n+1)),y1=0,
       y2=as.vector(apply(matrix(seq(0,n)),1,post))) %>% 
  ggplot() + geom_hline(yintercept = 0.5, col="darkgrey", lty=3) +
  geom_segment(aes(x=x1,xend=x2,y=y1,yend=y2,colour=x),lwd=2) +
  xlab(expression(theta)) + ylab(expression(paste("P(",theta,"|x)"))) +
  theme_bw()+
  facet_wrap(~x)
```

```{r, echo=FALSE, include=!knitr::is_latex_output()}
theta = c(0.5,0.75)
prior=0.5 # priori P(theta[1]) = 1-P(theta[2])
n=1;
post = function(x){ 
  (prior*dbinom(x,n,theta)) / sum(prior * dbinom(x,n,theta)) }
tibble(x=as.factor(rep(seq(0,n),each=length(theta))),
    x1=rep(theta,(n+1)),x2=rep(theta,(n+1)),y1=0,
    y2=as.vector(apply(matrix(seq(0,n)),1,post))) %>% 
  ggplot() + geom_hline(yintercept=0.5,col="darkgrey",lty=3) +
  geom_segment(aes(x=x1,xend=x2,y=y1,yend=y2,colour=x),lwd=2) + 
    xlab(expression(theta)) + ylab(expression(paste("P(",theta,"|x)"))) + 
  theme_bw() +  
  gganimate::transition_states(x)
```
Assim, se sua decisão for escolher o valor mais provável de $\theta$ após observar $x$, a conclusão seria que a moeda é viesada $(\theta=3/4)$ se for observado cara $(x=1)$ e que a moeda é honesta $(\theta=1/2)$ se o resultado for coroa $(x=0)$.

$~$ 

**Exemplo 1.b:** Considere agora que serão realizados $n$ lançamentos da moeda, de modo que agora tem-se $X|\theta \sim Bin(n,\theta)$, $\theta \in \{1/2,3/4\}$, $x \in \{0,1,\ldots,n\}$. Suponha que observa-se $X=x$.

$f(\theta=3/4|X=x)$ $=\dfrac{f(x|\theta=3/4)f(\theta=3/4)}{\displaystyle \sum_{\theta\in \{1/2,3/4\}}f(x|\theta)f(\theta)}$ $=\dfrac{\displaystyle \binom{n}{x}\left(\dfrac{3}{4}\right)^x\left(\dfrac{1}{4}\right)^{n-x}\dfrac{1}{2}}{\displaystyle \binom{n}{x}\left(\dfrac{3}{4}\right)^x\left(\dfrac{1}{4}\right)^{n-x}\dfrac{1}{2}+\displaystyle\binom{n}{x}\left(\dfrac{1}{2}\right)^x\left(\dfrac{1}{2}\right)^{n-x}\dfrac{1}{2}}$ $=\dfrac{1}{1+\left(\dfrac{2^n}{3^x}\right)}$ $=\dfrac{3^x}{3^x + 2^n}$.


```{r, include=knitr::is_latex_output()}
theta = c(0.5,0.75)
prior=0.5 # priori P(theta[1]) = 1-P(theta[2])
n=5;
post = function(x){ 
  (prior*dbinom(x,n,theta)) / sum(prior * dbinom(x,n,theta)) }
tibble(x=as.factor(rep(seq(0,n),each=length(theta))),
    x1=rep(theta,(n+1)),x2=rep(theta,(n+1)),y1=0,
    y2=as.vector(apply(matrix(seq(0,n)),1,post))) %>% 
  ggplot() + geom_hline(yintercept=0.5, col="darkgrey",lty=3) +
  geom_segment(aes(x=x1,xend=x2,y=y1,yend=y2,colour=x),lwd=2) + 
  xlab(expression(theta)) + ylab(expression(paste("P(",theta,"|x)"))) +
  theme_bw()+
  facet_wrap(~x)
```

```{r, include=!knitr::is_latex_output()}  
theta = c(0.5,0.75)
prior=0.5 # priori P(theta[1]) = 1-P(theta[2])
n=5;
post = function(x){ 
  (prior*dbinom(x,n,theta)) / sum(prior * dbinom(x,n,theta)) }
tibble(x=as.factor(rep(seq(0,n),each=length(theta))),
    x1=rep(theta,(n+1)),x2=rep(theta,(n+1)),y1=0,
    y2=as.vector(apply(matrix(seq(0,n)),1,post))) %>% 
  ggplot() + geom_hline(yintercept=0.5,col="darkgrey",lty=3) +
  geom_segment(aes(x=x1, xend=x2, y=y1,yend=y2,colour=x),lwd=2) + 
  xlab(expression(theta)) + ylab(expression(paste("P(",theta,"|x)"))) +   
  theme_bw()+
  gganimate::transition_states(x)
```

$~$ 

Note que o Exemplo 1.a é um caso particular desse exemplo com $n=1$. Se novamente sua decisão é baseada no valor mais provável de $\theta$, temos

$f(\theta=3/4|X=x) > \dfrac{1}{2}$ $\Longleftrightarrow \dfrac{3^x}{3^x + 2^n} > \dfrac{1}{2}$ $\Longleftrightarrow {3^x} > {2^n}$ $\Longleftrightarrow \dfrac{x}{n} = \bar{x} > \log_3{2}\approx 0,63$.

$~$ 

**Exemplo 1.c:** Considere que uma moeda será lançada $n$ vezes mas que $\theta$ é desconhecido, de modo que $\Theta = [0,1]$. Para simplificar, vamos assumir $f(\theta)=\mathbb{I}_{[0,1]}(\theta)$, isto é, $\theta \sim Unif(0,1)\sim Beta(1,1)$. Essa priori corresponde ao caso em que você acredita que todos os valores possíveis para $\theta$ são igualmente "prováveis", assim como nos exemplos anteriores. Novamente, $X|\theta \sim Bin(n,\theta)$

$f(\theta|x)=$ $\dfrac{f(x|\theta)f(\theta)}{\int_0^1 f(x|\theta)f(\theta)d\theta}=$ $\dfrac{\binom{n}{x}\theta^x(1-\theta)^{n-x} ~~\mathbb{I}_{[0,1]}(\theta)}{\int_0^1\binom{n}{x}\theta^x(1-\theta)^{n-x}d\theta}=$ $\dfrac{\dfrac{\Gamma(1+x+1+n-x)}{\Gamma(1+x)\Gamma(1+n-x)}~~\theta^x(1-\theta)^{n-x}~~\mathbb{I}_{[0,1]}(\theta)}{\underbrace{\displaystyle \int_0^1\dfrac{\Gamma(1+x+1+n-x)}{\Gamma(1+x)\Gamma(1+n-x)}~~\theta^x(1-\theta)^{n-x}d\theta}_{1}}$ $=\dfrac{\Gamma(1+x+1+n-x)}{\Gamma(1+x)\Gamma(1+n-x)}~~\theta^x(1-\theta)^{n-x}~~\mathbb{I}_{[0,1]}(\theta)$.

$~$ 

Logo $\theta|x \sim Beta(1+x,1+n-x)$. Nesse exemplo, o valor "mais provável" (com maior densidade a posteriori) para $\theta$ é a moda da distribuição, $Moda(\theta|x)$ $= \dfrac{(1+x)-1}{(1+x)+(1+n-x)-2}$ $= \dfrac{x}{n}$ $=\bar{x}$.

$~$

**Exemplo 1.d** Por fim, suponha que no exemplo anterior, sua opinião a priori é representada por uma distribuição beta qualquer com parâmetros $a$ e $b$, $a,b > 0$. Desta forma, $X|\theta \sim Bin(n,\theta)$ e $\theta\sim Beta(a,b)$. Calculando a distribuição a posteriori de forma similar ao exemplo anterior, temos que $\theta|X=x \sim Beta(a+x,b+n-x)$.

$~$ 

```{r, include=knitr::is_latex_output()}  
theta = seq(0,1,0.01)
a=1; b=1;
n=5
post1 = as.vector(apply(matrix(seq(0,n)),1,
            function(x){dbeta(theta,a+x,b+n-x)}))
tibble(x=as.factor(rep(seq(0,n),each=length(theta))),
    theta=rep(theta,(n+1)),post=post1) %>% 
  ggplot() + 
  geom_line(aes(x=theta,y=post, colour=x),lwd=1.5) + 
  geom_line(aes(x=theta,y=dbeta(theta,a,b),colour="Prior"),lwd=1,lty=2) + 
  xlab(expression(theta)) + ylab(expression(paste("f(",theta,"|x)"))) +
  theme_bw()+
  facet_wrap(~x)
```

```{r, include=!knitr::is_latex_output()}    
require(transformr)
theta = seq(0,1,0.01)
a=1; b=1;
n=5
post1 = as.vector(apply(matrix(seq(0,n)),1,
            function(x){dbeta(theta,a+x,b+n-x)}))
tibble(x=as.factor(rep(seq(0,n),each=length(theta))),
    theta=rep(theta,(n+1)),post=post1) %>% 
  ggplot() + 
  geom_line(aes(x=theta,y=post, colour=x),lwd=1.5) + 
  geom_line(aes(x=theta,y=dbeta(theta,a,b),colour="Prior"),lwd=1,lty=2) + 
  xlab(expression(theta)) + ylab(expression(paste("f(",theta,"|x)"))) +
  theme_bw()+
  gganimate::transition_states(x)
```

$~$ 

Suponha que $a=b=1$ (como no exemplo anterior), $n=5$ e $x=2$, de modo que $\theta|x=2 \sim Beta(3,4)$. Algumas medidas resumo da distribuição posterior para esse exemplo são

+ $Moda(\theta|x)$ $=\dfrac{a+x-1}{a+b+n-2}$ $=\dfrac{2}{5}$ $=0,4$;  

+ $E[\theta|x]$ $=\dfrac{a+x}{a+b+n}$ $=\dfrac{3}{7}$ $=0,43$;  

+ $Med(\theta|x)$ $\approx \dfrac{a+x-1/3}{a+b+n-2/3}$ $=\dfrac{8/3}{19/3}$ $\approx 0,42$;  

+ $Var(\theta|x)$ $=\dfrac{(a+x)(b+n-x)}{(a+b+n)^2(a+b+n+1)}$ $=\dfrac{12}{392}$ $\approx 0,031$.  

$~$ 

## Suficiência

Muitas vezes, a quantidade de dados é muito grande e desejamos "resumir" a informação trazida pelos dados. Uma forma de fazê-lo sem perder informação sobre o parâmetro de interesse é usar uma *estatística suficiente*.

$~$

**Definição:** Dizemos que uma função da amostra $T:\mathfrak{X} \rightarrow \mathbb{R}^p$ é uma *estatística suficiente* (do ponto de vista *frequentista*) se $f\left(\boldsymbol x | T(\boldsymbol x),\theta\right) = f\left(\boldsymbol x | T(\boldsymbol x)\right)$. 

$~$

Em palavras, conhecendo o valor da estatística suficiente, a distribuição da amostra (do v.a. $\boldsymbol X$) não depende mais do parâmetro $\theta$. Isso quer dizer que a informação disponível na amostra $\boldsymbol X$ sobre $\theta$ está contida em $T(\boldsymbol X)$. Obter uma estatística suficiente nem sempre é uma tarefa fácil mas o resultado a seguir, conhecido como *critério da fatoração* permite identificar estatísticas suficientes.

$~$

**Teorema:** A estatística $T:\mathfrak{X} \rightarrow \mathbb{R}^p$ é suficiente para a família de distribuições $\left\{f(\cdot|\theta):\theta \in \Theta\right\}$ se, e somente se, para todo $x \in \mathfrak{X}$ e para todo $\theta \in \Theta$, podemos escrever $f\left(\boldsymbol x | \theta\right)$ $= u(\boldsymbol x) v\left(T(\boldsymbol x),\theta\right)$, onde $u$ é uma função positiva que não depende de $\theta$ e $v$ é uma função não-negativa e depende de $\boldsymbol x$ somente através de $T(\boldsymbol x)$.

$~$

**Exemplo:** Seja $X_1,\ldots,X_n$ v.a. tais que, condicional ao conhecimento de $\theta$, são c.i.i.d. com $X_1|\theta \sim Exp(\theta)$. Então,

$f(\boldsymbol x|\theta)$ $=\prod f(x_i|\theta)$ $=\prod \theta e^{-\theta x_i} ~\mathbb{I}_{\mathbb{R+}}(x_i)$ $=\theta^n e^{-\theta \sum x_i} ~\prod ~\mathbb{I}_{\mathbb{R+}}(x_i)$ $= v\left(\sum x_i, \theta\right) u(\boldsymbol x)$.

Portanto, $T(\boldsymbol x) = \sum x_i$ é estatística suficiente para $\theta$. De fato, como $T(\boldsymbol X)$ $= \sum X_i | \theta$ $\sim Gama(n,\theta)$ e $\left\{X_1=x_1,\ldots,X_n=x_n\right\}$ $\subseteq \left\{T(\boldsymbol X) = \sum X_i = \sum x_i = t\right\}$,

$f\left(\boldsymbol x| T(\boldsymbol x),\theta\right)$ $=\dfrac{f\left(\boldsymbol{x},T(\boldsymbol{x})|\theta\right)}{f\left(T(\boldsymbol{x})|\theta\right)}$ $=\dfrac{f\left(\boldsymbol{x}|\theta\right)}{f\left(\sum{X_i}|\theta\right)}$ $=\dfrac{\theta^n e^{\theta \sum x_i} ~\prod ~\mathbb{I}_{\mathbb{R+}}(x_i)}{\frac{\theta^n}{\Gamma(n)}t^{n-1} e^{\theta t} ~\prod ~\mathbb{I}_{\mathbb{R+}}(x_i)}$ $= \dfrac{\Gamma(n)}{t^{n-1}} ~\mathbb{I}_{\mathbb{R}_+}\left(t\right)$, 

que não depende de $\theta$.

$~$

Sob o enfoque bayesiano, a definição de suficiência é um pouco mais intuitiva que a frequentista. 

**Definição:** Dizemos que uma função da amostra $T:\mathfrak{X} \rightarrow \mathbb{R}^p$ é uma *estatística suficiente* (no sentido *bayesiano*) se $f\left(\theta | T(\boldsymbol x)\right) = f\left(\theta | \boldsymbol x\right)$, para todo $x \in \mathfrak{X}$. 

$~$

Voltando ao exemplo, suponha agora que, a priori, $\theta \sim Gama(a,b)$. Então,

$f(\theta| \boldsymbol x)$ $\propto f(\boldsymbol x|\theta)f(\theta)$  $\propto \theta^n e^{-\theta \sum x_i} ~~\theta^{a-1}e^{-b\theta}$ $\propto \theta^{a+n-1} e^{-(b+\sum x_i)\theta}$

Seja $T = T(\boldsymbol X) = \sum X_i$, temos que $T|\theta\sim Gamma(n,\theta)$, de modo que

$f\left(\theta| T(\boldsymbol x)=t\right)$ $\propto f(t|\theta)f(\theta)$  $\propto \theta^n t^{n-1} e^{\theta t} ~~\theta^{a-1}e^{-b\theta}$ $\propto \theta^{a+n-1} e^{-(b+t)\theta}$ , com $t=\sum x_i$.

Assim, $\theta|\boldsymbol x$ $\sim \theta|T(\boldsymbol x)$ $\sim Gamma\left(a+n,b+\sum x_i\right)$ e, portanto, $T(\boldsymbol X) = \sum X_i$ é estatística suficiente para $\theta$.

$~$

Para os casos mais comuns, as definições são equivalentes [@Schervish12]. Pelo teorema da fatoração, temos que $f\left(\boldsymbol x | \theta\right)$ $= u(\boldsymbol x) v\left(T(\boldsymbol x),\theta\right)$ e, portanto

$f(\theta|\boldsymbol x)$ $\propto f(\theta) f\left(\boldsymbol x | \theta\right)$ $\propto f(\theta) v\left(T(\boldsymbol x),\theta\right)$

que só depende de $\boldsymbol x$ por meio de $T(\boldsymbol x)$.

$~$

Um dos princípios de inferência estatística é o *princípio da suficiência*. Segundo este, se $T$ é uma estatística suficiente para $\theta$ e se dois pontos amostrais $\boldsymbol x, \boldsymbol y \in \mathfrak{X}$ são tais que $T(\boldsymbol x)=T(\boldsymbol y)$ então as inferências baseadas nesses pontos devem ser as mesmas. Adiante, retomaremos esse princípio de forma mais formal.

$~$ 


<!-- ## Aula 09  -->

## Distribuição a Priori

+ A priori é sempre subjetiva (assim como a escolha do modelo estatístico)!  
  * Por exemplo, dizer que os dados seguem uma distribuição normal, é uma escolha subjetiva, muitas vezes baseadas nas facilidades matemáticas que essa distribuição proporciona.  
  * Do mesmo modo, suponha que dois indivíduos que consideram que a distribuição do parêmetro é simétrica, com mesmas suposições sobre média e variância. O primeiro pode optar por representar sua distribuição usando uma distribuição Normal, enquanto o segundo pode utilizar uma distribuição T ou Cauchy.  
+  Não existe "opinião errada", existem opiniões diferentes, dado o nível de conhecimento e as experiências prévias do indivíduo.  
+ A priori deve ser sua opinião apenas sobre o parâmetro $\theta$ e não deve depender de fatores como o desenho do experimento ou o objetivo do estudo.


<!-- ### Prioris Baseada na Opinião de um Especialista -->

### Método do Histograma

+ Muitas vezes, para "extrair" o conhecimento de um especialista, podemos dividir o espaço paramétrico em regiões e pedir para o especialista "ordenar" esses conjuntos, utilizando "pesos" que refletem a crença que o parâmetro esteja em cada uma daquelas regiões.

+ **Exemplo 1.** (@Albert09, pág 27)  
  * Seja $\theta$ uma proporção desconhecida $(\Theta=[0,1])$;  
  * Considere a partição $T = \left\{[0,0.1), [0.1,0.2), \ldots, [0.9,1] \right\}$;
  * Suponha que um especialistas atribui pesos $p=(1, 5.2, 8, 7.2, 4.6, 2.1, 0.7, 0.1, 0, 0)$ a esse intervalos;  
  * A piori, nesse caso, é o histograma apresentado a seguir.

```{r}
p=c(1, 5.2, 8, 7.2, 4.6, 2.1, 0.7, 0.1, 0, 0)
prior = c(0,p/(sum(p)))
tibble(theta=seq(0,1,0.1), prior) %>% 
  ggplot(data=.) +
  geom_step(aes(x=theta,y=prior),direction="vh",color="red",lwd=1.5)
```


+ Voltando ao exemplo da moeda, suponha novamente que foram observados $x=2$ sucessos em $n=5$ lançamentos. A posteriori nesse caso pode ser obtida multiplicando a distribuição a priori pela verossimilhança e "padronizando" a função obtida. Assim:


```{r}
n=5
x=2
p = c(1, 5.2, 8, 7.2, 4.6, 2.1, 0.7, 0.1, 0, 0)
p = p/(sum(p))
theta = seq(0,1,0.01)
prior = c(rep(p,each=10),0)/sum(c(rep(p,each=10),0))
vero = dbinom(x,n,theta)/sum(dbinom(x,n,theta))
post = (prior * vero)/sum(prior * vero)
pH = tibble(theta=rep(theta,3),dens=c(prior,vero,post),Dist=rep(c('1.priori','2.verossimilhança','3.posteriori'),each=101)) %>% 
  ggplot(data=.) +
  geom_line(aes(x=theta,y=dens,colour=Dist),lwd=1.5)
pH
```

$~$

### Elicitação de Hiperparâmetros

+ Nessa abordagem, a priori é obtida da seguinte maneira:
  1. Escolha uma família de distribuições conveniente. O conceito de "conveniência" aqui pode levar em conta, por exemplo, o suporte da distribuição, se é flexível o suficiente para acomodar diversos tipos de opinião, se permite a obtenção analítica da posteriori e assim por diante;  
  2. Obtenha um conjunto de medidas resumo (como média, variância, quantis, etc.);  
  3. Utilize as medidas resumo para calcular hiperparâmetros da distribuição escolhida.  

$~$ 

+ **Exemplo:** Na seção anterior, a priori dada pelo histograma tem média $m=0.31$ e variância aproximadamente $v=0.02$. Podemos utilizar como priori, por exemplo, uma distribuição beta com essa média e variância, já que a beta tem um suporte conveniente e facilita as contas, como também já vimos. Assim, vamos considerar uma distribuição $Beta(a,b)$ e escolher $a$ e $b$ satisfazendo:  

  (i) $E[\theta]$ $=\dfrac{a}{a+b}$ $=m$ $\Longleftrightarrow b=\left(\dfrac{1-m}{m}\right)a$
  (ii) $Var(\theta)$ $=\dfrac{ab}{(a+b)^2(a+b+1)}$ $=0.02$ $\Longleftrightarrow a=\dfrac{m(m-m^2-v)}{v}$

Resolvendo o sistema temos, de forma geral, que $a=\dfrac{m(m-m^2-v)}{v}$ e $b=\dfrac{(1-m)(m-m^2-v)}{v}$. 

Assim, no nosso exemplo, teríamos uma $Beta(3,6.7)$. Além disso, já vimos que, nesse caso, a distribuição a posteriori é $Beta(3+x,6.7+n-x)$. Considerando novamente $n=5$ e $x=2$, temos:

```{r}
n=5; x=2
m=0.31; v=0.02
a=m*(m-m^2-v)/v; b=(1-m)*(m-m^2-v)/v
p = c(1, 5.2, 8, 7.2, 4.6, 2.1, 0.7, 0.1, 0, 0)
p = p/(sum(p))
theta = seq(0,1,0.01)
prior = dbeta(theta,a,b)/sum(dbeta(theta,a,b))
vero = dbinom(x,n,theta)/sum(dbinom(x,n,theta))
post = dbeta(theta,a+x,b+n-x)/sum(dbeta(theta,a+x,b+n-x))
priorH = c(rep(p,each=10),0)/sum(c(rep(p,each=10),0))
tibble(theta=rep(theta,4),dens=c(prior,vero,post,priorH),
    Dist=rep(c('1.Priori Beta','2.Verossimilhança','3.Posteriori','0.Priori Histograma'),each=101)) %>% 
  ggplot(data=.) +
  geom_line(aes(x=theta,y=dens,colour=Dist),lwd=1.5)
```


$~$ 

### Prioris Conjugadas

Como visto no exemplo da moeda, em que a distribuição a priori era $Beta(a,b)$, a posteriori era facilmente obtida e também estava na classe das distribuições $Beta$. Em particular, quando observa-se $x$ sucessos em $n$ realizações de ensaios de Bernoulli, a distribuição a posteriori é $Beta(a+x,b+n-x)$. Isso ocorre pois essa distribuição pertence à uma classe bastante espefícica de distribuições a priori, chamadas distribuições conjugadas.

$~$

**Definição** Seja $\mathcal{P}=\{f(x|\theta):\;\theta \in \Theta\}$ uma família de distribuições (condicionais) para $\boldsymbol{X}$ e considere $\mathcal{C}=\{h(\theta|a):\;a\in A\}$ uma família de distribuições para $\theta$. Dizemos que (a família) $\mathcal{C}$ é **conjugada** para $\mathcal{P}$ se, $\forall \;h(\theta)\in \mathcal{C},$  $h(\theta|\boldsymbol{x})\propto f(\boldsymbol x|\theta)h(\theta) \in \mathcal{C},\forall \boldsymbol x \in \mathfrak{X}.$

$~$ 

**Resultado 1.** Seja $X$ v.a. tal que, condicional ao conhecimento de $\theta,$ $X|\theta \sim Bin(n,\theta).$ Considere que, a priori, $\theta \sim Beta(a,b).$ Então, $\theta|X=x \sim Beta(a+x,b+n-x).$ Portanto, a família $\mathcal{C}=\{Beta(a_1,a_2):\;(a_1,a_2)\in \mathbb{R}^2_+\}$ é conjugada para $\mathcal{P}=\{Bin(n,\theta):\;\theta \in [0,1]\}.$

$~$ 

+ Esse resultado também vale se  
  1. $X_1,...,X_n$ são v.a.s *condicionalmente independentes e identicamente distribuidas* (c.i.i.d.) com $X_i|\theta \sim Ber(\theta)$  
  1. $X_i|\theta\sim Geo(\theta),$ $i=1,...,n \; c.i.i.d.$  
  1. $X_i|\theta \sim BinNeg(k,\theta)$  
  $\theta\sim Beta(a,b)\Rightarrow$ $\theta|\boldsymbol X=\boldsymbol x \sim Beta(a+s,b+f)$ em que $s$ é o número de sucessos e $f$ é o número de fracassos.
 
$~$ 

**Resultado 2.** (*generalização do resultado anterior para o caso em que o número de categorias é maior que 2*)  

Seja $\boldsymbol X | \boldsymbol \theta \sim Multinomial(n,\boldsymbol \theta)$, isto é, sua função de probabilidade é dada por

$$f(\boldsymbol x| \boldsymbol \theta)= \binom{n}{x_1,x_2,...,x_k}~\prod_{i=1}^{k-1}\theta^i~\underbrace{\left(1-\sum_{i=1}^{k-1}\theta_i\right)^{\displaystyle n-\sum_{i=1}^{k-1}x_i}}_{\displaystyle \theta_k^{~~x_k}}$$

em que $\theta_i\in [0,1]$ com $\sum_{i=1}^K\theta_i=1$, $x_i \in \{0,1,...,n\}$ com $\sum_{i=1}^nx_i=n$ e $\displaystyle \binom{n}{x_1,x_2,...,x_k}=\dfrac{n!}{x_1!x_2!...x_k!}$.

Considere que, a priori, $\boldsymbol \theta \sim Dirichlet(a_1,...,a_k),$ $a_i > 0, i=1,...,k$, isto é, a f.d.p. a priori para $\boldsymbol \theta$ é dada por

$$f(\boldsymbol \theta) = \dfrac{\Gamma(\sum_{i=1}^K a_i)}{\Gamma(a_1)\Gamma(a_2)...\Gamma(a_k)}\prod_{i=1}^{k-1}\theta_i^{a_i-1}\bigg(\underbrace{1-\sum_{i=1}^{k-1}\theta_i}_{\theta_k}\bigg)^{a_k-1}.$$

Então, a distribuição a posteriori para $\boldsymbol \theta$ é
$\boldsymbol \theta|\boldsymbol X = \boldsymbol x \sim Dirichlet (a_1+x_1,...,a_k+x_k)$.

$~$ 

> **Demo:** Para verificar o resultado, basta ver que  
$f(\boldsymbol\theta|\boldsymbol x)$ $=\dfrac{f(\boldsymbol x| \boldsymbol \theta)f(\boldsymbol \theta)}{\int_\Theta f(\boldsymbol x| \boldsymbol \theta)f(\boldsymbol \theta)d\boldsymbol \theta}$ $\propto f(\boldsymbol x| \boldsymbol \theta)f(\boldsymbol \theta)$ $\propto \prod_{i=1}^{k-1}\theta_i^{(a_i+x_i-1)}\left(1-\sum_{i=1}^{k-1}\theta_i\right)^{(a_k+x_k)-1}$

$~$

**Resultado 3.** Seja $X_1,...,X_n$ v.a. c.i.i.d tais que $X_i|\theta \sim Unif(0,\theta)$ e considere que, a priori,$\theta \sim Pareto(a,b)$. Então $\theta|\boldsymbol X = \boldsymbol x \sim Pareto\left(a+n,max\{b,x_{(n)}\}\right)$.

$~$

> **Demo:**  
$f(\boldsymbol x|\theta)$ $\overset{ci}{=}\prod_{i=1}^nf(x_i|\theta)$ $\overset{id}{=}\prod_{i=1}^n\dfrac{1}{\theta}\mathbb{I}_{[0,\theta]}(x_i)$ $=\dfrac{1}{\theta^n}\mathbb{I}_{[0,\theta]}(x_{(n)})$ $=\dfrac{1}{\theta^n}\mathbb{I}_{[x_{(n)},+\infty)}(\theta)$  
em que $x_{(n)}=max\{x_1,...,x_n\}$.   
$~$  
$f(\theta)=\dfrac{ab^a}{\theta^{a+1}}\mathbb{I}_{[b,+\infty]}(\theta)$.  
Então  
$f(\theta| \boldsymbol x)$ $\propto f(\boldsymbol x|\theta)f(\theta)$ $=\dfrac{1}{\theta^{a+n+1}}\mathbb{I}_{[x_{(n)},+\infty)}(\theta)\mathbb{I}_{[b,+\infty)}(\theta)$ $=\dfrac{1}{\theta^{a+n+1}}\mathbb{I}_{[max\{b,x_{(n)}\},+\infty)}(\theta)$  
$~$
$\Rightarrow \theta|\boldsymbol X = \boldsymbol x \sim Pareto(a+n,max\{b,x_{(n)}\})$.

$~$

**Resultado 4.** Seja $X_1,...,X_n,Y_1,...,Y_m$ v.a. condicionalmente independentes tais que $X_i|\theta\sim Exp(\theta),i=1,...,n$ e $Y_j|\theta \sim Poisson(\theta),j=1,...,m$. Considere que, a priori, $\theta \sim Gama(a,b)$. Então $\theta| \boldsymbol x,\boldsymbol y \sim Gama(a+n+\sum_jy_j~,~b+m+\sum_ix_i)$.

> **Demo:**  
$f(\boldsymbol x, \boldsymbol y|\theta)\overset{ci}{=}f(\boldsymbol x|\theta)f(\boldsymbol y|\theta)\overset{ci}{=}$ $\prod_{i=1}^nf(x_i|\theta)\prod_{j=1}^mf(y_i|\theta)=$ $\prod_{i=1}^n\theta e^{-\theta x_i}\prod_{j=1}^m\dfrac{\theta^{y_j}e^{-\theta}}{y_j!}=$ $\dfrac{1}{\prod_{j=1}^my_j!}\theta^{n+\sum_j y_j}e^{-(m+\sum_ix_i)\theta}$  
$~$  
$f(\theta)=\dfrac{b^a}{\Gamma(a)}\theta^{a-1}e^{-b\theta}$
$~$  
$f(\theta| \boldsymbol{x,y})\propto f(\boldsymbol x, \boldsymbol y|\theta)f(\theta)\propto$ $\theta^{[a+n+\sum_jy_j]-1}e^{-[b+m+\sum_ix_i]\theta}$
$~$  
$\Rightarrow \theta| \boldsymbol x,\boldsymbol y \sim Gama(a+n+\sum_jy_j,b+m+\sum_ix_i)$

$~$  

**Resultado 5.** Seja $~\mathcal{P}=\{f(\boldsymbol x|\theta):\; \theta \in \Theta\}~$ e $~\mathcal{C}=\{h(\theta|a):\;a\in A\}~$ uma *família conjugada* para $\mathcal{P}$. Considere $\mathcal{M}=\{h(\theta)=\sum_{i=1}^mw_ih_i(\theta):$ $h_i \in \mathcal{C} \; e \; w_i>0,\; \sum_{i=1}^m w_i=1\}$. Então $\mathcal{M}$ é *família conjugada* para $\mathcal{P}$.

>**Demo:** Como $\mathcal{C}$ é conjugada para $\mathcal{P}$, para toda função $h_i \in \mathcal{C}$, temos que $f_i(\theta|\boldsymbol x)\propto h_i(\theta)f(\boldsymbol x|\theta)\in \mathcal{C}$. Então  
$~$  
$h\in \mathcal{M}$ $~\Rightarrow~ f(\theta|\boldsymbol x)$ $~\propto~ h(\theta)f(\boldsymbol x|\theta)$ $~\propto~\sum_{i=1}^m w_i\underbrace{h_i(\theta)f(\boldsymbol x|\theta)}_{\in \mathcal{C}}$ $~\propto~\sum_{i=1}^m w_i^*f_i(\theta|\boldsymbol x)\in \mathcal{M}$.

$~$

**Exemplo.**  Seja $X|\theta \sim Bin(n,\theta)$ e $f(\theta)$ $=wf_1(\theta)+(1-w)f_2(\theta)$, com $f_1\sim Beta(a_1,b_1)$ e $f_2\sim Beta(a_2,b_2)$.

$~$

$f(\theta|x)$ $=\dfrac{f(x|\theta)f(\theta)}{\int_0^1f(x|\theta)f(\theta)}$ $=\dfrac{f(x|\theta)[wf_1(\theta)+(1-w)f_2(\theta)]}{w\int_0^1f_1(\theta)f(x|\theta)d\theta+(1-w)\int_0^1f_2(\theta)d\theta}$

$\propto\dfrac{w\binom{n}{x}\frac{\Gamma(a_1+b_1)}{\Gamma(a_1)\Gamma(b_1)}\theta^{a_1+x-1}(1-\theta)^{b_1+n-x-1}+(1-w)\binom{n}{x}\frac{\Gamma(a_2+b_2)}{\Gamma(a_2)\Gamma(b_2)}\theta^{a_2+x-1}(1-\theta)^{b_2+n-x-1}}{\underbrace{w\binom{n}{x}\frac{\Gamma(a_1+b_1)}{\Gamma(a_1)\Gamma(b_1)}\frac{\Gamma(a_1+x)\Gamma(b_1+n-x)}{\Gamma(a_1+b_1+n)}}_{A}+\underbrace{(1-w)\binom{n}{x}\frac{\Gamma(a_2+b_2)}{\Gamma(a_2)\Gamma(b_2)}\frac{\Gamma(a_2+x)\Gamma(b_2+n-x)}{\Gamma(a_2+b_2+n)}}_{B}}$

$\propto~\underbrace{\dfrac{A}{A+B}}_{w^*}Beta(a_1+x,b_1+n-x)+\underbrace{\dfrac{B}{A+B}}_{1-w^*}Beta(a_2+x,b_2+n-x)$.

$~$

Primeiramente, suponha que $n=5$, e temos uma mistura das distribuições $Beta(5,12)$ e $Beta(10,3)$, com $w=0.5$. O gráfico a seguir apresenta as distribuições a priori, a verossimilhança e a posteriori para cada possível valor de $x$ em $\left\{0,1,\ldots,5\right\}$.

```{r, include=knitr::is_latex_output()}
a1=5; b1=12
a2=10; b2=3 
n=5
w=0.5

theta = seq(0,1,0.01)

A = as.vector(apply(matrix(seq(0,n)),1,
  function(x){w*choose(n,x)*gamma(a1+b1)/(gamma(a1)*gamma(b1))*
    (gamma(a1+x)*gamma(b1+n-x))/gamma(a1+b1+n)}))

B = as.vector(apply(matrix(seq(0,n)),1,
  function(x){(1-w)*choose(n,x)*gamma(a2+b2)/(gamma(a2)*gamma(b2))*
    (gamma(a2+x)*gamma(b2+n-x))/gamma(a2+b2+n)}))

w2 = A/(A+B)

prior2 = as.vector(apply(matrix(seq(0,n)),1,
  function(x){w*dbeta(theta,a1,b1)+
              (1-w)*dbeta(theta,a2,b2)}))
                        
post2 = as.vector(as.matrix(mapply(function(x,w2){
  w2*dbeta(theta,a1+x,b1+n-x)+
  (1-w2)*dbeta(theta,a2+x,b2+n-x)},seq(0,n),w2)))
   
#vero = as.vector(apply(matrix(seq(0,n)),1,
# function(x){dbinom(x,prob=theta,size=n)}))

# Verossimilhança proporcional visualmente melhor
vero = as.vector(apply(matrix(seq(0,n)),1,
  function(x){dbeta(theta,x+1,n-x+1)}))

tibble(x=as.factor(rep(seq(0,n),each=length(theta))),
    w2=rep(w2,each=length(theta)),
    theta=rep(theta,(n+1)),vero=vero,prior=prior2,post=post2) %>% 
  ggplot() + 
  geom_line(aes(x=theta,y=post, colour=x),lwd=1.5) + 
  geom_line(aes(x=theta,y=prior,colour="Prior"),lwd=1,lty=2) +
  geom_line(aes(x=theta,y=vero,colour="Verossimilhança"),lwd=1,lty=2)+
  xlab(expression(theta)) +   
  ylab(expression(paste("f(",theta,"|x)")))+
  theme_bw()
```

```{r, include=!knitr::is_latex_output()}
a1=5; b1=12
a2=10; b2=3 
n=5
w=0.5

theta = seq(0,1,0.01)

A = as.vector(apply(matrix(seq(0,n)),1,
  function(x){w*choose(n,x)*gamma(a1+b1)/(gamma(a1)*gamma(b1))*
    (gamma(a1+x)*gamma(b1+n-x))/gamma(a1+b1+n)}))

B = as.vector(apply(matrix(seq(0,n)),1,
  function(x){(1-w)*choose(n,x)*gamma(a2+b2)/(gamma(a2)*gamma(b2))*
    (gamma(a2+x)*gamma(b2+n-x))/gamma(a2+b2+n)}))

w2 = A/(A+B)

prior2 = as.vector(apply(matrix(seq(0,n)),1,
  function(x){w*dbeta(theta,a1,b1)+
              (1-w)*dbeta(theta,a2,b2)}))
                        
post2 = as.vector(as.matrix(mapply(function(x,w2){
  w2*dbeta(theta,a1+x,b1+n-x)+
  (1-w2)*dbeta(theta,a2+x,b2+n-x)},seq(0,n),w2)))
   
#vero = as.vector(apply(matrix(seq(0,n)),1,
# function(x){dbinom(x,prob=theta,size=n)}))

# Verossimilhança proporcional visualmente melhor
vero = as.vector(apply(matrix(seq(0,n)),1,
  function(x){dbeta(theta,x+1,n-x+1)}))

tibble(x=as.factor(rep(seq(0,n),each=length(theta))),
    w2=rep(w2,each=length(theta)),
    theta=rep(theta,(n+1)),vero=vero,prior=prior2,post=post2) %>% 
  ggplot() + 
  geom_line(aes(x=theta,y=post, colour=x),lwd=1.5) + 
  geom_line(aes(x=theta,y=prior,colour="Prior"),lwd=1,lty=2) +
  geom_line(aes(x=theta,y=vero,colour="Verossimilhança"),lwd=1,lty=2)+
  xlab(expression(theta)) +   
  ylab(expression(paste("f(",theta,"|x)")))+
  theme_bw() +
  gganimate::transition_states(x)
```

$~$

Agora, suponha que $n=5$ e foi observado $x=2$. Novamente, considere a mistura das distribuições $Beta(5,12)$ e $Beta(10,3)$ mas agora com pesos $w$ variando no conjunto $\left\{0,0.1,\ldots,0.9,1\right\}$.

```{r, include=knitr::is_latex_output()}
x = 2
w = seq(0,1,0.1)

A = as.vector(apply(matrix(w),1,
  function(w){w*choose(n,x)*gamma(a1+b1)/(gamma(a1)*
    gamma(b1))*(gamma(a1+x)*gamma(b1+n-x))/gamma(a1+b1+n)}))

B = as.vector(apply(matrix(w),1,
  function(w){(1-w)*choose(n,x)*gamma(a2+b2)/(gamma(a2)*
    gamma(b2))*(gamma(a2+x)*gamma(b2+n-x))/gamma(a2+b2+n)}))

w2 = A/(A+B)

prior2 = as.vector(apply(matrix(w),1,function(w){
  w*dbeta(theta,a1,b1)+(1-w)*dbeta(theta,a2,b2)}))

post2 = as.vector(as.matrix(mapply(function(w,w2){
  w2*dbeta(theta,a1+x,b1+n-x)+
  (1-w2)*dbeta(theta,a2+x,b2+n-x)},w,w2)))

vero = as.vector(apply(matrix(rep(x,2*n+1)),1,
  function(x){dbeta(theta,x+1,n-x+1)}))

z<-length(w)

tibble(w=as.factor(rep(w,each=length(theta))),
    w2=rep(w2,each=length(theta)),
    theta=rep(theta,z), prior = prior2, 
    post = post2, vero = vero) %>% 
  ggplot(colour = w) + 
  geom_line(aes(x=theta,y=post, colour=w),lwd=1.5) + 
  geom_line(aes(x=theta,y=prior,colour="Priori")) +
  geom_line(aes(x=theta,y=vero,colour="Verossimilhança"),lwd=1,lty=2)+
  xlab(expression(theta)) + ylab(expression(paste("f(",theta,"|x)")))+
  theme_bw()
```

```{r, include=!knitr::is_latex_output()}  
x = 2
w = seq(0,1,0.1)

A = as.vector(apply(matrix(w),1,
  function(w){w*choose(n,x)*gamma(a1+b1)/(gamma(a1)*
    gamma(b1))*(gamma(a1+x)*gamma(b1+n-x))/gamma(a1+b1+n)}))

B = as.vector(apply(matrix(w),1,
  function(w){(1-w)*choose(n,x)*gamma(a2+b2)/(gamma(a2)*
    gamma(b2))*(gamma(a2+x)*gamma(b2+n-x))/gamma(a2+b2+n)}))

w2 = A/(A+B)

prior2 = as.vector(apply(matrix(w),1,function(w){
  w*dbeta(theta,a1,b1)+(1-w)*dbeta(theta,a2,b2)}))

post2 = as.vector(as.matrix(mapply(function(w,w2){
  w2*dbeta(theta,a1+x,b1+n-x)+
  (1-w2)*dbeta(theta,a2+x,b2+n-x)},w,w2)))

vero = as.vector(apply(matrix(rep(x,2*n+1)),1,
  function(x){dbeta(theta,x+1,n-x+1)}))

z<-length(w)

tibble(w=as.factor(rep(w,each=length(theta))),
    w2=rep(w2,each=length(theta)),
    theta=rep(theta,z), prior = prior2, 
    post = post2, vero = vero) %>% 
  ggplot(colour = w) + 
  geom_line(aes(x=theta,y=post, colour=w),lwd=1.5) + 
  geom_line(aes(x=theta,y=prior,colour="Priori")) +
  geom_line(aes(x=theta,y=vero,colour="Verossimilhança"),lwd=1,lty=2)+
  xlab(expression(theta)) + ylab(expression(paste("f(",theta,"|x)")))+
  theme_bw() +
  gganimate::transition_states(w)
```


$~$

$~$

### Prioris "Não-Informativas"

#### Priori de Bayes-Laplace

**Princípio da Razão Insuficiente.** *Quando não existe razão suficiente para acreditar mais em algum subconjunto do espaço paramétrico $\Theta$, deve-se adotar equiprobabilidade.*

$~$

> **Exemplo 1.** Se $\Theta=\left\{\theta_1,\theta_2,\ldots,\theta_k\right\}$ então a priori de Bayes-Laplace é $f(\theta)=1/k$, $\theta \in \Theta~.$

$~$

> **Exemplo 2.** Se $\Theta=\left[a,b\right]$ então a priori de Bayes-Laplace é $f(\theta)=1/(b-a)$, $\theta \in \Theta~.$

$~$

$f(\theta|\boldsymbol{x})$ 
$= \dfrac{f(\theta)f(\boldsymbol{x}|\theta)}{\int_\Theta f(\theta)f(\boldsymbol{x}|\theta)~d\theta}$ 
$= \dfrac{c~f(\boldsymbol{x}|\theta)}{c~\int_\Theta f(\boldsymbol{x}|\theta)~d\theta}$ 
$= \dfrac{f(\boldsymbol{x}|\theta)}{\int_\Theta f(\boldsymbol{x}|\theta)~d\theta}$ 
$\propto f(\boldsymbol{x}|\theta)~.$

$~$

As principais críticas da priori de Bayes-Laplace são

1. A distribuição é *imprópria* quando o espaço paramétrico $\Theta$ não é finito ou limitado. Por exemplo, $\Theta=\mathbb{N}$, $\Theta=\mathbb{Z}$ ou $\Theta=\mathbb{R}$. Nesses casos, a priori de Bayes-Laplace é $f(\theta)\propto \mathbb{I}_\Theta(\theta)$, que não é uma distribuição de probabilidade.

1. Não é *invariante* a reparametrizações. Considere, por exemplo, $f(\theta)$ uma f.d.p. a priori para $\theta$ e $g$ uma transformação um-a-um (injetora) de $\theta$ tal que $\psi=g(\theta)$. A distribuição de $\psi$ pode ser calculada por $f_\psi(\psi) = f\left(g^{-1}(\psi)\right)\left|\dfrac{dg^{-1}(\psi)}{d\psi}\right|~.$ Assim, se $g$ é uma transformação não linear e a distribuição a priori para $\theta$ é uniforme, a distribuição para $\psi$ não é uniforme, em geral.

$~$

#### Priori de Jeffreys

Seja $g$ uma transformação um-a-um do parâmetro $\theta$ e defina $\psi=g(\theta)$. Considere uma função $h:\mathfrak{X}\times\Theta\longrightarrow\mathbb{R}$. Uma classe de distribuições a priori invariantes pode ser definida por
$$f(\theta) \propto \left(\text{Var}_{X|\theta}\left[\dfrac{\partial h(\boldsymbol X | \theta)}{\partial\theta}~\bigg|~\theta\right]\right)^{1/2}~.$$

>**Demo.** Para mostrar a invariância do método, considere o caso contínuo em que
$$f_\psi(\psi) = f\left(g^{-1}(\psi)\right)\left|\dfrac{\partial g^{-1}(\psi)}{\partial\psi}\right|~.$$
Seja $h^*(x,\psi)=h\left(x,g^{-1}(\psi)\right)$. Então  
$\dfrac{\partial h^*(x,\psi)}{\partial\psi}$ 
$=\dfrac{\partial h\left(x,g^{-1}(\psi)\right)}{\partial\psi}$ 
$=\left.\dfrac{\partial h(x,\theta)}{\partial\theta}\right|_{\theta=g^{-1}(\psi)}\cdot\dfrac{\partial g^{-1}(\psi)}{\partial\psi}~,$  
e, portanto,  
$\text{Var}\left[\dfrac{\partial h^*(\boldsymbol{X},\psi)}{\partial\psi}~\bigg|~\theta=g^{-1}(\psi)\right]$ 
$=\text{Var}\left[\dfrac{\partial h(\boldsymbol{X},\theta)}{\partial\theta}~\bigg|~\theta=g^{-1}(\psi)\right]\cdot\left[\dfrac{\partial g^{-1}(\psi)}{\partial\psi}\right]^2$ 
$=\left[f\left(g^{-1}(\psi)\right)\left(\dfrac{\partial g^{-1}(\psi)}{\partial\psi}\right)\right]^2~,$  
de modo que  
$f_\psi(\psi)$ $=f\left(g^{-1}(\psi)\right)\left|\dfrac{\partial g^{-1}(\psi)}{\partial\psi}\right|$ 
$=\text{Var}\left[\dfrac{\partial h^*(\boldsymbol{X},\psi)}{\partial\psi}~\bigg|~\theta=g^{-1}(\psi)\right]^{1/2}~.$

$~$

A escolha mais usual para $h$ é $h(\boldsymbol{x},\theta)=\log f(\boldsymbol{x}|\theta)~.$ Assim, como $E\left[\dfrac{\partial \log f(\boldsymbol{X}|\theta)}{\partial\theta}~\bigg|~\theta\right]=0$, temos  
$f(\theta)$ 
$\propto\text{Var}\left[\dfrac{\partial \log f(\boldsymbol{X}|\theta)}{\partial\theta}~\bigg|~\theta\right]^{1/2}$ 
$=\text{E}\left[\left(\dfrac{\partial \log f(\boldsymbol{X}|\theta)}{\partial\theta}\right)^2~\bigg|~\theta\right]^{1/2}$ 
$=\left[\mathcal{I}(\theta)\right]^{1/2}~,$  
onde $\mathcal{I}(\theta)$ é a *Informação de Fisher* de $\theta$. Neste caso, $f(\theta)\propto\left[\mathcal{I}(\theta)\right]^{1/2}$ é chamada **priori de Jeffreys**.

$~$

>**Exemplo 1.** Considere novamente o experimento de lançar uma moeda $n$ vezes e contar o número de caras, isto é, $X|\theta \sim \text{Bin}(n,\theta)$. Então,  
$f(x|\theta)=\displaystyle\binom{n}{x}\theta^x(1-\theta)^{n-x}$ 
$\Longrightarrow~ \log f(x|\theta)=\log\binom{n}{x}+x\log\theta+(n-x)\log(1-\theta)$  
$~$  
$\dfrac{\partial\log f(x|\theta)}{\partial\theta}$ 
$=\dfrac{x}{\theta}-\dfrac{n-x}{1-\theta}$ 
$=\dfrac{x-n\theta}{\theta(1-\theta)}~.$  
$~$  
Como $E\left[X|\theta\right]=n\theta$ e $Var(X|\theta)$ $=E\left[\left(X-E\left[X|\theta\right]\right)^2~\Big|~\theta\right]$ $=E\left[\left(X-n\theta\right)^2~\Big|~\theta\right]$ $=n\theta(1-\theta)$, a informação de Fisher neste caso é  
$\mathcal{I}_x(\theta)$ $=\text{E}\left[\left(\dfrac{\partial\log f(x|\theta)}{\partial\theta}\right)^2~\bigg|~\theta\right]$ $=\text{E}\left[\left(\dfrac{X-n\theta}{\theta(1-\theta)}\right)^2~\bigg|~\theta\right]$ 
$=\dfrac{1}{\theta^2(1-\theta)^2}~\text{E}\left[\left(X-n\theta\right)^2~|~\theta\right]$
$=\dfrac{1}{\theta^2(1-\theta)^2}~\text{Var}\left(X~|~\theta\right)$ 
$=\dfrac{n~\theta(1-\theta)}{\theta^2(1-\theta)^2}$ 
$=\dfrac{n}{\theta(1-\theta)}$ $=n\theta^{-1}(1-\theta)^{-1}~,$  
$~$  
de modo que a priori de Jeffreys é  
$f(\theta)$ $\propto\left[\mathcal{I}_x(\theta)\right]^{1/2}$ 
$\propto\theta^{-1/2}(1-\theta)^{-1/2}~.$

$~$

> **Exemplo 2.** Considere agora que a mesma moeda é lançada e anota-se o número de caras $Y$ até que sejam observadas $r$ coroas, isto é, $Y|\theta \sim \text{BinNeg}(r,\theta)$. Então,
$f(y|\theta)=\displaystyle\binom{y+r-1}{y}\theta^y(1-\theta)^{r}$ 
$\Longrightarrow~ \log f(y|\theta)=\log\binom{y+k-1}{y}+y\log\theta+r\log(1-\theta)$  
$~$  
$\dfrac{\partial\log f(y|\theta)}{\partial\theta}$ 
$=\dfrac{y}{\theta}-\dfrac{r}{1-\theta}$ 
$=\dfrac{1}{\theta}\left[y-\dfrac{r~\theta}{1-\theta}\right]~.$  
$~$  
Como $E\left[X|\theta\right]=\dfrac{r~\theta}{1-\theta}$ e $Var(X|\theta)=\dfrac{r~\theta}{(1-\theta)^2}$, a informação de Fisher neste caso é  
$\mathcal{I}_y(\theta)$ $=\text{E}\left[\dfrac{1}{\theta^2}\left(y-\dfrac{r~\theta}{1-\theta}\right)^2~\bigg|~\theta\right]$ 
$=\dfrac{1}{\theta^2}~\text{Var}\left(Y~|~\theta\right)$ 
$=\dfrac{r}{\theta(1-\theta)^2}$ $=r\theta^{-1}(1-\theta)^{-2}~,$  
$~$  
de modo que a priori de Jeffreys é  
$f(\theta)$ $\propto\left[\mathcal{I}_y(\theta)\right]^{1/2}$ 
$\propto\theta^{-1/2}(1-\theta)^{-1}~.$

$~$

Note que nos exemplos apresentados, a priori depende da *regra de parada*, isto é, a forma como decidimos quando parar de lançar a moeda e que determina se o modelo estatístico é binomial ou binomial negativo. Em outras palavras, a opinião a priori definida dessa forma depende do modelo adotado, mesmo que o parâmetro seja o mesmo nos dois casos.

$~$  

#### Priori de Máxima Entropia

**Entropia** é um conceito físico que quantifica a desordem ou imprevisibilidade de um sistema, ou da falta de informação sobre ele. O conceito de entropia desempenha um importante papel na teoria da informação. O *princípio da máxima entropia* afirma que a distribuição de probabilidade que melhor representa a falta de informação é aquela com a maior entropia.


**Caso Discreto.** Considere um espaço paramétrico enumerável $\Theta = \{\theta_1,\theta_2,...\}$. A *entropia* da distribuição $h$ é dada por  
$$\mathcal{E}(h)=\text{E}[-\log h(\theta)]=\displaystyle-\sum_{\theta\in\Theta} \log\left[h(\theta)\right]~h(\theta)~.$$

$~$  

> **Exemplo 1.** Considere o espaço paramétrico $\Theta=\{\theta_1,...,\theta_k\}$ e $h(\theta_i)=p_i$ uma distribuição discreta para $\theta$. A *distribuição da máxima entropia* para $\theta$ é a função $h$ que maximiza $\mathcal{E}(h)=-\displaystyle\sum_{i=1}^{k} p_i\log(p_i)$ com a restrição $\displaystyle\sum_{i=1}^k h(\theta_i)=\sum_{i=1}^k p_i=1~.$  
Utilizando o método de multiplicadores de Lagrange, deve-se maximizar a função lagrangiana  
$\mathcal{E}^*(h)=\displaystyle-\sum_{i=1}^k p_i\log(p_i)+\lambda\left(\sum_{i=1}^k p_i-1\right)$  
$\dfrac{\partial\mathcal{E}^*(h)}{\partial p_i}=-\left[p_i~\dfrac{1}{p_i}+\log(p_i)\right]+\lambda=0$ $\Longleftrightarrow p_i = e^{\lambda-1}~~,~~~i=1,\ldots,k~.$  
Assim, como $p_i$ deve ser constante e $\sum p_i=1$, conclui-se que $p_i=1/k$, para $i=1,\ldots,k~.$

$~$

> **Exemplo 2:** Considere agora $\Theta = \{\theta_1,\theta_2,...\}$ e suponha que há $m$ informações parciais a respeito do parâmetro $\theta$ que podem ser escritas como $\text{E}[g_j(\theta)]=\mu_j~,~$ $j=1,...,m~.$  
Usando novamente o método de Lagrange, deve-se maximizar  
$\mathcal{E}^*(h)$ $=\displaystyle\sum_{i=1}^\infty p_i\log(p_i)+\lambda\left(\sum_{i=1}^\infty p_i-1\right)+ \sum_{j=1}^m\lambda_j\left(\sum_{i=1}^\infty p_i~g_j(\theta_i)-\mu_j\right)$  
$\dfrac{\partial \mathcal{E}^*(h)}{\partial p_i}=\displaystyle-\log(p_i)-1+\lambda+\sum_{j=1}^m\lambda_j~g_j(\theta_i)=0$ 
$\Longleftrightarrow p_i \propto e^{\lambda-1+\sum_{j=1}^m \lambda_j~g_j(\theta_i)}$ $\propto e^{\sum_{j=1}^m \lambda_j~g_j(\theta_i)}~~,~~~i=1,\ldots,k~.$  
Como $\sum p_i=1$, $p_i = \dfrac{e^{\sum_{j=1}^m \lambda_j~g_j(\theta_i)}}{\sum_{i=1}^\infty e^{\sum_{j=1}^m \lambda_j~g_j(\theta_i)}}~$ e $\lambda_j$ é obtido por meio das restrições.

$~$

> **Exemplo 2a:** Seja $\Theta = \{0,1,2,...\}$ e suponha que $\text{E}[\theta]=\mu.$  
Usando o resultado do exemplo anterior com $g(\theta)=\theta$ e $\theta_i=i$, $i=0,1,2,\ldots~,$  
$p_i=\dfrac{e^{\sum_{j=1}^m \lambda_j~g_j(\theta_i)}}{\sum_{i=0}^\infty e^{\sum_{j=1}^m \lambda_j~g_j(\theta_i)}}$ 
$=\dfrac{e^{\lambda~i}}{\sum_{i=0}^\infty e^{\lambda~i}}~$
$\overset{\left|e^\lambda\right|<1}{=}~\dfrac{e^{\lambda~i}}{1/\left(1-e^\lambda\right)}$ 
$=\left(e^\lambda\right)^i\left(1-e^\lambda\right)$ 
$\Longrightarrow \theta \sim \text{Geo}\left(1-e^\lambda\right)~.$  
Como $\text{E}\left[\theta\right]=\dfrac{e^\lambda}{\left(1-e^\lambda\right)}=\mu$, tem-se que $\lambda=\log\dfrac{\mu}{1+\mu}~.$

$~$

> **Exemplo 2b:** Considere que $\Theta = \{1,2,...,k\}$ e suponha que $\text{Med}(\theta)=m~.$  
Nesse caso, $g(\theta)=\mathbb{I}\left(\theta\leq m\right)$ e $\theta_i=i$, $i=1,2,\ldots,k~,$ de modo que  
$\text{E}\left[g(\theta)\right]$ $=\text{E}\left[\mathbb{I}(\theta\leq m)\right]$ $=\text{P}\left(\theta\leq m\right)=1/2$ e, portanto, $\displaystyle\sum_{i\leq m}p_i=\sum_{j> m}p_j=1/2~.$
$p_i=\dfrac{e^{\sum_{j=1}^m \lambda_j~g_j(\theta_i)}}{\sum_{i=1}^k e^{\sum_{j=1}^m \lambda_j~g_j(\theta_i)}}$ 
$=\left\{\begin{array}{lll} \dfrac{e^\lambda}{\sum_{i\leq m} e^\lambda}&,& i\leq m \\ \dfrac{1}{\sum_{i\leq m} 1}&,& i> m\end{array}\right.$ 
$=\left\{\begin{array}{lll} \dfrac{1}{2m}&,& i\leq m \\ \dfrac{1}{2(k-m)}&,& i> m\end{array}\right.$  
(A distribuição de $\theta$ é uniforme por blocos.)

$~$

$~$

<!-- $\mathcal{E}(\boldsymbol p)=$ $\sum_{i=1}^kp_iln(p_i),$ $\boldsymbol p = (p_1,...,p_k),\; \sum p_i=1$ -->

<!-- $~$ -->

<!-- **Divergência de Kullbach-Leibler** -->

<!-- $\boldsymbol p = (p_1,...,p_k);\;\boldsymbol q = (q_1,...,q_k),$ -->

<!-- $D(\boldsymbol{p,q})=\sum p_iln\left(\dfrac{p_i}{q_i}\right)$ -->

<!-- Suponha $g=(1/k,...,1/k)$ -->

<!-- $D(\boldsymbol{p,q})=\sum_{i=1}^{k}p_i[ln(p_i)-ln(1/k)]$ $=\sum_{i=1}^kp_i ln(pi)+ln(k)\underbrace{\sum_{i=1}^k p_i}_{1}$ $=ln(k)-\mathcal{E}(\boldsymbol p)$ -->

<!-- $\Rightarrow \mathcal{E}(\boldsymbol p)$ está associado com quanto a distribuição $\boldsymbol p$ "difer" da distribuição uniforme (priori de referência na ausência total de informação) -->

<!-- $~$ -->

<!-- **Jaynes** redefiniu entropia (no caso contínuo) por  -->

<!-- $\mathcal{E}(h)=-\int_\Theta h(\theta)ln\left(\dfrac{h(\theta)}{h_0(\theta)}\right)d\theta$ -->

<!-- $~$ -->

<!-- **Observação:** Caso Geral $\mathcal{E}(H)=-\int_\Theta ln\left(\dfrac{dH(\theta)}{dH_0(\theta)}\right)dH(\theta)$ onde $H$ e $H_0$ são medidas de probabilidade para $\theta$ e $\dfrac{dH}{dH_0}$ é derivada de Radom-Nikodim. -->

<!-- $~$ -->

<!-- Assim como no caso discreto, se temos $m$ restrições $E[g_i(\theta)]=\mu_i,$ a densidade de máxima entropia é -->

<!-- $h(\theta)\propto h_0(\theta)exp\{\sum_{j=1}^m\lambda_j g_j(\theta)\}$ e os $\lambda_j,\;j=1,...,m$ são obtidos das restrições. Por exemplo, se $E[\theta]=\mu,$ basta fazer  -->

<!-- $\mu = \int_\Theta \theta c h_0(\theta)exp\{\lambda\theta\}d\theta$ com $c^{-1}=\int_\Theta h_0(\theta)exp\{\lambda \theta\}d\theta$. -->

<!-- $~$ -->

<!-- **Exemplo 1:** $\Theta = \mathbb{R}_+$ e $E[\theta]=\mu$, -->

<!-- $h_0(\theta) \propto 1\mathbb{I}_{\mathbb{R}_+}(\theta)$ $\Rightarrow h(\theta )\propto exp\{\lambda\theta\}\mathbb{I}_{\mathbb{R}_+}(\theta)$ -->

<!-- $h(\theta)=-\lambda exp\{\lambda\theta\}\mathbb{I}_{\mathbb{R}_+}(\theta)\mathbb{I}_{\mathbb{R}_-}(\lambda)$ -->

<!-- $E[\theta]=-1/\lambda =\mu$ $\Rightarrow \lambda= -1/\mu$ -->

<!-- $h(\theta)=\dfrac{1}{\mu}e^{-\frac{1}{\mu}\theta},\; \mu>0$ -->

<!-- $~$ -->

<!-- **Exemplo 2** $\Theta = \mathbb{R}$ e $E[\theta]=\mu$ e $Var[\theta]=\sigma^2=E[(\theta-\mu)^2]$ -->

<!-- $h(\theta)\propto exp\{\lambda_1\mu+\lambda_2(\theta-\mu)^2\}$ $\propto exp\left\{\lambda_2\left[\theta-\left(\mu-\dfrac{\lambda_1}{2\lambda_2}\right)\right]^2\right\}+\left[\lambda_1\mu+\dfrac{\lambda_1^2}{4\lambda_2}\right]$ -->

<!-- Parecido a uma $X\sim N(\mu_x,\sigma_X^2)$ onde $f(x)=\dfrac{1}{\sqrt{2\pi}\sigma_X}exp\left\{-\dfrac{1}{2\sigma_X^2})(x-\mu)^2\right\}$ $\propto exp\left\{-\dfrac{1}{2\sigma_X^2}(x-\mu)^2\right\}$ -->

<!-- $\mu-\dfrac{\lambda_1}{2\lambda_2}=\mu$ $\Rightarrow\; \lambda_1=0;\; \lambda_2=-\dfrac{1}{2\sigma_X^2}$ $\Rightarrow \theta \sim N(\mu,\sigma^2)$ -->

$~$

$~$
