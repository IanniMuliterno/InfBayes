<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2 Introdução à Inferência Bayesiana | Fundamentos de Inferência Bayesiana</title>
  <meta name="description" content="Notas de aula de Infência Bayesiana." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="2 Introdução à Inferência Bayesiana | Fundamentos de Inferência Bayesiana" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Notas de aula de Infência Bayesiana." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2 Introdução à Inferência Bayesiana | Fundamentos de Inferência Bayesiana" />
  
  <meta name="twitter:description" content="Notas de aula de Infência Bayesiana." />
  

<meta name="author" content="Victor Fossaluza e Luís Gustavo Esteves" />


<meta name="date" content="2020-09-02" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ProbSubj.html"/>
<link rel="next" href="TeoDec.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.9.2.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.52.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.52.2/plotly-latest.min.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Notas de Aula de Inferência Bayesiana</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefácio</a></li>
<li class="chapter" data-level="1" data-path="ProbSubj.html"><a href="ProbSubj.html"><i class="fa fa-check"></i><b>1</b> Probabilidade Subjetiva</a><ul>
<li class="chapter" data-level="1.1" data-path="ProbSubj.html"><a href="ProbSubj.html#definição-axiomática"><i class="fa fa-check"></i><b>1.1</b> Definição Axiomática</a></li>
<li class="chapter" data-level="1.2" data-path="ProbSubj.html"><a href="ProbSubj.html#interpretações-de-probabilidade"><i class="fa fa-check"></i><b>1.2</b> Interpretações de Probabilidade</a></li>
<li class="chapter" data-level="1.3" data-path="ProbSubj.html"><a href="ProbSubj.html#relação-de-crença-precsim"><i class="fa fa-check"></i><b>1.3</b> Relação de Crença <span class="math inline">\(\precsim\)</span></a></li>
<li class="chapter" data-level="1.4" data-path="ProbSubj.html"><a href="ProbSubj.html#medida-de-probabilidade-que-representa-precsim"><i class="fa fa-check"></i><b>1.4</b> Medida de Probabilidade que “representa” <span class="math inline">\(\precsim\)</span></a></li>
<li class="chapter" data-level="1.5" data-path="ProbSubj.html"><a href="ProbSubj.html#medida-de-probabilidade-condicional"><i class="fa fa-check"></i><b>1.5</b> Medida de Probabilidade Condicional</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Bayes.html"><a href="Bayes.html"><i class="fa fa-check"></i><b>2</b> Introdução à Inferência Bayesiana</a><ul>
<li class="chapter" data-level="2.1" data-path="Bayes.html"><a href="Bayes.html#BasBayes"><i class="fa fa-check"></i><b>2.1</b> Conceitos Básicos</a><ul>
<li class="chapter" data-level="2.1.1" data-path="Bayes.html"><a href="Bayes.html#inferência-frequentista-ou-clássica"><i class="fa fa-check"></i><b>2.1.1</b> Inferência Frequentista (ou Clássica)</a></li>
<li class="chapter" data-level="2.1.2" data-path="Bayes.html"><a href="Bayes.html#inferência-bayesiana"><i class="fa fa-check"></i><b>2.1.2</b> Inferência Bayesiana</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="Bayes.html"><a href="Bayes.html#suficiência"><i class="fa fa-check"></i><b>2.2</b> Suficiência</a></li>
<li class="chapter" data-level="2.3" data-path="Bayes.html"><a href="Bayes.html#distribuição-a-priori"><i class="fa fa-check"></i><b>2.3</b> Distribuição a Priori</a><ul>
<li class="chapter" data-level="2.3.1" data-path="Bayes.html"><a href="Bayes.html#método-do-histograma"><i class="fa fa-check"></i><b>2.3.1</b> Método do Histograma</a></li>
<li class="chapter" data-level="2.3.2" data-path="Bayes.html"><a href="Bayes.html#elicitação-de-hiperparâmetros"><i class="fa fa-check"></i><b>2.3.2</b> Elicitação de Hiperparâmetros</a></li>
<li class="chapter" data-level="2.3.3" data-path="Bayes.html"><a href="Bayes.html#prioris-conjugadas"><i class="fa fa-check"></i><b>2.3.3</b> Prioris Conjugadas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="TeoDec.html"><a href="TeoDec.html"><i class="fa fa-check"></i><b>3</b> Introdução à Teoría da Decisão</a><ul>
<li class="chapter" data-level="3.1" data-path="TeoDec.html"><a href="TeoDec.html#BasDec"><i class="fa fa-check"></i><b>3.1</b> Conceitos Básicos</a></li>
<li class="chapter" data-level="3.2" data-path="TeoDec.html"><a href="TeoDec.html#aleatorização-e-decisões-mistas"><i class="fa fa-check"></i><b>3.2</b> Aleatorização e Decisões Mistas</a></li>
<li class="chapter" data-level="3.3" data-path="TeoDec.html"><a href="TeoDec.html#problemas-com-dados"><i class="fa fa-check"></i><b>3.3</b> Problemas com Dados</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Estimacao.html"><a href="Estimacao.html"><i class="fa fa-check"></i><b>4</b> Estimação</a><ul>
<li class="chapter" data-level="4.1" data-path="Estimacao.html"><a href="Estimacao.html#estimação-pontual"><i class="fa fa-check"></i><b>4.1</b> Estimação Pontual</a></li>
<li class="chapter" data-level="4.2" data-path="Estimacao.html"><a href="Estimacao.html#estimação-por-regiões"><i class="fa fa-check"></i><b>4.2</b> Estimação por Regiões</a></li>
<li class="chapter" data-level="4.3" data-path="Estimacao.html"><a href="Estimacao.html#custo-das-observações"><i class="fa fa-check"></i><b>4.3</b> Custo das Observações</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Test.html"><a href="Test.html"><i class="fa fa-check"></i><b>5</b> Testes de Hipóteses</a><ul>
<li class="chapter" data-level="5.1" data-path="Test.html"><a href="Test.html#BasTest"><i class="fa fa-check"></i><b>5.1</b> Conceitos Básicos</a></li>
<li class="chapter" data-level="5.2" data-path="Test.html"><a href="Test.html#revisão-abordagem-frequentista"><i class="fa fa-check"></i><b>5.2</b> Revisão: Abordagem Frequentista</a></li>
<li class="chapter" data-level="5.3" data-path="Test.html"><a href="Test.html#abordagem-bayesiana-via-teoria-da-decisão"><i class="fa fa-check"></i><b>5.3</b> Abordagem Bayesiana (via Teoria da Decisão)</a></li>
<li class="chapter" data-level="5.4" data-path="Test.html"><a href="Test.html#probabilidade-posterior-de-h_0"><i class="fa fa-check"></i><b>5.4</b> Probabilidade Posterior de <span class="math inline">\(H_0\)</span></a></li>
<li class="chapter" data-level="5.5" data-path="Test.html"><a href="Test.html#fator-de-bayes"><i class="fa fa-check"></i><b>5.5</b> Fator de Bayes</a></li>
<li class="chapter" data-level="5.6" data-path="Test.html"><a href="Test.html#teste-de-jeffreys"><i class="fa fa-check"></i><b>5.6</b> Teste de Jeffreys</a></li>
<li class="chapter" data-level="5.7" data-path="Test.html"><a href="Test.html#hipóteses-precisas"><i class="fa fa-check"></i><b>5.7</b> Hipóteses Precisas</a></li>
<li class="chapter" data-level="5.8" data-path="Test.html"><a href="Test.html#fbst---full-bayesian-significance-test"><i class="fa fa-check"></i><b>5.8</b> FBST - <em>Full Bayesian Significance Test</em></a></li>
<li class="chapter" data-level="5.9" data-path="Test.html"><a href="Test.html#p-value---nivel-de-significância-adaptativo"><i class="fa fa-check"></i><b>5.9</b> P-value - Nivel de Significância Adaptativo</a></li>
</ul></li>
<li class="appendix"><span><b>Apêndice</b></span></li>
<li class="chapter" data-level="A" data-path="medprob.html"><a href="medprob.html"><i class="fa fa-check"></i><b>A</b> Breve Resumo de Medida e Probabilidade</a><ul>
<li class="chapter" data-level="A.1" data-path="medprob.html"><a href="medprob.html#basprob"><i class="fa fa-check"></i><b>A.1</b> Conceitos Básicos</a></li>
<li class="chapter" data-level="A.2" data-path="medprob.html"><a href="medprob.html#lebesgue"><i class="fa fa-check"></i><b>A.2</b> Valor Esperado de <span class="math inline">\(X\)</span> (OU uma ideia da tal Integral de Lebesgue)</a></li>
<li class="chapter" data-level="A.3" data-path="medprob.html"><a href="medprob.html#funções-de-variáveis-aleatórias"><i class="fa fa-check"></i><b>A.3</b> Funções de Variáveis Aleatórias</a></li>
<li class="chapter" data-level="A.4" data-path="medprob.html"><a href="medprob.html#função-de-distribuição"><i class="fa fa-check"></i><b>A.4</b> Função de Distribuição</a></li>
<li class="chapter" data-level="A.5" data-path="medprob.html"><a href="medprob.html#probabilidade-condicional"><i class="fa fa-check"></i><b>A.5</b> Probabilidade Condicional</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="referências.html"><a href="referências.html"><i class="fa fa-check"></i>Referências</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Fundamentos de Inferência Bayesiana</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="Bayes" class="section level1">
<h1><span class="header-section-number">2</span> Introdução à Inferência Bayesiana</h1>
<div id="BasBayes" class="section level2">
<h2><span class="header-section-number">2.1</span> Conceitos Básicos</h2>
<ul>
<li><p><strong>Inferência Estatística:</strong> fazer afirmações sobre quantidades não observáveis em um determinado contexto.</p></li>
<li><p><span class="math inline">\(\theta\)</span> : <strong>parâmetro</strong> - quantidade desconhecida de interesse (não-observável em determinado contexto).</p></li>
<li><p><span class="math inline">\(\Theta\)</span> : <strong>espaço paramétrico</strong> - conjunto onde <span class="math inline">\(\theta\)</span> toma valores (supostamente conhecido).</p></li>
<li><p><span class="math inline">\(E=\left(\boldsymbol X, \theta, \left\{f(\boldsymbol x|\theta)\right\}\right)\)</span>: <strong>experimento</strong> - “<em>tornar visível algo que antes era invisível</em>” ou, mais especificamente no nosso contexto, observar uma realização <span class="math inline">\(\boldsymbol x \in \mathfrak{X}\)</span> de um vetor aleatório <span class="math inline">\(\boldsymbol X\)</span> com alguma distribuição <span class="math inline">\(f(\boldsymbol x|\theta)\)</span>. Essa distribuição pertence, na maioria dos casos, à uma família de distribuições fixada mas que depende do parâmetro desconhecido de interesse <span class="math inline">\(\theta\)</span>. Note que na grande maioria dos problemas do dia a dia de um estatístico ele se utiliza de resultados experimentais para fazer afirmações sobre <span class="math inline">\(\theta\)</span> e este, por sua vez, é não-observável em geral.</p></li>
<li><p><span class="math inline">\(\mathfrak{X}\)</span> : <strong>espaço amostral</strong> - conjunto onde <span class="math inline">\(\boldsymbol X\)</span> toma valores (supostamente conhecido).</p></li>
<li><p><span class="math inline">\(\mathcal{F}\)</span> : <span class="math inline">\(\sigma\)</span>-álgebra de (sub)conjuntos de <span class="math inline">\(\mathfrak{X}\)</span>.</p></li>
<li><p>Neste espaço amostral, defini-se uma família <span class="math inline">\(\mathcal{P}=\{P(\cdot|\theta): \theta \in \Theta\}\)</span>, isto é, um conjunto de distribuições (condicionais) para <span class="math inline">\(\boldsymbol X\)</span> indexadas por <span class="math inline">\(\theta\)</span>.</p></li>
<li><p><span class="math inline">\((\mathfrak{X},\mathcal{F},\mathcal{P})\)</span> : modelo estatístico (clássico).</p></li>
<li><p><span class="math inline">\(V_X(\theta)=f(\boldsymbol x |\theta)\)</span> : função de verossimilhança.</p></li>
</ul>
<p><span class="math inline">\(~\)</span></p>
<div id="inferência-frequentista-ou-clássica" class="section level3">
<h3><span class="header-section-number">2.1.1</span> Inferência Frequentista (ou Clássica)</h3>
<ul>
<li><p><span class="math inline">\(\theta\)</span> é considerado fixo (apesar de desconhecido) e, portanto, não recebe uma distribuição de probabilidade.</p></li>
<li><p>Baseia-se no " princípio" da amostragem repetida (interpretação frequentista de probabilidade), isto é, supõe que é possivel realizar infinitas vezes o experimento. Assim, o <span class="math inline">\(\boldsymbol x\)</span> é apenas um dos possiveis resultados (hipóteticos) do experimento.</p></li>
<li><p>Probabilidade somente é definida em (uma <span class="math inline">\(\sigma-álgebra\)</span> de) <span class="math inline">\(\mathfrak{X}\)</span>.</p></li>
</ul>
</div>
<div id="inferência-bayesiana" class="section level3">
<h3><span class="header-section-number">2.1.2</span> Inferência Bayesiana</h3>
<ul>
<li><p>Baseia-se na interpretação subjetivista de probabilidade, de modo que a <em>SUA</em> incerteza sobre algo desconhecido deve ser quantificada (traduzida) em termos de probabilidade.</p></li>
<li><p>Assim, <em>SUA</em> incerteza sobre o parâmetro (desconhecido) é representada por uma distribuição de probabilidade, <span class="math inline">\(\theta\)</span> é tratado como uma variável aleatória (v.a.) e <em>SUA</em> distribuição para <span class="math inline">\(\theta\)</span> antes da realização do experimento, <span class="math inline">\(f(\theta),\)</span> é chamada de <strong>distribuição a priori</strong>. Note que a atribuição de uma distribuição a prior para <span class="math inline">\(\theta\)</span> independe da natureza do parâmetro, ele pode ser a proporção de indivíduos que avalia positivamente o governo atual (quantidade essa que muda a todo instante) ou ainda a milésima casa do <span class="math inline">\(\pi\)</span> (algum número de 0 a 9, fixo porém desconhecido no momento dessa leitura).</p></li>
<li><p>A atualização de <em>SUA</em> incerteza sobre <span class="math inline">\(\theta,\)</span> incorporando uma nova informação trazida pelos dados <span class="math inline">\(\boldsymbol x\)</span> (representada por <span class="math inline">\(f(\boldsymbol x| \theta)\)</span>) é feita pelo <em>Teorema de Bayes</em>:</p></li>
<li><p><strong>Teorema de Bayes:</strong></p></li>
</ul>
<p><span class="math display">\[\underbrace{f(\theta| \boldsymbol x)}_{dist. posteriori}=~~\dfrac{f(\theta)f(\boldsymbol x|\theta)}{\displaystyle \int_{\Theta}f(\boldsymbol x|\theta)dP_\theta} ~\propto~ \underbrace{f(\theta)}_{priori}\overbrace{f(\boldsymbol x|\theta)}^{verossimilhança}.\]</span></p>
<!-- $$\underbrace{f(\theta| \boldsymbol x)}_{dist. posteriori} = \dfrac{f(\boldsymbol{x}| \theta)}{\int_{\Theta}f(\boldsymbol x|\theta)dP_\theta} \propto f(\boldsymbol x|\theta).$$ -->
<ul>
<li>Toda a inferência sobre <span class="math inline">\(\theta\)</span> será baseada exclusivamente em <span class="math inline">\(f(\theta| \boldsymbol x)\)</span>, não sendo necessário considerar pontos amostrais que poderiam mas não foram observados (como é feito na inferência frequentista).</li>
</ul>
<p><span class="math inline">\(~\)</span></p>
<ul>
<li><strong>Observação:</strong> será utilizada a notação geral para integral (de Lebesgue): <span class="math display">\[\displaystyle \int_{\Theta}f(\boldsymbol x|\theta)dP_\theta
= \left\{ \begin{array}{ll} \displaystyle \int_{\Theta}f(\boldsymbol x|\theta) f(\theta) d\theta ~&amp;~ (caso~~contínuo)\\
\displaystyle \sum_{\Theta}f(\boldsymbol x|\theta) f(\theta) ~&amp;~ (caso~~discreto) \end{array}\right.\]</span></li>
</ul>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Exemplo 1.a:</strong> Suponha que existem duas moedas, uma delas tem <span class="math inline">\(\theta =1/2\)</span> (honesta) e a outra <span class="math inline">\(\theta=3/4\)</span> (viesada). Uma moeda é escolhida e é feito um lançamento da moeda selecionada. Nesse experimento, tem-se <span class="math inline">\(X|\theta \sim Ber(\theta)\)</span>, com <span class="math inline">\(\Theta=\{1/2,3/4\}\)</span> e <span class="math inline">\(\mathfrak{X}=\{0,1\}\)</span>. Como “chutar” o valor de <span class="math inline">\(\theta\)</span>?</p>
<p>Considere que não existe razão para você acreditar que há algum tipo de preferência na escolha de uma ou outra moeda, isto é, considere que a priori <span class="math inline">\(f(\theta=1/2)\)</span> <span class="math inline">\(=f(\theta=3/4)\)</span> <span class="math inline">\(=1/2\)</span>. Suponha que o lançamento resultou em cara (<span class="math inline">\(x=1\)</span>). Então</p>
<p><span class="math inline">\(f(\theta = 3/4|X=1)\)</span> <span class="math inline">\(=\dfrac{f(X=1|\theta=3/4)f(\theta=3/4)}{\sum_\theta f(X=1|\theta)f(\theta)}\)</span> <span class="math inline">\(=\dfrac{\dfrac{3}{4}\dfrac{1}{2}}{\dfrac{3}{4}~\dfrac{1}{2}+\dfrac{1}{2}~\dfrac{1}{2}}=\)</span> <span class="math inline">\(\dfrac{3/4}{5/4}=\dfrac{3}{5}\)</span> <span class="math inline">\(= 1-\underbrace{f(\theta=1/2|X=1)}_{2/5}\)</span>.</p>
<p>Se, no entando, o resultado do lançamento da moeda fosse coroa (<span class="math inline">\(x=0\)</span>), teríamos</p>
<p><span class="math inline">\(P(\theta=3/4|X=0)\)</span> <span class="math inline">\(=\dfrac{\dfrac{1}{4}~\dfrac{1}{2}}{\dfrac{1}{4}~\dfrac{1}{2}+\dfrac{1}{2}~\dfrac{1}{2}}\)</span> <span class="math inline">\(=\dfrac{1/2}{1/2+2/2}=\dfrac{1}{3}\)</span>.</p>
<p><img src="InfBayes_files/figure-html/unnamed-chunk-3-1.gif" width="80%" style="display: block; margin: auto;" />
Assim, se sua decisão for escolher o valor mais provável de <span class="math inline">\(\theta\)</span> após observar <span class="math inline">\(x\)</span>, a conclusão seria que a moeda é viesada <span class="math inline">\((\theta=3/4)\)</span> se for observado cara <span class="math inline">\((x=1)\)</span> e que a moeda é honesta <span class="math inline">\((\theta=1/2)\)</span> se o resultado for coroa <span class="math inline">\((x=0)\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Exemplo 1.b:</strong> Considere agora que serão realizados <span class="math inline">\(n\)</span> lançamentos da moeda, de modo que agora tem-se <span class="math inline">\(X|\theta \sim Bin(n,\theta)\)</span>, <span class="math inline">\(\theta \in \{1/2,3/4\}\)</span>, <span class="math inline">\(x \in \{0,1,\ldots,n\}\)</span>. Suponha que observa-se <span class="math inline">\(X=x\)</span>.</p>
<p><span class="math inline">\(f(\theta=3/4|X=x)\)</span> <span class="math inline">\(=\dfrac{f(x|\theta=3/4)f(\theta=3/4)}{\displaystyle \sum_{\theta\in \{1/2,3/4\}}f(x|\theta)f(\theta)}\)</span> <span class="math inline">\(=\dfrac{\displaystyle \binom{n}{x}\left(\dfrac{3}{4}\right)^x\left(\dfrac{1}{4}\right)^{n-x}\dfrac{1}{2}}{\displaystyle \binom{n}{x}\left(\dfrac{3}{4}\right)^x\left(\dfrac{1}{4}\right)^{n-x}\dfrac{1}{2}+\displaystyle\binom{n}{x}\left(\dfrac{1}{2}\right)^x\left(\dfrac{1}{2}\right)^{n-x}\dfrac{1}{2}}\)</span> <span class="math inline">\(=\dfrac{1}{1+\left(\dfrac{2^n}{3^x}\right)}\)</span> <span class="math inline">\(=\dfrac{3^x}{3^x + 2^n}\)</span>.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="Bayes.html#cb1-1"></a>theta =<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.5</span>,<span class="fl">0.75</span>)</span>
<span id="cb1-2"><a href="Bayes.html#cb1-2"></a>prior=<span class="fl">0.5</span> <span class="co"># priori P(theta[1]) = 1-P(theta[2])</span></span>
<span id="cb1-3"><a href="Bayes.html#cb1-3"></a>n=<span class="dv">5</span>;</span>
<span id="cb1-4"><a href="Bayes.html#cb1-4"></a>post =<span class="st"> </span><span class="cf">function</span>(x){ </span>
<span id="cb1-5"><a href="Bayes.html#cb1-5"></a>  (prior<span class="op">*</span><span class="kw">dbinom</span>(x,n,theta)) <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(prior <span class="op">*</span><span class="st"> </span><span class="kw">dbinom</span>(x,n,theta)) }</span>
<span id="cb1-6"><a href="Bayes.html#cb1-6"></a><span class="kw">tibble</span>(<span class="dt">x=</span><span class="kw">as.factor</span>(<span class="kw">rep</span>(<span class="kw">seq</span>(<span class="dv">0</span>,n),<span class="dt">each=</span><span class="kw">length</span>(theta))),</span>
<span id="cb1-7"><a href="Bayes.html#cb1-7"></a>    <span class="dt">x1=</span><span class="kw">rep</span>(theta,(n<span class="op">+</span><span class="dv">1</span>)),<span class="dt">x2=</span><span class="kw">rep</span>(theta,(n<span class="op">+</span><span class="dv">1</span>)),<span class="dt">y1=</span><span class="dv">0</span>,</span>
<span id="cb1-8"><a href="Bayes.html#cb1-8"></a>    <span class="dt">y2=</span><span class="kw">as.vector</span>(<span class="kw">apply</span>(<span class="kw">matrix</span>(<span class="kw">seq</span>(<span class="dv">0</span>,n)),<span class="dv">1</span>,post))) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1-9"><a href="Bayes.html#cb1-9"></a><span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span><span class="kw">geom_hline</span>(<span class="dt">yintercept=</span><span class="fl">0.5</span>,<span class="dt">col=</span><span class="st">&quot;darkgrey&quot;</span>,<span class="dt">lty=</span><span class="dv">3</span>) <span class="op">+</span></span>
<span id="cb1-10"><a href="Bayes.html#cb1-10"></a><span class="st">  </span><span class="kw">geom_segment</span>(<span class="kw">aes</span>(<span class="dt">x=</span>x1, <span class="dt">xend=</span>x2, <span class="dt">y=</span>y1,<span class="dt">yend=</span>y2,<span class="dt">colour=</span>x),<span class="dt">lwd=</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb1-11"><a href="Bayes.html#cb1-11"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>(theta)) <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&quot;P(&quot;</span>,theta,<span class="st">&quot;|x)&quot;</span>))) <span class="op">+</span><span class="st">   </span></span>
<span id="cb1-12"><a href="Bayes.html#cb1-12"></a><span class="st">  </span><span class="kw">theme_bw</span>()<span class="op">+</span></span>
<span id="cb1-13"><a href="Bayes.html#cb1-13"></a><span class="st">  </span>gganimate<span class="op">::</span><span class="kw">transition_states</span>(x)</span></code></pre></div>
<p><img src="InfBayes_files/figure-html/unnamed-chunk-5-1.gif" width="80%" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(~\)</span></p>
<p>Note que o Exemplo 1.a é um caso particular desse exemplo com <span class="math inline">\(n=1\)</span>. Se novamente sua decisão é baseada no valor mais provável de <span class="math inline">\(\theta\)</span>, temos</p>
<p><span class="math inline">\(f(\theta=3/4|X=x) &gt; \dfrac{1}{2}\)</span> <span class="math inline">\(\Longleftrightarrow \dfrac{3^x}{3^x + 2^n} &gt; \dfrac{1}{2}\)</span> <span class="math inline">\(\Longleftrightarrow {3^x} &gt; {2^n}\)</span> <span class="math inline">\(\Longleftrightarrow \dfrac{x}{n} = \bar{x} &gt; \log_3{2}\approx 0,63\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Exemplo 1.c:</strong> Considere que uma moeda será lançada <span class="math inline">\(n\)</span> vezes mas que <span class="math inline">\(\theta\)</span> é desconhecido, de modo que <span class="math inline">\(\Theta = [0,1]\)</span>. Para simplificar, vamos assumir <span class="math inline">\(f(\theta)=\mathbb{I}_{[0,1]}(\theta)\)</span>, isto é, <span class="math inline">\(\theta \sim Unif(0,1)\sim Beta(1,1)\)</span>. Essa priori corresponde ao caso em que você acredita que todos os valores possíveis para <span class="math inline">\(\theta\)</span> são igualmente “prováveis”, assim como nos exemplos anteriores. Novamente, <span class="math inline">\(X|\theta \sim Bin(n,\theta)\)</span></p>
<p><span class="math inline">\(f(\theta|x)=\)</span> <span class="math inline">\(\dfrac{f(x|\theta)f(\theta)}{\int_0^1 f(x|\theta)f(\theta)d\theta}=\)</span> <span class="math inline">\(\dfrac{\binom{n}{x}\theta^x(1-\theta)^{n-x} ~~\mathbb{I}_{[0,1]}(\theta)}{\int_0^1\binom{n}{x}\theta^x(1-\theta)^{n-x}d\theta}=\)</span> <span class="math inline">\(\dfrac{\dfrac{\Gamma(1+x+1+n-x)}{\Gamma(1+x)\Gamma(1+n-x)}~~\theta^x(1-\theta)^{n-x}~~\mathbb{I}_{[0,1]}(\theta)}{\underbrace{\displaystyle \int_0^1\dfrac{\Gamma(1+x+1+n-x)}{\Gamma(1+x)\Gamma(1+n-x)}~~\theta^x(1-\theta)^{n-x}d\theta}_{1}}\)</span> <span class="math inline">\(=\dfrac{\Gamma(1+x+1+n-x)}{\Gamma(1+x)\Gamma(1+n-x)}~~\theta^x(1-\theta)^{n-x}~~\mathbb{I}_{[0,1]}(\theta)\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p>Logo <span class="math inline">\(\theta|x \sim Beta(1+x,1+n-x)\)</span>. Nesse exemplo, o valor “mais provável” (com maior densidade a posteriori) para <span class="math inline">\(\theta\)</span> é a moda da distribuição, <span class="math inline">\(Moda(\theta|x)\)</span> <span class="math inline">\(= \dfrac{(1+x)-1}{(1+x)+(1+n-x)-2}\)</span> <span class="math inline">\(= \dfrac{x}{n}\)</span> <span class="math inline">\(=\bar{x}\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Exemplo 1.d</strong> Por fim, suponha que no exemplo anterior, sua opinião a priori é representada por uma distribuição beta qualquer com parâmetros <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span>, <span class="math inline">\(a,b &gt; 0\)</span>. Desta forma, <span class="math inline">\(X|\theta \sim Bin(n,\theta)\)</span> e <span class="math inline">\(\theta\sim Beta(a,b)\)</span>. Calculando a distribuição a posteriori de forma similar ao exemplo anterior, temos que <span class="math inline">\(\theta|X=x \sim Beta(a+x,b+n-x)\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="Bayes.html#cb2-1"></a><span class="kw">require</span>(transformr)</span>
<span id="cb2-2"><a href="Bayes.html#cb2-2"></a>theta =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.01</span>)</span>
<span id="cb2-3"><a href="Bayes.html#cb2-3"></a>a=<span class="dv">1</span>; b=<span class="dv">1</span>;</span>
<span id="cb2-4"><a href="Bayes.html#cb2-4"></a>n=<span class="dv">5</span></span>
<span id="cb2-5"><a href="Bayes.html#cb2-5"></a>post1 =<span class="st"> </span><span class="kw">as.vector</span>(<span class="kw">apply</span>(<span class="kw">matrix</span>(<span class="kw">seq</span>(<span class="dv">0</span>,n)),<span class="dv">1</span>,</span>
<span id="cb2-6"><a href="Bayes.html#cb2-6"></a>            <span class="cf">function</span>(x){<span class="kw">dbeta</span>(theta,a<span class="op">+</span>x,b<span class="op">+</span>n<span class="op">-</span>x)}))</span>
<span id="cb2-7"><a href="Bayes.html#cb2-7"></a><span class="kw">tibble</span>(<span class="dt">x=</span><span class="kw">as.factor</span>(<span class="kw">rep</span>(<span class="kw">seq</span>(<span class="dv">0</span>,n),<span class="dt">each=</span><span class="kw">length</span>(theta))),</span>
<span id="cb2-8"><a href="Bayes.html#cb2-8"></a>    <span class="dt">theta=</span><span class="kw">rep</span>(theta,(n<span class="op">+</span><span class="dv">1</span>)),<span class="dt">post=</span>post1) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2-9"><a href="Bayes.html#cb2-9"></a><span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb2-10"><a href="Bayes.html#cb2-10"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>theta,<span class="dt">y=</span>post, <span class="dt">colour=</span>x),<span class="dt">lwd=</span><span class="fl">1.5</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb2-11"><a href="Bayes.html#cb2-11"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>theta,<span class="dt">y=</span><span class="kw">dbeta</span>(theta,a,b),<span class="dt">colour=</span><span class="st">&quot;Prior&quot;</span>),<span class="dt">lwd=</span><span class="dv">1</span>,<span class="dt">lty=</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb2-12"><a href="Bayes.html#cb2-12"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>(theta)) <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&quot;f(&quot;</span>,theta,<span class="st">&quot;|x)&quot;</span>))) <span class="op">+</span></span>
<span id="cb2-13"><a href="Bayes.html#cb2-13"></a><span class="st">  </span><span class="kw">theme_bw</span>()<span class="op">+</span></span>
<span id="cb2-14"><a href="Bayes.html#cb2-14"></a><span class="st">  </span>gganimate<span class="op">::</span><span class="kw">transition_states</span>(x)</span></code></pre></div>
<p><img src="InfBayes_files/figure-html/unnamed-chunk-7-1.gif" width="80%" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(~\)</span></p>
<p>Suponha que <span class="math inline">\(a=b=1\)</span> (como no exemplo anterior), <span class="math inline">\(n=5\)</span> e <span class="math inline">\(x=2\)</span>, de modo que <span class="math inline">\(\theta|x=2 \sim Beta(3,4)\)</span>. Algumas medidas resumo da distribuição posterior para esse exemplo são</p>
<ul>
<li><p><span class="math inline">\(Moda(\theta|x)\)</span> <span class="math inline">\(=\dfrac{a+x-1}{a+b+n-2}\)</span> <span class="math inline">\(=\dfrac{2}{5}\)</span> <span class="math inline">\(=0,4\)</span>;</p></li>
<li><p><span class="math inline">\(E[\theta|x]\)</span> <span class="math inline">\(=\dfrac{a+x}{a+b+n}\)</span> <span class="math inline">\(=\dfrac{3}{7}\)</span> <span class="math inline">\(=0,43\)</span>;</p></li>
<li><p><span class="math inline">\(Med(\theta|x)\)</span> <span class="math inline">\(\approx \dfrac{a+x-1/3}{a+b+n-2/3}\)</span> <span class="math inline">\(=\dfrac{8/3}{19/3}\)</span> <span class="math inline">\(\approx 0,42\)</span>;</p></li>
<li><p><span class="math inline">\(Var(\theta|x)\)</span> <span class="math inline">\(=\dfrac{(a+x)(b+n-x)}{(a+b+n)^2(a+b+n+1)}\)</span> <span class="math inline">\(=\dfrac{12}{392}\)</span> <span class="math inline">\(\approx 0,031\)</span>.</p></li>
</ul>
<p><span class="math inline">\(~\)</span></p>
</div>
</div>
<div id="suficiência" class="section level2">
<h2><span class="header-section-number">2.2</span> Suficiência</h2>
<p>Muitas vezes, a quantidade de dados é muito grande e desejamos “resumir” a informação trazida pelos dados. Uma forma de fazê-lo sem perder informação sobre o parâmetro de interesse é usar uma <em>estatística suficiente</em>.</p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Definição:</strong> Dizemos que uma função da amostra <span class="math inline">\(T:\mathfrak{X} \rightarrow \mathbb{R}^p\)</span> é uma <em>estatística suficiente</em> (do ponto de vista <em>frequentista</em>) se <span class="math inline">\(f\left(\boldsymbol x | T(\boldsymbol x),\theta\right) = f\left(\boldsymbol x | T(\boldsymbol x)\right)\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p>Em palavras, conhecendo o valor da estatística suficiente, a distribuição da amostra (do v.a. <span class="math inline">\(\boldsymbol X\)</span>) não depende mais do parâmetro <span class="math inline">\(\theta\)</span>. Isso quer dizer que a informação disponível na amostra <span class="math inline">\(\boldsymbol X\)</span> sobre <span class="math inline">\(\theta\)</span> está contida em <span class="math inline">\(T(\boldsymbol X)\)</span>. Obter uma estatística suficiente nem sempre é uma tarefa fácil mas o resultado a seguir, conhecido como <em>critério da fatoração</em> permite identificar estatísticas suficientes.</p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Teorema:</strong> A estatística <span class="math inline">\(T:\mathfrak{X} \rightarrow \mathbb{R}^p\)</span> é suficiente para a família de distribuições <span class="math inline">\(\left\{f(\cdot|\theta):\theta \in \Theta\right\}\)</span> se, e somente se, para todo <span class="math inline">\(x \in \mathfrak{X}\)</span> e para todo <span class="math inline">\(\theta \in \Theta\)</span>, podemos escrever <span class="math inline">\(f\left(\boldsymbol x | \theta\right)\)</span> <span class="math inline">\(= u(\boldsymbol x) v\left(T(\boldsymbol x),\theta\right)\)</span>, onde <span class="math inline">\(u\)</span> é uma função positiva que não depende de <span class="math inline">\(\theta\)</span> e <span class="math inline">\(v\)</span> é uma função não-negativa e depende de <span class="math inline">\(\boldsymbol x\)</span> somente através de <span class="math inline">\(T(\boldsymbol x)\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Exemplo:</strong> Seja <span class="math inline">\(X_1,\ldots,X_n\)</span> v.a. tais que, condicional ao conhecimento de <span class="math inline">\(\theta\)</span>, são c.i.i.d. com <span class="math inline">\(X_1|\theta \sim Exp(\theta)\)</span>. Então,</p>
<p><span class="math inline">\(f(\boldsymbol x|\theta)\)</span> <span class="math inline">\(=\prod f(x_i|\theta)\)</span> <span class="math inline">\(=\prod \theta e^{-\theta x_i} ~\mathbb{I}_{\mathbb{R+}}(x_i)\)</span> <span class="math inline">\(=\theta^n e^{-\theta \sum x_i} ~\prod ~\mathbb{I}_{\mathbb{R+}}(x_i)\)</span> <span class="math inline">\(= v\left(\sum x_i, \theta\right) u(\boldsymbol x)\)</span>.</p>
<p>Portanto, <span class="math inline">\(T(\boldsymbol x) = \sum x_i\)</span> é estatística suficiente para <span class="math inline">\(\theta\)</span>. De fato, como <span class="math inline">\(T(\boldsymbol X)\)</span> <span class="math inline">\(= \sum X_i | \theta\)</span> <span class="math inline">\(\sim Gama(n,\theta)\)</span> e <span class="math inline">\(\left\{X_1=x_1,\ldots,X_n=x_n\right\}\)</span> <span class="math inline">\(\subseteq \left\{T(\boldsymbol X) = \sum X_i = \sum x_i = t\right\}\)</span>,</p>
<p><span class="math inline">\(f\left(\boldsymbol x| T(\boldsymbol x),\theta\right)\)</span> <span class="math inline">\(=\dfrac{f\left(\boldsymbol{x},T(\boldsymbol{x})|\theta\right)}{f\left(T(\boldsymbol{x})|\theta\right)}\)</span> <span class="math inline">\(=\dfrac{f\left(\boldsymbol{x}|\theta\right)}{f\left(\sum{X_i}|\theta\right)}\)</span> <span class="math inline">\(=\dfrac{\theta^n e^{\theta \sum x_i} ~\prod ~\mathbb{I}_{\mathbb{R+}}(x_i)}{\frac{\theta^n}{\Gamma(n)}t^{n-1} e^{\theta t} ~\prod ~\mathbb{I}_{\mathbb{R+}}(x_i)}\)</span> <span class="math inline">\(= \dfrac{\Gamma(n)}{t^{n-1}} ~\mathbb{I}_{\mathbb{R}_+}\left(t\right)\)</span>,</p>
<p>que não depende de <span class="math inline">\(\theta\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p>Sob o enfoque bayesiano, a definição de suficiência é um pouco mais intuitiva que a frequentista.</p>
<p><strong>Definição:</strong> Dizemos que uma função da amostra <span class="math inline">\(T:\mathfrak{X} \rightarrow \mathbb{R}^p\)</span> é uma <em>estatística suficiente</em> (no sentido <em>bayesiano</em>) se <span class="math inline">\(f\left(\theta | T(\boldsymbol x)\right) = f\left(\theta | \boldsymbol x\right)\)</span>, para todo <span class="math inline">\(x \in \mathfrak{X}\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p>Voltando ao exemplo, suponha agora que, a priori, <span class="math inline">\(\theta \sim Gama(a,b)\)</span>. Então,</p>
<p><span class="math inline">\(f(\theta| \boldsymbol x)\)</span> <span class="math inline">\(\propto f(\boldsymbol x|\theta)f(\theta)\)</span> <span class="math inline">\(\propto \theta^n e^{-\theta \sum x_i} ~~\theta^{a-1}e^{-b\theta}\)</span> <span class="math inline">\(\propto \theta^{a+n-1} e^{-(b+\sum x_i)\theta}\)</span></p>
<p>Seja <span class="math inline">\(T = T(\boldsymbol X) = \sum X_i\)</span>, temos que <span class="math inline">\(T|\theta\sim Gamma(n,\theta)\)</span>, de modo que</p>
<p><span class="math inline">\(f\left(\theta| T(\boldsymbol x)=t\right)\)</span> <span class="math inline">\(\propto f(t|\theta)f(\theta)\)</span> <span class="math inline">\(\propto \theta^n t^{n-1} e^{\theta t} ~~\theta^{a-1}e^{-b\theta}\)</span> <span class="math inline">\(\propto \theta^{a+n-1} e^{-(b+t)\theta}\)</span> , com <span class="math inline">\(t=\sum x_i\)</span>.</p>
<p>Assim, <span class="math inline">\(\theta|\boldsymbol x\)</span> <span class="math inline">\(\sim \theta|T(\boldsymbol x)\)</span> <span class="math inline">\(\sim Gamma\left(a+n,b+\sum x_i\right)\)</span> e, portanto, <span class="math inline">\(T(\boldsymbol X) = \sum X_i\)</span> é estatística suficiente para <span class="math inline">\(\theta\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p>Para os casos mais comuns, as definições são equivalentes <span class="citation">(Schervish <a href="#ref-Schervish12" role="doc-biblioref">2012</a>)</span>. Pelo teorema da fatoração, temos que <span class="math inline">\(f\left(\boldsymbol x | \theta\right)\)</span> <span class="math inline">\(= u(\boldsymbol x) v\left(T(\boldsymbol x),\theta\right)\)</span> e, portanto</p>
<p><span class="math inline">\(f(\theta|\boldsymbol x)\)</span> <span class="math inline">\(\propto f(\theta) f\left(\boldsymbol x | \theta\right)\)</span> <span class="math inline">\(\propto f(\theta) v\left(T(\boldsymbol x),\theta\right)\)</span></p>
<p>que só depende de <span class="math inline">\(\boldsymbol x\)</span> por meio de <span class="math inline">\(T(\boldsymbol x)\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p>Um dos princípios de inferência estatística é o <em>princípio da suficiência</em>. Segundo este, se <span class="math inline">\(T\)</span> é uma estatística suficiente para <span class="math inline">\(\theta\)</span> e se dois pontos amostrais <span class="math inline">\(\boldsymbol x, \boldsymbol y \in \mathfrak{X}\)</span> são tais que <span class="math inline">\(T(\boldsymbol x)=T(\boldsymbol y)\)</span> então as inferências baseadas nesses pontos devem ser as mesmas. Adiante, retomaremos esse princípio de forma mais formal.</p>
<p><span class="math inline">\(~\)</span></p>
<!-- ## Aula 09  -->
</div>
<div id="distribuição-a-priori" class="section level2">
<h2><span class="header-section-number">2.3</span> Distribuição a Priori</h2>
<ul>
<li>A priori é sempre subjetiva (assim como a escolha do modelo estatístico)!
<ul>
<li>Por exemplo, dizer que os dados seguem uma distribuição normal, é uma escolha subjetiva, muitas vezes baseadas nas facilidades matemáticas que essa distribuição proporciona.<br />
</li>
<li>Do mesmo modo, suponha que dois indivíduos que consideram que a distribuição do parêmetro é simétrica, com mesmas suposições sobre média e variância. O primeiro pode optar por representar sua distribuição usando uma distribuição Normal, enquanto o segundo pode utilizar uma distribuição T ou Cauchy.<br />
</li>
</ul></li>
<li>Não existe “opinião errada”, existem opiniões diferentes, dado o nível de conhecimento e as experiências prévias do indivíduo.<br />
</li>
<li>A priori deve ser sua opinião apenas sobre o parâmetro <span class="math inline">\(\theta\)</span> e não deve depender de fatores como o desenho do experimento ou o objetivo do estudo.</li>
</ul>
<!-- ### Prioris Baseada na Opinião de um Especialista -->
<div id="método-do-histograma" class="section level3">
<h3><span class="header-section-number">2.3.1</span> Método do Histograma</h3>
<ul>
<li><p>Muitas vezes, para “extrair” o conhecimento de um especialista, podemos dividir o espaço paramétrico em regiões e pedir para o especialista “ordenar” esses conjuntos, utilizando “pesos” que refletem a crença que o parâmetro esteja em cada uma daquelas regiões.</p></li>
<li><p><strong>Exemplo 1.</strong> (<span class="citation">Albert (<a href="#ref-Albert09" role="doc-biblioref">2009</a>)</span>, pág 27)</p>
<ul>
<li>Seja <span class="math inline">\(\theta\)</span> uma proporção desconhecida <span class="math inline">\((\Theta=[0,1])\)</span>;<br />
</li>
<li>Considere a partição <span class="math inline">\(T = \left\{[0,0.1), [0.1,0.2), \ldots, [0.9,1] \right\}\)</span>;</li>
<li>Suponha que um especialistas atribui pesos <span class="math inline">\(p=(1, 5.2, 8, 7.2, 4.6, 2.1, 0.7, 0.1, 0, 0)\)</span> a esse intervalos;<br />
</li>
<li>A piori, nesse caso, é o histograma apresentado a seguir.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="Bayes.html#cb3-1"></a>p=<span class="kw">c</span>(<span class="dv">1</span>, <span class="fl">5.2</span>, <span class="dv">8</span>, <span class="fl">7.2</span>, <span class="fl">4.6</span>, <span class="fl">2.1</span>, <span class="fl">0.7</span>, <span class="fl">0.1</span>, <span class="dv">0</span>, <span class="dv">0</span>)</span>
<span id="cb3-2"><a href="Bayes.html#cb3-2"></a>prior =<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>,p<span class="op">/</span>(<span class="kw">sum</span>(p)))</span>
<span id="cb3-3"><a href="Bayes.html#cb3-3"></a><span class="kw">tibble</span>(<span class="dt">theta=</span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.1</span>), prior) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb3-4"><a href="Bayes.html#cb3-4"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="dt">data=</span>.) <span class="op">+</span></span>
<span id="cb3-5"><a href="Bayes.html#cb3-5"></a><span class="st">  </span><span class="kw">geom_step</span>(<span class="kw">aes</span>(<span class="dt">x=</span>theta,<span class="dt">y=</span>prior),<span class="dt">direction=</span><span class="st">&quot;vh&quot;</span>,<span class="dt">color=</span><span class="st">&quot;red&quot;</span>,<span class="dt">lwd=</span><span class="fl">1.5</span>)</span></code></pre></div>
<p><img src="InfBayes_files/figure-html/unnamed-chunk-8-1.png" width="80%" style="display: block; margin: auto;" /></p>
<ul>
<li>Voltando ao exemplo da moeda, suponha novamente que foram observados <span class="math inline">\(x=2\)</span> sucessos em <span class="math inline">\(n=5\)</span> lançamentos. A posteriori nesse caso pode ser obtida multiplicando a distribuição a priori pela verossimilhança e “padronizando” a função obtida. Assim:</li>
</ul>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="Bayes.html#cb4-1"></a>n=<span class="dv">5</span></span>
<span id="cb4-2"><a href="Bayes.html#cb4-2"></a>x=<span class="dv">2</span></span>
<span id="cb4-3"><a href="Bayes.html#cb4-3"></a>p =<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="fl">5.2</span>, <span class="dv">8</span>, <span class="fl">7.2</span>, <span class="fl">4.6</span>, <span class="fl">2.1</span>, <span class="fl">0.7</span>, <span class="fl">0.1</span>, <span class="dv">0</span>, <span class="dv">0</span>)</span>
<span id="cb4-4"><a href="Bayes.html#cb4-4"></a>p =<span class="st"> </span>p<span class="op">/</span>(<span class="kw">sum</span>(p))</span>
<span id="cb4-5"><a href="Bayes.html#cb4-5"></a>theta =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.01</span>)</span>
<span id="cb4-6"><a href="Bayes.html#cb4-6"></a>prior =<span class="st"> </span><span class="kw">c</span>(<span class="kw">rep</span>(p,<span class="dt">each=</span><span class="dv">10</span>),<span class="dv">0</span>)<span class="op">/</span><span class="kw">sum</span>(<span class="kw">c</span>(<span class="kw">rep</span>(p,<span class="dt">each=</span><span class="dv">10</span>),<span class="dv">0</span>))</span>
<span id="cb4-7"><a href="Bayes.html#cb4-7"></a>vero =<span class="st"> </span><span class="kw">dbinom</span>(x,n,theta)<span class="op">/</span><span class="kw">sum</span>(<span class="kw">dbinom</span>(x,n,theta))</span>
<span id="cb4-8"><a href="Bayes.html#cb4-8"></a>post =<span class="st"> </span>(prior <span class="op">*</span><span class="st"> </span>vero)<span class="op">/</span><span class="kw">sum</span>(prior <span class="op">*</span><span class="st"> </span>vero)</span>
<span id="cb4-9"><a href="Bayes.html#cb4-9"></a>pH =<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">theta=</span><span class="kw">rep</span>(theta,<span class="dv">3</span>),<span class="dt">dens=</span><span class="kw">c</span>(prior,vero,post),<span class="dt">Dist=</span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&#39;1.priori&#39;</span>,<span class="st">&#39;2.verossimilhança&#39;</span>,<span class="st">&#39;3.posteriori&#39;</span>),<span class="dt">each=</span><span class="dv">101</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb4-10"><a href="Bayes.html#cb4-10"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="dt">data=</span>.) <span class="op">+</span></span>
<span id="cb4-11"><a href="Bayes.html#cb4-11"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>theta,<span class="dt">y=</span>dens,<span class="dt">colour=</span>Dist),<span class="dt">lwd=</span><span class="fl">1.5</span>)</span>
<span id="cb4-12"><a href="Bayes.html#cb4-12"></a>pH</span></code></pre></div>
<p><img src="InfBayes_files/figure-html/unnamed-chunk-9-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(~\)</span></p>
</div>
<div id="elicitação-de-hiperparâmetros" class="section level3">
<h3><span class="header-section-number">2.3.2</span> Elicitação de Hiperparâmetros</h3>
<ul>
<li>Nessa abordagem, a priori é obtida da seguinte maneira:
<ol style="list-style-type: decimal">
<li>Escolha uma família de distribuições conveniente. O conceito de “conveniência” aqui pode levar em conta, por exemplo, o suporte da distribuição, se é flexível o suficiente para acomodar diversos tipos de opinião, se permite a obtenção analítica da posteriori e assim por diante;<br />
</li>
<li>Obtenha um conjunto de medidas resumo (como média, variância, quantis, etc.);<br />
</li>
<li>Utilize as medidas resumo para calcular hiperparâmetros da distribuição escolhida.</li>
</ol></li>
</ul>
<p><span class="math inline">\(~\)</span></p>
<ul>
<li><p><strong>Exemplo:</strong> Na seção anterior, a priori dada pelo histograma tem média <span class="math inline">\(m=0.31\)</span> e variância aproximadamente <span class="math inline">\(v=0.02\)</span>. Podemos utilizar como priori, por exemplo, uma distribuição beta com essa média e variância, já que a beta tem um suporte conveniente e facilita as contas, como também já vimos. Assim, vamos considerar uma distribuição <span class="math inline">\(Beta(a,b)\)</span> e escolher <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span> satisfazendo:</p>
<ol style="list-style-type: lower-roman">
<li><span class="math inline">\(E[\theta]\)</span> <span class="math inline">\(=\dfrac{a}{a+b}\)</span> <span class="math inline">\(=m\)</span> <span class="math inline">\(\Longleftrightarrow b=\left(\dfrac{1-m}{m}\right)a\)</span></li>
<li><span class="math inline">\(Var(\theta)\)</span> <span class="math inline">\(=\dfrac{ab}{(a+b)^2(a+b+1)}\)</span> <span class="math inline">\(=0.02\)</span> <span class="math inline">\(\Longleftrightarrow a=\dfrac{m(m-m^2-v)}{v}\)</span></li>
</ol></li>
</ul>
<p>Resolvendo o sistema temos, de forma geral, que <span class="math inline">\(a=\dfrac{m(m-m^2-v)}{v}\)</span> e <span class="math inline">\(b=\dfrac{(1-m)(m-m^2-v)}{v}\)</span>.</p>
<p>Assim, no nosso exemplo, teríamos uma <span class="math inline">\(Beta(3,6.7)\)</span>. Além disso, já vimos que, nesse caso, a distribuição a posteriori é <span class="math inline">\(Beta(3+x,6.7+n-x)\)</span>. Considerando novamente <span class="math inline">\(n=5\)</span> e <span class="math inline">\(x=2\)</span>, temos:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="Bayes.html#cb5-1"></a>n=<span class="dv">5</span>; x=<span class="dv">2</span></span>
<span id="cb5-2"><a href="Bayes.html#cb5-2"></a>m=<span class="fl">0.31</span>; v=<span class="fl">0.02</span></span>
<span id="cb5-3"><a href="Bayes.html#cb5-3"></a>a=m<span class="op">*</span>(m<span class="op">-</span>m<span class="op">^</span><span class="dv">2</span><span class="op">-</span>v)<span class="op">/</span>v; b=(<span class="dv">1</span><span class="op">-</span>m)<span class="op">*</span>(m<span class="op">-</span>m<span class="op">^</span><span class="dv">2</span><span class="op">-</span>v)<span class="op">/</span>v</span>
<span id="cb5-4"><a href="Bayes.html#cb5-4"></a>p =<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="fl">5.2</span>, <span class="dv">8</span>, <span class="fl">7.2</span>, <span class="fl">4.6</span>, <span class="fl">2.1</span>, <span class="fl">0.7</span>, <span class="fl">0.1</span>, <span class="dv">0</span>, <span class="dv">0</span>)</span>
<span id="cb5-5"><a href="Bayes.html#cb5-5"></a>p =<span class="st"> </span>p<span class="op">/</span>(<span class="kw">sum</span>(p))</span>
<span id="cb5-6"><a href="Bayes.html#cb5-6"></a>theta =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.01</span>)</span>
<span id="cb5-7"><a href="Bayes.html#cb5-7"></a>prior =<span class="st"> </span><span class="kw">dbeta</span>(theta,a,b)<span class="op">/</span><span class="kw">sum</span>(<span class="kw">dbeta</span>(theta,a,b))</span>
<span id="cb5-8"><a href="Bayes.html#cb5-8"></a>vero =<span class="st"> </span><span class="kw">dbinom</span>(x,n,theta)<span class="op">/</span><span class="kw">sum</span>(<span class="kw">dbinom</span>(x,n,theta))</span>
<span id="cb5-9"><a href="Bayes.html#cb5-9"></a>post =<span class="st"> </span><span class="kw">dbeta</span>(theta,a<span class="op">+</span>x,b<span class="op">+</span>n<span class="op">-</span>x)<span class="op">/</span><span class="kw">sum</span>(<span class="kw">dbeta</span>(theta,a<span class="op">+</span>x,b<span class="op">+</span>n<span class="op">-</span>x))</span>
<span id="cb5-10"><a href="Bayes.html#cb5-10"></a>priorH =<span class="st"> </span><span class="kw">c</span>(<span class="kw">rep</span>(p,<span class="dt">each=</span><span class="dv">10</span>),<span class="dv">0</span>)<span class="op">/</span><span class="kw">sum</span>(<span class="kw">c</span>(<span class="kw">rep</span>(p,<span class="dt">each=</span><span class="dv">10</span>),<span class="dv">0</span>))</span>
<span id="cb5-11"><a href="Bayes.html#cb5-11"></a><span class="kw">tibble</span>(<span class="dt">theta=</span><span class="kw">rep</span>(theta,<span class="dv">4</span>),<span class="dt">dens=</span><span class="kw">c</span>(prior,vero,post,priorH),</span>
<span id="cb5-12"><a href="Bayes.html#cb5-12"></a>    <span class="dt">Dist=</span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&#39;1.Priori Beta&#39;</span>,<span class="st">&#39;2.Verossimilhança&#39;</span>,<span class="st">&#39;3.Posteriori&#39;</span>,<span class="st">&#39;0.Priori Histograma&#39;</span>),<span class="dt">each=</span><span class="dv">101</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb5-13"><a href="Bayes.html#cb5-13"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="dt">data=</span>.) <span class="op">+</span></span>
<span id="cb5-14"><a href="Bayes.html#cb5-14"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>theta,<span class="dt">y=</span>dens,<span class="dt">colour=</span>Dist),<span class="dt">lwd=</span><span class="fl">1.5</span>)</span></code></pre></div>
<p><img src="InfBayes_files/figure-html/unnamed-chunk-10-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(~\)</span></p>
</div>
<div id="prioris-conjugadas" class="section level3">
<h3><span class="header-section-number">2.3.3</span> Prioris Conjugadas</h3>
<p>Como visto no exemplo da moeda, em que a distribuição a priori era <span class="math inline">\(Beta(a,b)\)</span>, a posteriori era facilmente obtida e também estava na classe das distribuições <span class="math inline">\(Beta\)</span>. Em particular, quando observa-se <span class="math inline">\(x\)</span> sucessos em <span class="math inline">\(n\)</span> realizações de ensaios de Bernoulli, a distribuição a posteriori é <span class="math inline">\(Beta(a+x,b+n-x)\)</span>. Isso ocorre pois essa distribuição pertence à uma classe bastante espefícica de distribuições a priori, chamadas distribuições conjugadas.</p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Definição</strong> Seja <span class="math inline">\(\mathcal{P}=\{f(x|\theta):\;\theta \in \Theta\}\)</span> uma família de distribuições (condicionais) para <span class="math inline">\(\boldsymbol{X}\)</span> e considere <span class="math inline">\(\mathcal{C}=\{h(\theta|a):\;a\in A\}\)</span> uma família de distribuições para <span class="math inline">\(\theta\)</span>. Dizemos que (a família) <span class="math inline">\(\mathcal{C}\)</span> é <strong>conjugada</strong> para <span class="math inline">\(\mathcal{P}\)</span> se, <span class="math inline">\(\forall \;h(\theta)\in \mathcal{C},\)</span> <span class="math inline">\(h(\theta|\boldsymbol{x})\propto f(\boldsymbol x|\theta)h(\theta) \in \mathcal{C},\forall \boldsymbol x \in \mathfrak{X}.\)</span></p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Resultado 1.</strong> Seja <span class="math inline">\(X\)</span> v.a. tal que, condicional ao conhecimento de <span class="math inline">\(\theta,\)</span> <span class="math inline">\(X|\theta \sim Bin(n,\theta).\)</span> Considere que, a priori, <span class="math inline">\(\theta \sim Beta(a,b).\)</span> Então, <span class="math inline">\(\theta|X=x \sim Beta(a+x,b+n-x).\)</span> Portanto, a família <span class="math inline">\(\mathcal{C}=\{Beta(a_1,a_2):\;(a_1,a_2)\in \mathbb{R}^2_+\}\)</span> é conjugada para <span class="math inline">\(\mathcal{P}=\{Bin(n,\theta):\;\theta \in [0,1]\}.\)</span></p>
<p><span class="math inline">\(~\)</span></p>
<ul>
<li>Esse resultado também vale se
<ol style="list-style-type: decimal">
<li><span class="math inline">\(X_1,...,X_n\)</span> são v.a.s <em>condicionalmente independentes e identicamente distribuidas</em> (c.i.i.d.) com <span class="math inline">\(X_i|\theta \sim Ber(\theta)\)</span><br />
</li>
<li><span class="math inline">\(X_i|\theta\sim Geo(\theta),\)</span> <span class="math inline">\(i=1,...,n \; c.i.i.d.\)</span><br />
</li>
<li><span class="math inline">\(X_i|\theta \sim BinNeg(k,\theta)\)</span><br />
<span class="math inline">\(\theta\sim Beta(a,b)\Rightarrow\)</span> <span class="math inline">\(\theta|\boldsymbol X=\boldsymbol x \sim Beta(a+s,b+f)\)</span> em que <span class="math inline">\(s\)</span> é o número de sucessos e <span class="math inline">\(f\)</span> é o número de fracassos.</li>
</ol></li>
</ul>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Resultado 2.</strong> (<em>generalização do resultado anterior para o caso em que o número de categorias é maior que 2</em>)</p>
<p>Seja <span class="math inline">\(\boldsymbol X | \boldsymbol \theta \sim Multinomial(n,\boldsymbol \theta)\)</span>, isto é, sua função de probabilidade é dada por</p>
<p><span class="math display">\[f(\boldsymbol x| \boldsymbol \theta)= \binom{n}{x_1,x_2,...,x_k}~\prod_{i=1}^{k-1}\theta^i~\underbrace{\left(1-\sum_{i=1}^{k-1}\theta_i\right)^{\displaystyle n-\sum_{i=1}^{k-1}x_i}}_{\displaystyle \theta_k^{~~x_k}}\]</span></p>
<p>em que <span class="math inline">\(\theta_i\in [0,1]\)</span> com <span class="math inline">\(\sum_{i=1}^K\theta_i=1\)</span>, <span class="math inline">\(x_i \in \{0,1,...,n\}\)</span> com <span class="math inline">\(\sum_{i=1}^nx_i=n\)</span> e <span class="math inline">\(\displaystyle \binom{n}{x_1,x_2,...,x_k}=\dfrac{n!}{x_1!x_2!...x_k!}\)</span>.</p>
<p>Considere que, a priori, <span class="math inline">\(\boldsymbol \theta \sim Dirichlet(a_1,...,a_k),\)</span> <span class="math inline">\(a_i &gt; 0, i=1,...,k\)</span>, isto é, a f.d.p. a priori para <span class="math inline">\(\boldsymbol \theta\)</span> é dada por</p>
<p><span class="math display">\[f(\boldsymbol \theta) = \dfrac{\Gamma(\sum_{i=1}^K a_i)}{\Gamma(a_1)\Gamma(a_2)...\Gamma(a_k)}\prod_{i=1}^{k-1}\theta_i^{a_i-1}\bigg(\underbrace{1-\sum_{i=1}^{k-1}\theta_i}_{\theta_k}\bigg)^{a_k-1}.\]</span></p>
<p>Então, a distribuição a posteriori para <span class="math inline">\(\boldsymbol \theta\)</span> é
<span class="math inline">\(\boldsymbol \theta|\boldsymbol X = \boldsymbol x \sim Dirichlet (a_1+x_1,...,a_k+x_k)\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<blockquote>
<p><strong>Demo:</strong> Para verificar o resultado, basta ver que<br />
<span class="math inline">\(f(\boldsymbol\theta|\boldsymbol x)\)</span> <span class="math inline">\(=\dfrac{f(\boldsymbol x| \boldsymbol \theta)f(\boldsymbol \theta)}{\int_\Theta f(\boldsymbol x| \boldsymbol \theta)f(\boldsymbol \theta)d\boldsymbol \theta}\)</span> <span class="math inline">\(\propto f(\boldsymbol x| \boldsymbol \theta)f(\boldsymbol \theta)\)</span> <span class="math inline">\(\propto \prod_{i=1}^{k-1}\theta_i^{(a_i+x_i-1)}\left(1-\sum_{i=1}^{k-1}\theta_i\right)^{(a_k+x_k)-1}\)</span></p>
</blockquote>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Resultado 3.</strong> Seja <span class="math inline">\(X_1,...,X_n\)</span> v.a. c.i.i.d tais que <span class="math inline">\(X_i|\theta \sim Unif(0,\theta)\)</span> e considere que, a priori,<span class="math inline">\(\theta \sim Pareto(a,b)\)</span>. Então <span class="math inline">\(\theta|\boldsymbol X = \boldsymbol x \sim Pareto\left(a+n,max\{b,x_{(n)}\}\right)\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<blockquote>
<p><strong>Demo:</strong><br />
<span class="math inline">\(f(\boldsymbol x|\theta)\)</span> <span class="math inline">\(\overset{ci}{=}\prod_{i=1}^nf(x_i|\theta)\)</span> <span class="math inline">\(\overset{id}{=}\prod_{i=1}^n\dfrac{1}{\theta}\mathbb{I}_{[0,\theta]}(x_i)\)</span> <span class="math inline">\(=\dfrac{1}{\theta^n}\mathbb{I}_{[0,\theta]}(x_{(n)})\)</span> <span class="math inline">\(=\dfrac{1}{\theta^n}\mathbb{I}_{[x_{(n)},+\infty)}(\theta)\)</span><br />
em que <span class="math inline">\(x_{(n)}=max\{x_1,...,x_n\}\)</span>.<br />
<span class="math inline">\(~\)</span><br />
<span class="math inline">\(f(\theta)=\dfrac{ab^a}{\theta^{a+1}}\mathbb{I}_{[b,+\infty]}(\theta)\)</span>.<br />
Então<br />
<span class="math inline">\(f(\theta| \boldsymbol x)\)</span> <span class="math inline">\(\propto f(\boldsymbol x|\theta)f(\theta)\)</span> <span class="math inline">\(=\dfrac{1}{\theta^{a+n+1}}\mathbb{I}_{[x_{(n)},+\infty)}(\theta)\mathbb{I}_{[b,+\infty)}(\theta)\)</span> <span class="math inline">\(=\dfrac{1}{\theta^{a+n+1}}\mathbb{I}_{[max\{b,x_{(n)}\},+\infty)}(\theta)\)</span><br />
<span class="math inline">\(~\)</span>
<span class="math inline">\(\Rightarrow \theta|\boldsymbol X = \boldsymbol x \sim Pareto(a+n,max\{b,x_{(n)}\})\)</span>.</p>
</blockquote>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Resultado 4.</strong> Seja <span class="math inline">\(X_1,...,X_n,Y_1,...,Y_m\)</span> v.a. condicionalmente independentes tais que <span class="math inline">\(X_i|\theta\sim Exp(\theta),i=1,...,n\)</span> e <span class="math inline">\(Y_j|\theta \sim Poisson(\theta),j=1,...,m\)</span>. Considere que, a priori, <span class="math inline">\(\theta \sim Gama(a,b)\)</span>. Então <span class="math inline">\(\theta| \boldsymbol x,\boldsymbol y \sim Gama(a+n+\sum_jy_j~,~b+m+\sum_ix_i)\)</span>.</p>
<blockquote>
<p><strong>Demo:</strong><br />
<span class="math inline">\(f(\boldsymbol x, \boldsymbol y|\theta)\overset{ci}{=}f(\boldsymbol x|\theta)f(\boldsymbol y|\theta)\overset{ci}{=}\)</span> <span class="math inline">\(\prod_{i=1}^nf(x_i|\theta)\prod_{j=1}^mf(y_i|\theta)=\)</span> <span class="math inline">\(\prod_{i=1}^n\theta e^{-\theta x_i}\prod_{j=1}^m\dfrac{\theta^{y_j}e^{-\theta}}{y_j!}=\)</span> <span class="math inline">\(\dfrac{1}{\prod_{j=1}^my_j!}\theta^{n+\sum_j y_j}e^{-(m+\sum_ix_i)\theta}\)</span><br />
<span class="math inline">\(~\)</span><br />
<span class="math inline">\(f(\theta)=\dfrac{b^a}{\Gamma(a)}\theta^{a-1}e^{-b\theta}\)</span>
<span class="math inline">\(~\)</span><br />
<span class="math inline">\(f(\theta| \boldsymbol{x,y})\propto f(\boldsymbol x, \boldsymbol y|\theta)f(\theta)\propto\)</span> <span class="math inline">\(\theta^{[a+n+\sum_jy_j]-1}e^{-[b+m+\sum_ix_i]\theta}\)</span>
<span class="math inline">\(~\)</span><br />
<span class="math inline">\(\Rightarrow \theta| \boldsymbol x,\boldsymbol y \sim Gama(a+n+\sum_jy_j,b+m+\sum_ix_i)\)</span></p>
</blockquote>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Resultado 5.</strong> Seja <span class="math inline">\(~\mathcal{P}=\{f(\boldsymbol x|\theta):\; \theta \in \Theta\}~\)</span> e <span class="math inline">\(~\mathcal{C}=\{h(\theta|a):\;a\in A\}~\)</span> uma <em>família conjugada</em> para <span class="math inline">\(\mathcal{P}\)</span>. Considere <span class="math inline">\(\mathcal{M}=\{h(\theta)=\sum_{i=1}^mw_ih_i(\theta):\)</span> <span class="math inline">\(h_i \in \mathcal{C} \; e \; w_i&gt;0,\; \sum_{i=1}^m w_i=1\}\)</span>. Então <span class="math inline">\(\mathcal{M}\)</span> é <em>família conjugada</em> para <span class="math inline">\(\mathcal{P}\)</span>.</p>
<blockquote>
<p><strong>Demo:</strong> Como <span class="math inline">\(\mathcal{C}\)</span> é conjugada para <span class="math inline">\(\mathcal{P}\)</span>, para toda função <span class="math inline">\(h_i \in \mathcal{C}\)</span>, temos que <span class="math inline">\(f_i(\theta|\boldsymbol x)\propto h_i(\theta)f(\boldsymbol x|\theta)\in \mathcal{C}\)</span>. Então<br />
<span class="math inline">\(~\)</span><br />
<span class="math inline">\(h\in \mathcal{M}\)</span> <span class="math inline">\(~\Rightarrow~ f(\theta|\boldsymbol x)\)</span> <span class="math inline">\(~\propto~ h(\theta)f(\boldsymbol x|\theta)\)</span> <span class="math inline">\(~\propto~\sum_{i=1}^m w_i\underbrace{h_i(\theta)f(\boldsymbol x|\theta)}_{\in \mathcal{C}}\)</span> <span class="math inline">\(~\propto~\sum_{i=1}^m w_i^*f_i(\theta|\boldsymbol x)\in \mathcal{M}\)</span>.</p>
</blockquote>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Exemplo.</strong> Seja <span class="math inline">\(X|\theta \sim Bin(n,\theta)\)</span> e <span class="math inline">\(f(\theta)\)</span> <span class="math inline">\(=wf_1(\theta)+(1-w)f_2(\theta)\)</span>, com <span class="math inline">\(f_1\sim Beta(a_1,b_1)\)</span> e <span class="math inline">\(f_2\sim Beta(a_2,b_2)\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p><span class="math inline">\(f(\theta|x)\)</span> <span class="math inline">\(=\dfrac{f(x|\theta)f(\theta)}{\int_0^1f(x|\theta)f(\theta)}\)</span> <span class="math inline">\(=\dfrac{f(x|\theta)[wf_1(\theta)+(1-w)f_2(\theta)]}{w\int_0^1f_1(\theta)f(x|\theta)d\theta+(1-w)\int_0^1f_2(\theta)d\theta}\)</span></p>
<p><span class="math inline">\(\propto\dfrac{w\binom{n}{x}\frac{\Gamma(a_1+b_1)}{\Gamma(a_1)\Gamma(b_1)}\theta^{a_1+x-1}(1-\theta)^{b_1+n-x-1}+(1-w)\binom{n}{x}\frac{\Gamma(a_2+b_2)}{\Gamma(a_2)\Gamma(b_2)}\theta^{a_2+x-1}(1-\theta)^{b_2+n-x-1}}{\underbrace{w\binom{n}{x}\frac{\Gamma(a_1+b_1)}{\Gamma(a_1)\Gamma(b_1)}\frac{\Gamma(a_1+x)\Gamma(b_1+n-x)}{\Gamma(a_1+b_1+n)}}_{A}+\underbrace{(1-w)\binom{n}{x}\frac{\Gamma(a_2+b_2)}{\Gamma(a_2)\Gamma(b_2)}\frac{\Gamma(a_2+x)\Gamma(b_2+n-x)}{\Gamma(a_2+b_2+n)}}_{B}}\)</span></p>
<p><span class="math inline">\(\propto~\underbrace{\dfrac{A}{A+B}}_{w^*}Beta(a_1+x,b_1+n-x)+\underbrace{\dfrac{B}{A+B}}_{1-w^*}Beta(a_2+x,b_2+n-x)\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p>Primeiramente, suponha que <span class="math inline">\(n=5\)</span>, e temos uma mistura das distribuições <span class="math inline">\(Beta(5,12)\)</span> e <span class="math inline">\(Beta(10,3)\)</span>, com <span class="math inline">\(w=0.5\)</span>. O gráfico a seguir apresenta as distribuições a priori, a verossimilhança e a posteriori para cada possível valor de <span class="math inline">\(x\)</span> em <span class="math inline">\(\left\{0,1,\ldots,5\right\}\)</span>.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="Bayes.html#cb6-1"></a>a1=<span class="dv">5</span>; b1=<span class="dv">12</span></span>
<span id="cb6-2"><a href="Bayes.html#cb6-2"></a>a2=<span class="dv">10</span>; b2=<span class="dv">3</span> </span>
<span id="cb6-3"><a href="Bayes.html#cb6-3"></a>n=<span class="dv">5</span></span>
<span id="cb6-4"><a href="Bayes.html#cb6-4"></a>w=<span class="fl">0.5</span></span>
<span id="cb6-5"><a href="Bayes.html#cb6-5"></a></span>
<span id="cb6-6"><a href="Bayes.html#cb6-6"></a>theta =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.01</span>)</span>
<span id="cb6-7"><a href="Bayes.html#cb6-7"></a></span>
<span id="cb6-8"><a href="Bayes.html#cb6-8"></a>A =<span class="st"> </span><span class="kw">as.vector</span>(<span class="kw">apply</span>(<span class="kw">matrix</span>(<span class="kw">seq</span>(<span class="dv">0</span>,n)),<span class="dv">1</span>,</span>
<span id="cb6-9"><a href="Bayes.html#cb6-9"></a>  <span class="cf">function</span>(x){w<span class="op">*</span><span class="kw">choose</span>(n,x)<span class="op">*</span><span class="kw">gamma</span>(a1<span class="op">+</span>b1)<span class="op">/</span>(<span class="kw">gamma</span>(a1)<span class="op">*</span><span class="kw">gamma</span>(b1))<span class="op">*</span></span>
<span id="cb6-10"><a href="Bayes.html#cb6-10"></a><span class="st">    </span>(<span class="kw">gamma</span>(a1<span class="op">+</span>x)<span class="op">*</span><span class="kw">gamma</span>(b1<span class="op">+</span>n<span class="op">-</span>x))<span class="op">/</span><span class="kw">gamma</span>(a1<span class="op">+</span>b1<span class="op">+</span>n)}))</span>
<span id="cb6-11"><a href="Bayes.html#cb6-11"></a></span>
<span id="cb6-12"><a href="Bayes.html#cb6-12"></a>B =<span class="st"> </span><span class="kw">as.vector</span>(<span class="kw">apply</span>(<span class="kw">matrix</span>(<span class="kw">seq</span>(<span class="dv">0</span>,n)),<span class="dv">1</span>,</span>
<span id="cb6-13"><a href="Bayes.html#cb6-13"></a>  <span class="cf">function</span>(x){(<span class="dv">1</span><span class="op">-</span>w)<span class="op">*</span><span class="kw">choose</span>(n,x)<span class="op">*</span><span class="kw">gamma</span>(a2<span class="op">+</span>b2)<span class="op">/</span>(<span class="kw">gamma</span>(a2)<span class="op">*</span><span class="kw">gamma</span>(b2))<span class="op">*</span></span>
<span id="cb6-14"><a href="Bayes.html#cb6-14"></a><span class="st">    </span>(<span class="kw">gamma</span>(a2<span class="op">+</span>x)<span class="op">*</span><span class="kw">gamma</span>(b2<span class="op">+</span>n<span class="op">-</span>x))<span class="op">/</span><span class="kw">gamma</span>(a2<span class="op">+</span>b2<span class="op">+</span>n)}))</span>
<span id="cb6-15"><a href="Bayes.html#cb6-15"></a></span>
<span id="cb6-16"><a href="Bayes.html#cb6-16"></a>w2 =<span class="st"> </span>A<span class="op">/</span>(A<span class="op">+</span>B)</span>
<span id="cb6-17"><a href="Bayes.html#cb6-17"></a></span>
<span id="cb6-18"><a href="Bayes.html#cb6-18"></a>prior2 =<span class="st"> </span><span class="kw">as.vector</span>(<span class="kw">apply</span>(<span class="kw">matrix</span>(<span class="kw">seq</span>(<span class="dv">0</span>,n)),<span class="dv">1</span>,</span>
<span id="cb6-19"><a href="Bayes.html#cb6-19"></a>  <span class="cf">function</span>(x){w<span class="op">*</span><span class="kw">dbeta</span>(theta,a1,b1)<span class="op">+</span></span>
<span id="cb6-20"><a href="Bayes.html#cb6-20"></a><span class="st">              </span>(<span class="dv">1</span><span class="op">-</span>w)<span class="op">*</span><span class="kw">dbeta</span>(theta,a2,b2)}))</span>
<span id="cb6-21"><a href="Bayes.html#cb6-21"></a>                        </span>
<span id="cb6-22"><a href="Bayes.html#cb6-22"></a>post2 =<span class="st"> </span><span class="kw">as.vector</span>(<span class="kw">as.matrix</span>(<span class="kw">mapply</span>(<span class="cf">function</span>(x,w2){</span>
<span id="cb6-23"><a href="Bayes.html#cb6-23"></a>  w2<span class="op">*</span><span class="kw">dbeta</span>(theta,a1<span class="op">+</span>x,b1<span class="op">+</span>n<span class="op">-</span>x)<span class="op">+</span></span>
<span id="cb6-24"><a href="Bayes.html#cb6-24"></a><span class="st">  </span>(<span class="dv">1</span><span class="op">-</span>w2)<span class="op">*</span><span class="kw">dbeta</span>(theta,a2<span class="op">+</span>x,b2<span class="op">+</span>n<span class="op">-</span>x)},<span class="kw">seq</span>(<span class="dv">0</span>,n),w2)))</span>
<span id="cb6-25"><a href="Bayes.html#cb6-25"></a>   </span>
<span id="cb6-26"><a href="Bayes.html#cb6-26"></a><span class="co">#vero = as.vector(apply(matrix(seq(0,n)),1,</span></span>
<span id="cb6-27"><a href="Bayes.html#cb6-27"></a><span class="co"># function(x){dbinom(x,prob=theta,size=n)}))</span></span>
<span id="cb6-28"><a href="Bayes.html#cb6-28"></a></span>
<span id="cb6-29"><a href="Bayes.html#cb6-29"></a><span class="co"># Verossimilhança proporcional visualmente melhor</span></span>
<span id="cb6-30"><a href="Bayes.html#cb6-30"></a>vero =<span class="st"> </span><span class="kw">as.vector</span>(<span class="kw">apply</span>(<span class="kw">matrix</span>(<span class="kw">seq</span>(<span class="dv">0</span>,n)),<span class="dv">1</span>,</span>
<span id="cb6-31"><a href="Bayes.html#cb6-31"></a>  <span class="cf">function</span>(x){<span class="kw">dbeta</span>(theta,x<span class="op">+</span><span class="dv">1</span>,n<span class="op">-</span>x<span class="op">+</span><span class="dv">1</span>)}))</span>
<span id="cb6-32"><a href="Bayes.html#cb6-32"></a></span>
<span id="cb6-33"><a href="Bayes.html#cb6-33"></a><span class="kw">tibble</span>(<span class="dt">x=</span><span class="kw">as.factor</span>(<span class="kw">rep</span>(<span class="kw">seq</span>(<span class="dv">0</span>,n),<span class="dt">each=</span><span class="kw">length</span>(theta))),</span>
<span id="cb6-34"><a href="Bayes.html#cb6-34"></a>    <span class="dt">w2=</span><span class="kw">rep</span>(w2,<span class="dt">each=</span><span class="kw">length</span>(theta)),</span>
<span id="cb6-35"><a href="Bayes.html#cb6-35"></a>    <span class="dt">theta=</span><span class="kw">rep</span>(theta,(n<span class="op">+</span><span class="dv">1</span>)),<span class="dt">vero=</span>vero,<span class="dt">prior=</span>prior2,<span class="dt">post=</span>post2) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb6-36"><a href="Bayes.html#cb6-36"></a><span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb6-37"><a href="Bayes.html#cb6-37"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>theta,<span class="dt">y=</span>post, <span class="dt">colour=</span>x),<span class="dt">lwd=</span><span class="fl">1.5</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb6-38"><a href="Bayes.html#cb6-38"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>theta,<span class="dt">y=</span>prior,<span class="dt">colour=</span><span class="st">&quot;Prior&quot;</span>),<span class="dt">lwd=</span><span class="dv">1</span>,<span class="dt">lty=</span><span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb6-39"><a href="Bayes.html#cb6-39"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>theta,<span class="dt">y=</span>vero,<span class="dt">colour=</span><span class="st">&quot;Verossimilhança&quot;</span>),<span class="dt">lwd=</span><span class="dv">1</span>,<span class="dt">lty=</span><span class="dv">2</span>)<span class="op">+</span></span>
<span id="cb6-40"><a href="Bayes.html#cb6-40"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>(theta)) <span class="op">+</span><span class="st">   </span></span>
<span id="cb6-41"><a href="Bayes.html#cb6-41"></a><span class="st">  </span><span class="kw">ylab</span>(<span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&quot;f(&quot;</span>,theta,<span class="st">&quot;|x)&quot;</span>)))<span class="op">+</span></span>
<span id="cb6-42"><a href="Bayes.html#cb6-42"></a><span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span></span>
<span id="cb6-43"><a href="Bayes.html#cb6-43"></a><span class="st">  </span>gganimate<span class="op">::</span><span class="kw">transition_states</span>(x)</span></code></pre></div>
<p><img src="InfBayes_files/figure-html/unnamed-chunk-12-1.gif" width="80%" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(~\)</span></p>
<p>Agora, suponha que <span class="math inline">\(n=5\)</span> e foi observado <span class="math inline">\(x=2\)</span>. Novamente, considere a mistura das distribuições <span class="math inline">\(Beta(5,12)\)</span> e <span class="math inline">\(Beta(10,3)\)</span> mas agora com pesos <span class="math inline">\(w\)</span> variando no conjunto <span class="math inline">\(\left\{0,0.1,\ldots,0.9,1\right\}\)</span>.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="Bayes.html#cb7-1"></a>x =<span class="st"> </span><span class="dv">2</span></span>
<span id="cb7-2"><a href="Bayes.html#cb7-2"></a>w =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.1</span>)</span>
<span id="cb7-3"><a href="Bayes.html#cb7-3"></a></span>
<span id="cb7-4"><a href="Bayes.html#cb7-4"></a>A =<span class="st"> </span><span class="kw">as.vector</span>(<span class="kw">apply</span>(<span class="kw">matrix</span>(w),<span class="dv">1</span>,</span>
<span id="cb7-5"><a href="Bayes.html#cb7-5"></a>  <span class="cf">function</span>(w){w<span class="op">*</span><span class="kw">choose</span>(n,x)<span class="op">*</span><span class="kw">gamma</span>(a1<span class="op">+</span>b1)<span class="op">/</span>(<span class="kw">gamma</span>(a1)<span class="op">*</span></span>
<span id="cb7-6"><a href="Bayes.html#cb7-6"></a><span class="st">    </span><span class="kw">gamma</span>(b1))<span class="op">*</span>(<span class="kw">gamma</span>(a1<span class="op">+</span>x)<span class="op">*</span><span class="kw">gamma</span>(b1<span class="op">+</span>n<span class="op">-</span>x))<span class="op">/</span><span class="kw">gamma</span>(a1<span class="op">+</span>b1<span class="op">+</span>n)}))</span>
<span id="cb7-7"><a href="Bayes.html#cb7-7"></a></span>
<span id="cb7-8"><a href="Bayes.html#cb7-8"></a>B =<span class="st"> </span><span class="kw">as.vector</span>(<span class="kw">apply</span>(<span class="kw">matrix</span>(w),<span class="dv">1</span>,</span>
<span id="cb7-9"><a href="Bayes.html#cb7-9"></a>  <span class="cf">function</span>(w){(<span class="dv">1</span><span class="op">-</span>w)<span class="op">*</span><span class="kw">choose</span>(n,x)<span class="op">*</span><span class="kw">gamma</span>(a2<span class="op">+</span>b2)<span class="op">/</span>(<span class="kw">gamma</span>(a2)<span class="op">*</span></span>
<span id="cb7-10"><a href="Bayes.html#cb7-10"></a><span class="st">    </span><span class="kw">gamma</span>(b2))<span class="op">*</span>(<span class="kw">gamma</span>(a2<span class="op">+</span>x)<span class="op">*</span><span class="kw">gamma</span>(b2<span class="op">+</span>n<span class="op">-</span>x))<span class="op">/</span><span class="kw">gamma</span>(a2<span class="op">+</span>b2<span class="op">+</span>n)}))</span>
<span id="cb7-11"><a href="Bayes.html#cb7-11"></a></span>
<span id="cb7-12"><a href="Bayes.html#cb7-12"></a>w2 =<span class="st"> </span>A<span class="op">/</span>(A<span class="op">+</span>B)</span>
<span id="cb7-13"><a href="Bayes.html#cb7-13"></a></span>
<span id="cb7-14"><a href="Bayes.html#cb7-14"></a>prior2 =<span class="st"> </span><span class="kw">as.vector</span>(<span class="kw">apply</span>(<span class="kw">matrix</span>(w),<span class="dv">1</span>,<span class="cf">function</span>(w){</span>
<span id="cb7-15"><a href="Bayes.html#cb7-15"></a>  w<span class="op">*</span><span class="kw">dbeta</span>(theta,a1,b1)<span class="op">+</span>(<span class="dv">1</span><span class="op">-</span>w)<span class="op">*</span><span class="kw">dbeta</span>(theta,a2,b2)}))</span>
<span id="cb7-16"><a href="Bayes.html#cb7-16"></a></span>
<span id="cb7-17"><a href="Bayes.html#cb7-17"></a>post2 =<span class="st"> </span><span class="kw">as.vector</span>(<span class="kw">as.matrix</span>(<span class="kw">mapply</span>(<span class="cf">function</span>(w,w2){</span>
<span id="cb7-18"><a href="Bayes.html#cb7-18"></a>  w2<span class="op">*</span><span class="kw">dbeta</span>(theta,a1<span class="op">+</span>x,b1<span class="op">+</span>n<span class="op">-</span>x)<span class="op">+</span></span>
<span id="cb7-19"><a href="Bayes.html#cb7-19"></a><span class="st">  </span>(<span class="dv">1</span><span class="op">-</span>w2)<span class="op">*</span><span class="kw">dbeta</span>(theta,a2<span class="op">+</span>x,b2<span class="op">+</span>n<span class="op">-</span>x)},w,w2)))</span>
<span id="cb7-20"><a href="Bayes.html#cb7-20"></a></span>
<span id="cb7-21"><a href="Bayes.html#cb7-21"></a>vero =<span class="st"> </span><span class="kw">as.vector</span>(<span class="kw">apply</span>(<span class="kw">matrix</span>(<span class="kw">rep</span>(x,<span class="dv">2</span><span class="op">*</span>n<span class="op">+</span><span class="dv">1</span>)),<span class="dv">1</span>,</span>
<span id="cb7-22"><a href="Bayes.html#cb7-22"></a>  <span class="cf">function</span>(x){<span class="kw">dbeta</span>(theta,x<span class="op">+</span><span class="dv">1</span>,n<span class="op">-</span>x<span class="op">+</span><span class="dv">1</span>)}))</span>
<span id="cb7-23"><a href="Bayes.html#cb7-23"></a></span>
<span id="cb7-24"><a href="Bayes.html#cb7-24"></a>z&lt;-<span class="kw">length</span>(w)</span>
<span id="cb7-25"><a href="Bayes.html#cb7-25"></a></span>
<span id="cb7-26"><a href="Bayes.html#cb7-26"></a><span class="kw">tibble</span>(<span class="dt">w=</span><span class="kw">as.factor</span>(<span class="kw">rep</span>(w,<span class="dt">each=</span><span class="kw">length</span>(theta))),</span>
<span id="cb7-27"><a href="Bayes.html#cb7-27"></a>    <span class="dt">w2=</span><span class="kw">rep</span>(w2,<span class="dt">each=</span><span class="kw">length</span>(theta)),</span>
<span id="cb7-28"><a href="Bayes.html#cb7-28"></a>    <span class="dt">theta=</span><span class="kw">rep</span>(theta,z), <span class="dt">prior =</span> prior2, </span>
<span id="cb7-29"><a href="Bayes.html#cb7-29"></a>    <span class="dt">post =</span> post2, <span class="dt">vero =</span> vero) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb7-30"><a href="Bayes.html#cb7-30"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="dt">colour =</span> w) <span class="op">+</span><span class="st"> </span></span>
<span id="cb7-31"><a href="Bayes.html#cb7-31"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>theta,<span class="dt">y=</span>post, <span class="dt">colour=</span>w),<span class="dt">lwd=</span><span class="fl">1.5</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb7-32"><a href="Bayes.html#cb7-32"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>theta,<span class="dt">y=</span>prior,<span class="dt">colour=</span><span class="st">&quot;Priori&quot;</span>)) <span class="op">+</span></span>
<span id="cb7-33"><a href="Bayes.html#cb7-33"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>theta,<span class="dt">y=</span>vero,<span class="dt">colour=</span><span class="st">&quot;Verossimilhança&quot;</span>),<span class="dt">lwd=</span><span class="dv">1</span>,<span class="dt">lty=</span><span class="dv">2</span>)<span class="op">+</span></span>
<span id="cb7-34"><a href="Bayes.html#cb7-34"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>(theta)) <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&quot;f(&quot;</span>,theta,<span class="st">&quot;|x)&quot;</span>)))<span class="op">+</span></span>
<span id="cb7-35"><a href="Bayes.html#cb7-35"></a><span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span></span>
<span id="cb7-36"><a href="Bayes.html#cb7-36"></a><span class="st">  </span>gganimate<span class="op">::</span><span class="kw">transition_states</span>(w)</span></code></pre></div>
<p><img src="InfBayes_files/figure-html/unnamed-chunk-14-1.gif" width="80%" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(~\)</span></p>

</div>
</div>
</div>
<h3>Referências</h3>
<div id="refs" class="references">
<div id="ref-Albert09">
<p>Albert, Jim. 2009. <em>Bayesian Computation with R</em>. Springer.</p>
</div>
<div id="ref-Schervish12">
<p>Schervish, M. J. 2012. <em>Theory of Statistics</em>. Springer Science &amp; Business Media.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ProbSubj.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="TeoDec.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["InfBayes.pdf", "InfBayes.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
