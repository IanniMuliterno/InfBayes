[
["index.html", "Fundamentos de Inferência Bayesiana Prefácio", " Fundamentos de Inferência Bayesiana Victor Fossaluza e Luís Gustavo Esteves 2020-08-18 Prefácio Esse documento foi criado com base nos cursos de Inferência Bayesiana ministrados por nós no Instituto de Matemática e Estatística da Universidade de São Paulo (IME-USP). Essas notas devem ser usadas como um roteiro de estudos e não irão necessariamente apresentar todo o conteúdo dessas disciplinas. Além disso, esta é uma versão preliminar que está bem longe da versão final, de modo que podem haver muitos erros e, assim, correções ou sugestões serão sempre muito bem vindas! "],
["ProbSubj.html", "1 Probabilidade Subjetiva 1.1 Definição Axiomática 1.2 Interpretações de Probabilidade 1.3 Relação de Crença \\(\\precsim\\) 1.4 Medida de Probabilidade que “representa” \\(\\precsim\\) 1.5 Medida de Probabilidade Condicional", " 1 Probabilidade Subjetiva A construção de probabilidade subjetiva apresentada aqui pode ser encontrada no livro Optimal Statistical Decisions (DeGroot 1970). \\(\\Omega\\): espaço amostral, conjunto não vazio. \\(\\mathcal{A}\\): \\(\\sigma\\)-álgebra de subconjuntos de \\(\\Omega\\), isto é, \\(\\Theta \\in \\mathcal{A}\\); \\(A \\in \\mathcal{A} \\Longrightarrow A^{c} \\in \\mathcal{A}\\); \\(\\displaystyle A_1, A_2, \\ldots \\in \\mathcal{A} \\Longrightarrow \\bigcup_{i\\geq1} A_i \\in \\mathcal{A}\\). Os elementos de \\(\\mathcal{A}\\) são chamados de eventos e serão denotados por \\(A, B, C, \\ldots, A_1, A_2, \\ldots\\) 1.1 Definição Axiomática \\(P: \\mathcal{A} \\longrightarrow [0,1]\\) é uma medida de probabilidade se \\(P(\\Omega) = 1\\); \\(\\displaystyle A_1, A_2, \\ldots \\in \\mathcal{A}\\) com \\(A_i \\bigcap A_j = \\emptyset\\) , \\(\\displaystyle P\\left(\\bigcup_{i \\geq 1} A_i\\right) = \\sum_{i \\geq 1} P\\left(A_i\\right)\\). 1.2 Interpretações de Probabilidade Interpretação Clássica (De Moivre, Laplace) baseia-se na equiprobabilidade dos resultados; \\(P(A) = \\frac{|A|}{|\\Omega|}\\). Exemplo: um lançamento de moeda, \\(A\\) = “cara”, \\(P(A) = \\frac{1}{2}\\). \\(~\\) Interpretação Frequentista (Venn, von Mises, Reichenbach, etc.) quase unânime na primeira metade do século XX e ainda é a mais aceita; baseia-se na regularidade das frequências relativas (lei dos grandes números); \\(P(A) = lim \\frac{A_n}{n}\\), onde \\(A_n\\) é o número de ocorrências de \\(A\\) em \\(n\\) realizações idênticas e independentes do experimento; Supõe que é possível repetir indefinidamente o experimento nas mesmas circustâncias. Exemplo: um lançamento de moeda, \\(A\\) = “cara”. \\(~\\) Interpretação Lógica (Keynes, Jeffreys, Carnap, etc.) medida de “vínculo parcial” entre uma evidência e uma hipótese; baseia-se em relações objetivas entre proposições. Exemplo: considere duas proposições: “até agora todos os lançamentos resultaram em cara” e “será realizado um novo lançamento”. Pode-se afirmar que “provavelmente o resultado do novo lançamento será cara”. \\(~\\) Interpretação Subjetivista (Ramsey, de Finetti, Savage, etc) probabilidade como medida subjetiva de crença; baseada na experiência de cada indivíduo, portanto única. Exemplo: suponha que Bruno lançou uma moeda 3 vezes e todos os resultados foram cara. Esse indivíduo, em posse dessa informação, pode acreditar que o resultado cara é mais provável que coroa. Contudo, quando pergunta sobre a probabilidade de cara ao seu colega Olavo, ignorante com relação a moeda, ele responde que é 1/2. \\(~\\) 1.3 Relação de Crença \\(\\precsim\\) \\(\\precsim\\) : relação de “crença” em \\(\\mathcal{A}\\times\\mathcal{A}\\) \\(A \\prec B\\) : acredito mais em \\(B\\) que em \\(A\\) (\\(B \\succ A\\)) \\(A \\sim B\\) : acredito igualmente em \\(B\\) e \\(A\\) \\(A \\precsim B\\) : acredito em \\(B\\) pelo menos tanto quanto em \\(A\\) Objetivo: sob certas condições em \\(\\precsim\\), obter uma medida de probabilidade \\(P\\) que representa (concorda) com \\(\\precsim\\). \\[A \\precsim B ~ \\Longleftrightarrow ~ P(A) \\leq P(B)\\] \\(~\\) Suposições sobre \\(\\precsim\\) SP1: Para \\(A, B \\in \\mathcal{A}\\), exatamente uma das afirmações a seguir deve valer: \\[A \\prec B ~,~ B \\prec A ~\\textrm{ou}~ A \\sim B.\\] \\(~\\) SP2: \\(A_1, A_2, B_1, B_2 \\in \\mathcal{A}\\) tais que \\(A_1 \\cap A_2 = B_1 \\cap B_2 = \\emptyset\\) e \\(A_i \\precsim B_i\\), \\(i=1,2\\). Então \\[A_1 \\cup A_2 \\precsim B_1 \\cup B_2 .\\] Além disso, se \\(A_i \\prec B_i\\) para algum \\(i\\), então \\(A_1 \\cup A_2 \\prec B_1 \\cup B_2 .\\) \\(~\\) SP3: Se \\(A\\) é um evento, então \\(\\emptyset \\precsim A\\). Além disso, \\(\\emptyset \\prec \\Omega\\). \\(~\\) SP4: Se \\(A_1, A_2, \\ldots\\) uma sequência decrescente de eventos, isto é, \\(A_n \\supseteq A_{n+1}, \\forall n\\), e \\(B\\) tal que \\(B \\precsim A_n, \\forall n\\) então \\[B \\precsim \\bigcap_{n \\geq 1} A_n.\\] \\(~\\) SP5: Existe uma variável aleatória \\(X: \\Omega \\longrightarrow \\mathbb{R}\\), \\(\\mathcal{A}\\)-mensurável, tal que \\(X(\\omega) \\in [0,1], \\forall \\omega \\in \\Omega\\) e, se \\(I_1\\) e \\(I_2\\) são intervalos contidos em \\([0,1]\\), \\(\\{X \\in I_1\\} \\precsim \\{X \\in I_2\\} \\Leftrightarrow \\lambda(I_1) \\leq \\lambda(I_2)~.\\) Se \\(I=[a,b] \\subseteq [0,1]\\), \\(\\lambda(I) = b-a\\) é o comprimento do intervalo \\(I\\) (medida de Lebesgue). “Experimento auxiliar” ; \\(X \\sim\\) Uniforme[0,1]. \\(\\{X \\in [a,b]\\}\\) \\(\\sim \\{X \\in (a,b]\\}\\) \\(\\sim \\{X \\in [a,b)\\}\\) \\(\\sim \\{X \\in (a,b)\\}\\). \\(~\\) Lema 1: \\(A, B, D \\in \\mathcal{A}\\) tais que \\(A \\cap D = B \\cap D = \\emptyset\\). Então \\[A \\precsim B ~\\Leftrightarrow~ A \\cup D \\precsim B \\cup D\\] Demo: (\\(\\Rightarrow\\)) \\(A \\precsim B \\Rightarrow A \\cup D \\precsim B \\cup D\\) (SP2) (\\(\\Leftarrow\\)) \\(B \\prec A \\Rightarrow B \\cup D \\prec A \\cup D\\) (SP2) \\(~\\) Teorema 1: Se \\(A \\precsim B\\) e \\(B \\precsim D\\) então \\(A \\precsim D\\). Demo: (i) \\((1) \\cup (2) \\cup (4) \\cup (5) \\precsim (1) \\cup (2) \\cup (3) \\cup (6)\\) \\(~\\Rightarrow~ (4) \\cup (5) \\precsim (3) \\cup (6)\\). (ii) Analogamente, \\((2) \\cup (6) \\precsim (4) \\cup (7)\\) De (i) e (ii) e pelo Lema 1, \\((4) \\cup (5) \\cup (2) \\cup (6) \\precsim (3) \\cup (6) \\cup (4) \\cup (7)\\) \\(~\\Rightarrow~ (2) \\cup (5) \\precsim (3) \\cup (7)\\) \\({~\\Rightarrow~ (2) \\cup (5) \\cup (1) \\cup(4) \\precsim (3) \\cup (7) \\cup (1) \\cup(4)}\\). \\(~\\) Teorema 2 (generalização do SP2): Se \\(A_1, \\ldots, A_n\\) são eventos disjuntos e \\(B_1, \\ldots, B_n\\) são também eventos disjuntos tais que \\(A_i \\precsim B_i\\), para \\(i=1,\\ldots,n\\), então \\[\\bigcup_{i=1}^{n} A_i \\precsim \\bigcup_{i=1}^{n} B_i.\\] Se \\(A_i \\prec B_i\\) para algum i, então \\(\\bigcup_{i=1}^{n} A_i \\prec \\bigcup_{i=1}^{n} B_i.\\) Demo: Exercício. \\(~\\) Teorema 3: Se \\(A \\precsim B\\) então \\(A^c \\succsim B^c\\). Demo: Do Lema 1, \\(A \\cup (A^c \\cap B^c) \\precsim B \\cup (A^c \\cap B^c)\\) \\(\\Rightarrow B^c \\cup (A \\cap B) \\precsim A^c \\cup (A \\cap B)\\) \\(\\Rightarrow B^c \\precsim A^c\\). \\(~\\) Resultado: Para todo evento \\(A\\), \\(A \\precsim \\Omega\\). Demo: Por SP3, \\(\\emptyset \\precsim A^c\\). Tomando \\(D=A\\) no Lema 1, \\(\\emptyset \\cup A \\precsim A^c \\cup A \\Rightarrow A \\precsim \\Omega\\). \\(~\\) Teorema 4: Se \\(A \\subseteq B\\) então \\(A \\precsim B\\). Demo: Suponha, \\(B \\prec A\\). Tomando \\(D=B^c\\) no Lema 1, \\(B \\cup B^c \\prec A \\cup B^c \\Rightarrow \\Omega \\prec A \\cup B^c\\). Absurdo! \\(~\\) Exemplo 1: \\(\\omega_0 \\in \\Omega\\). \\(A \\precsim B \\Leftrightarrow \\{\\omega_0 \\in B\\) ou \\(\\omega_0 \\notin (A \\cup B)\\}\\). Mostre que \\(\\precsim\\) obedece a SP1 a SP4. (SP1) \\(A \\precsim B \\Leftrightarrow \\omega_0 \\in B \\cup (A \\cup B)^c\\) \\(\\Rightarrow B \\prec A \\Leftrightarrow \\omega_0 \\in B^c \\cap (A \\cup B)\\) \\(\\Leftrightarrow \\omega_0 \\in A \\cap B^c.\\) Analogamente, \\(A \\prec B \\Leftrightarrow \\omega_0 \\in B \\cap A^c.\\) \\(A \\sim B \\Leftrightarrow A \\precsim B\\) e \\(B \\precsim A\\) \\(\\Leftrightarrow \\omega_0 \\in [B \\cup (A \\cup B)^c] \\cap [A \\cup (A \\cup B)^c]\\) \\(\\Leftrightarrow \\omega_0 \\in (A \\cap B) \\cup (A \\cup B)^c.\\) \\(~\\) (SP2) \\(A_i \\precsim B_i , i=1,2 \\Leftrightarrow\\) \\(\\omega_0 \\in [B_1 \\cup (A_1 \\cup B_1)^c] \\cap [B_2 \\cup (A_2 \\cup B_2)^c]\\) \\(\\Leftrightarrow \\omega_0 \\in [(B_1 \\cup B_2) \\cap D^c] \\cup (A_1 \\cup B_1 \\cup A_2 \\cup B_2)^c,\\) com \\(D = (A_1 \\cap B2) \\cup (A_2 \\cap B1).\\) \\(A_1 \\cup A_2 \\precsim B_1 \\cup B_2 \\Leftrightarrow\\) \\(\\omega_0 \\in (B_1 \\cup B_2) \\cup (A_1 \\cup A_2 \\cup B_1 \\cup B_2)^c\\) Como \\((B_1 \\cup B_2) \\cap D^c \\subseteq (B_1 \\cup B_2)\\), vale o SP2. \\(~\\) (SP3) \\(\\emptyset \\precsim A \\Leftrightarrow \\omega_0 \\in A \\cup (\\emptyset \\cup A)^c\\) \\(\\Leftrightarrow \\omega_0 \\in A \\cup A^c = \\Omega.\\) Como \\(\\Omega\\) é não-vazio, \\(\\exists \\omega_0 \\in \\Omega\\) e, portanto, \\(\\emptyset \\prec \\Omega\\). \\(~\\) (SP4) Exercício! \\(~\\) Exemplo 2: \\(\\Omega = \\mathbb{N}\\), \\(\\mathcal{A} = \\mathcal{P}(\\mathbb{N})\\). \\(A \\precsim B \\Leftrightarrow \\{B\\) é infinito ou \\(A\\) e \\(B\\) são finitos com \\(|A| \\leq |B|\\}\\). Verifique se \\(\\precsim\\) satisfaz SP1 a SP4. \\(~\\) Teorema 5: Se \\(A_1 \\subseteq A_2 \\subseteq \\ldots\\) é uma sequência crescente de eventos e \\(B\\) é tal que \\(A_n \\precsim B, \\forall n\\) então \\[\\bigcup_{n \\geq 1} A_n \\precsim B.\\] Demo: \\(A_n^c \\supseteq A_{n+1}^c\\) e, pelo Teo 3, \\(A_n^c \\succsim B^c\\), \\(\\forall n\\). Por SP4, \\(\\bigcap_{n \\geq 1} A_n^c \\succsim B^c\\) \\(\\Rightarrow \\bigcup_{n \\geq 1} A_n \\precsim B.\\) \\(~\\) Teorema 6: \\(\\left(A_n\\right)_{n \\geq 1}\\) e \\(\\left(B_n\\right)_{n \\geq 1}\\) sequências tais que \\(A_i \\cap A_j = B_k \\cap B_l = \\emptyset\\), \\(\\forall i \\neq j\\), \\(\\forall k \\neq l\\). \\[A_i \\precsim B_i, \\forall i ~\\Rightarrow~ \\bigcup_{n \\geq 1} A_n \\precsim \\bigcup_{n \\geq 1} B_n.\\] Se existe ao menos um \\(j\\) tal que \\(A_j \\prec B_j\\) então \\(\\displaystyle{ \\bigcup_{n \\geq 1} A_n \\prec \\bigcup_{n \\geq 1} B_n }.\\) Demo: Da extensão de SP2, temos que \\(\\displaystyle{ \\bigcup_{i = 1}^n A_i \\precsim \\bigcup_{i = 1}^n B_i }\\), \\(\\forall n \\geq 1\\) \\(~\\Rightarrow~ \\displaystyle{ \\bigcup_{i = 1}^n A_i \\precsim \\bigcup_{i = 1}^{\\infty} B_i }\\), \\(\\forall n \\geq 1\\) \\(~\\Rightarrow~ \\displaystyle{ \\bigcup_{i = 1}^{\\infty} A_i \\precsim \\bigcup_{i = 1}^{\\infty} B_i }~\\) (Teo 5) \\(\\exists n_0\\) tal que \\(A_{n_0} \\prec B_{n_0}\\). De SP2, temos que, para \\(n \\geq n_0\\), \\(\\displaystyle \\bigcup_{i = 1}^{n_0} A_i = \\bigcup_{i = 1}^{n_0-1} A_i \\cup A_{n_0} \\prec \\bigcup_{i = 1}^{n_0-1} B_i \\cup B_{n_0} = \\bigcup_{i = 1}^{n_0} B_i\\) \\(~\\Rightarrow~ \\displaystyle \\bigcup_{i = 1}^{n_0} A_i \\prec \\bigcup_{i = 1}^{n_0} B_i.\\) Da primeira parte, temos que \\(\\displaystyle{ \\bigcup_{i = n_0+1}^{\\infty} A_i \\precsim \\bigcup_{i = n_0+1}^{\\infty} B_i } ~\\) e, por SP2, \\(\\displaystyle \\bigcup_{i = 1}^{n_0} A_i \\cup \\bigcup_{i = n_0+1}^{\\infty} A_i \\prec \\bigcup_{i = 1}^{n_0} B_i \\cup \\bigcup_{i = n_0+1}^{\\infty} B_i\\) provando o resultado. \\(~\\) 1.4 Medida de Probabilidade que “representa” \\(\\precsim\\) Teorema 7: Seja \\(A \\in \\mathcal{A}\\). Então \\(\\exists! a^* \\in [0,1]\\) tal que \\(A \\sim \\{X \\in [0,a^*]\\}\\). Demo: Seja \\(U(A) = \\left\\{ a \\in [0,1] : A \\precsim \\{X \\in [0,a]\\} \\right\\}\\). \\(1 \\in U(A)\\) pois \\(\\Omega = \\{X \\in [0,1]\\} \\succsim A\\) \\(~\\Rightarrow~ U(A) \\neq \\emptyset\\). Tome \\(a^* = \\inf U(A)\\). \\(~\\) (i) Considere \\((a_n)_{n \\geq 1}\\), \\(a_n \\in [0,1], \\forall n \\geq 1\\), tal que \\(a_n \\geq a_{n+1} \\geq a^*\\) e \\(a_n \\downarrow a^*\\). Então, \\(\\forall n \\geq 1\\) , \\(\\{X \\in [0,a_n]\\} \\succsim A\\). Por SP4, \\(\\displaystyle \\bigcap_{n=1}^\\infty \\{X \\in [0,a_n]\\} \\succsim A\\) \\(~\\Rightarrow~ \\{X \\in [0,a^*]\\} \\succsim A\\) \\(~\\) (ii) Se \\(a^*=0\\) , \\(\\{X \\in [0,0]\\} \\sim \\emptyset \\precsim A\\) (por SP3). Se \\(a^* &gt; 0\\) , considere \\((a_n)_{n \\geq 1}\\) com \\(a_n \\leq a_{n+1} &lt; a^*\\) e \\(a_n \\uparrow a^*\\). \\(\\{X \\in [0,a_n]\\} \\precsim A, \\forall n \\geq 1\\) e, pelo Teo 5, \\(\\displaystyle \\bigcup_{n=1}^{\\infty} \\{X \\in [0,a_n]\\} \\precsim A\\) \\(~\\Rightarrow~ \\{X \\in [0,a^*)\\} \\sim \\{X \\in [0,a^*]\\} \\precsim A\\). \\(~\\) De (i) e (ii), temos que \\(A \\sim \\{X \\in [0,a^*]\\}\\). \\(~\\) \\(a^*\\) é único pois se \\(a_1 &lt; a^* &lt; a_2\\) são outros valores quaisquer, segue que \\(\\{X \\in [0,a_1]\\} \\prec \\{X \\in [0,a^*]\\} \\prec \\{X \\in [0,a_2]\\}\\) e só um desses eventos pode ser equivalente à \\(A\\). \\(~\\) Teorema 8: A probabilidade do evento \\(A\\), \\(P(A)\\), é definida como \\(a^* \\in [0,1]\\) tal que \\(A \\sim \\{X \\in [0,a^*]\\}\\). Assim, \\(A \\sim \\left\\{X \\in \\left[0,P(A)\\right]\\right\\}\\). A função de probabilidade assim definida satisfaz: \\[A \\precsim B ~\\Leftrightarrow~ P(A) \\leq P(B).\\] Demo: Do Teo 7, \\(A \\sim \\left\\{X \\in \\left[0,P(A)\\right]\\right\\}\\) e \\(B \\sim \\left\\{X \\in \\left[0,P(B)\\right]\\right\\}\\). \\(A \\precsim B\\) \\(~\\Leftrightarrow~ \\left\\{X \\in \\left[0,P(A)\\right]\\right\\} \\precsim \\left\\{X \\in \\left[0,P(B)\\right]\\right\\}\\) \\(~\\Leftrightarrow~ \\lambda \\left([0,P(A)]\\right) \\precsim \\lambda \\left([0,P(B)]\\right)\\) \\(~\\Leftrightarrow~ P(A) \\leq P(B).\\) \\(~\\) Teorema 9: A função \\(P: \\mathcal{A} \\longrightarrow [0,1]\\) que, para cada \\(A \\in \\mathcal{A}\\), associa \\(P(A)\\) tal que \\(A \\sim \\left\\{X \\in \\left[0,P(A)\\right]\\right\\}\\) é uma medida de probabilidade (no sentido \\(\\sigma\\)-aditiva). Demo: (i) \\(P(A) \\geq 0\\). \\(\\Omega \\sim \\{X \\in [0,1]\\}\\Rightarrow P(\\Omega)=1\\). \\(\\emptyset \\sim \\{X \\in [0,0]\\} \\Rightarrow P(\\emptyset)=0\\) \\(\\emptyset \\precsim A \\Rightarrow 0 \\leq P(A)\\). \\(~\\) (ii) Seja \\(A\\) e \\(B\\) tal que \\(A \\cap B = \\emptyset\\). Vamos mostrar que \\(P(A \\cup B) = P(A) + P(B)\\). Pelo Teo 8, \\(A \\sim \\{ X \\in [0,P(A)]\\}\\), \\(B \\sim \\{ X \\in [0,P(B)]\\}\\), \\(A \\cup B \\sim \\{ X \\in [0,P(A \\cup B)]\\}\\). Como \\(A \\subseteq A \\cup B\\) e, por SP3, \\(A \\precsim A \\cup B\\), vale que \\(P(A) \\leq P(A \\cup B)\\). Vamos verificar que \\(B \\sim \\left\\{X \\in \\left(P(A),P(A \\cup B) \\right]\\right\\}\\). Suponha, por absurdo, \\(B \\prec \\left\\{X \\in \\left(P(A),P(A \\cup B) \\right]\\right\\}\\). \\(A \\precsim \\{X \\in [0,P(A)]\\}\\) \\(~\\overset{SP2}{\\Longrightarrow}~\\) \\(A \\cup B \\prec \\{X \\in [0,P(A)]\\} \\cup \\left\\{X \\in \\left(P(A),P(A \\cup B) \\right]\\right\\}\\) \\(~\\Rightarrow~ A \\cup B \\prec \\left\\{X \\in [0,P(A)] \\cup \\left(P(A),P(A \\cup B) \\right]\\right\\}\\) \\(~\\Rightarrow~ A \\cup B \\prec \\left\\{X \\in \\left[0,P(A \\cup B) \\right]\\right\\}\\) ~ (Absurdo!) Analogamente, \\(B \\succ \\left\\{X \\in \\left(P(A),P(A \\cup B) \\right]\\right\\}\\) é absurdo! Logo, \\(B \\sim \\left\\{X \\in \\left(P(A),P(A \\cup B) \\right]\\right\\} \\sim \\left\\{X \\in \\left[0, P(A \\cup B)-P(A) \\right]\\right\\}\\). Como \\(B \\sim \\left\\{X \\in \\left[0,P(B)\\right]\\right\\}\\), temos que \\(P(A \\cup B) = P(A) + P(B)\\). \\(~\\) Corolário 1: Se \\(A_1, \\ldots, A_n\\) são eventos disjuntos, então \\(P\\left(\\bigcup_{i=1}^{n} A_i\\right) = \\sum_{i=1}^{n} P\\left(A_i\\right)\\). Demo: Indução. \\(~\\) Teorema 10: Seja \\(A_1 \\supseteq A_2 \\supseteq \\ldots\\) uma seq. decrescente de eventos tais que \\(\\bigcap_{i=1}^{n} A_i = \\emptyset\\). Então \\(\\displaystyle \\lim_{n \\uparrow \\infty} P(A_n) = 0\\). Demo: \\(A_1 \\supseteq A_2 \\supseteq \\ldots\\) \\(\\Rightarrow\\) \\(P(A_1) \\geq P(A)_2 \\geq \\ldots\\). Além disso, \\(\\displaystyle \\lim_{n \\uparrow \\infty} P(A_n) = b\\). Como \\(P(A_n) \\geq b\\), \\(\\forall n\\), segue que \\(A_n \\succsim \\{X \\in [0,b]\\}\\), \\(\\forall n\\). Por SP4, \\(\\emptyset = \\bigcap_{i=n}^{\\infty} A_i \\succsim \\{X \\in [0,b]\\}\\). Se \\(b&gt;0\\), então \\(\\{X \\in [0,b]\\} \\succ \\{X \\in [0,b/2]\\} \\succsim \\emptyset\\). Como essa relação contradiz a anterior, temos que \\(b\\) deve ser igual a \\(0\\). \\(~\\) Exercício 1: Use o Corolário 1 e o Teorema 10 para conculuir a demonstração do Teorema 9, mostrando que \\(P\\) é \\(\\sigma\\)-aditiva, isto é, \\[P\\left(\\bigcup_{i=1}^{\\infty} A_i\\right) = \\sum_{i=1}^{\\infty} P\\left(A_i\\right) ~,~~ A_i \\cap A_j = \\emptyset, \\forall i \\neq j.\\] Solução: Seja \\((A_n)_{n \\geq 1}\\) sequência de eventos disjuntos. Segue do Corolário 1 que (i) \\(\\displaystyle P\\left(\\bigcup_{i=1}^{\\infty} A_n\\right) = \\sum_{i=1}^{n} P\\left(A_i\\right) + P\\left(\\bigcup_{j=n+1}^{\\infty} A_j\\right)\\), \\(n=1,2,\\ldots\\) Considere \\(\\displaystyle B_n=\\bigcup_{j=n+1}^{\\infty} A_j\\), \\(n \\geq 1\\), uma sequência decrescente de eventos tais que \\(\\displaystyle \\bigcap_{n=1}^{\\infty} B_n = \\emptyset\\). Pelo Teorema 10, segue que \\(\\displaystyle \\lim_{n\\uparrow \\infty} B_n = 0\\). Assim, tomando o limite do lado direito de (i), segue que \\(\\displaystyle P\\left(\\bigcup_{i=1}^{\\infty} A_n\\right)\\) \\(=\\displaystyle \\lim_{n\\uparrow \\infty} \\sum_{i=1}^{n} P\\left(A_i\\right) + \\lim_{n\\uparrow \\infty} P\\left(B_n\\right)\\) \\(=\\displaystyle \\sum_{i=1}^{\\infty} P\\left(A_i\\right)\\). \\(~\\) Teorema 11: Se a relação de crença \\(\\precsim\\) obedece SP1 a SP5 então \\(\\exists !~ P: \\mathcal{A} \\rightarrow [0,1]\\), medida de probabilidade, tal que \\(P\\) representa \\(\\precsim\\). Demo: Exercício! \\(~\\) 1.5 Medida de Probabilidade Condicional Nova Relação: \\((A|D) \\precsim (B|D)\\) (Sabendo que \\(D\\) ocorreu, \\(B\\) é preferível a \\(A\\)). Para \\(D = \\Omega\\), temos o caso anterior: \\(A \\precsim B\\) \\(\\Leftrightarrow (A|\\Omega) \\precsim (B|\\Omega)\\). Suponha que vale as suposições SP1 a SP5 e, adicionalmente, SP6: \\((A|D) \\precsim (B|D) \\Leftrightarrow (A \\cap D) \\precsim (B \\cap D)\\) \\(~~\\Big( (A \\cap D|\\Omega) \\precsim (B \\cap D|\\Omega) \\Big)\\) Teorema 12: \\(\\forall A, B, D \\in \\mathcal{A}\\), considere \\(\\precsim\\) satisfazendo SP1 a SP6. Então \\(P: \\mathcal{A} \\rightarrow [0,1]\\) de modo que para cada \\(A \\in \\mathcal{A}\\) é associada \\(P(A) \\in [0,1]\\) tal que \\(A \\sim \\left\\{X \\in \\left[0,P(A)\\right]\\right\\}\\) é uma medida de probabilidade que representa \\(\\precsim\\), isto é, \\[(A|\\Omega) \\precsim (B|\\Omega) \\Leftrightarrow P(A) \\leq P(B).\\] Além disso, se \\(D \\in \\mathcal{A}\\) é tal que \\(P(D) \\geq 0\\), então \\[(A|D) \\precsim (B|D) \\Leftrightarrow P(A|D) \\leq P(B|D),\\] onde \\(P(\\cdot|D): \\mathcal{A} \\rightarrow [0,1]\\) é uma medida de probabilidade tal que \\[P(A|D) = \\frac{P(A \\cap D)}{P(D)}.\\] Referências "],
["Bayes.html", "2 Introdução à Inferência Bayesiana 2.1 Conceitos Básicos 2.2 Suficiência 2.3 Distribuição a Priori", " 2 Introdução à Inferência Bayesiana 2.1 Conceitos Básicos Inferência Estatística: fazer afirmações sobre quantidades não observáveis em um determinado contexto. \\(\\theta\\) : parâmetro - quantidade desconhecida de interesse (não-observável em determinado contexto). \\(\\Theta\\) : espaço paramétrico - conjunto onde \\(\\theta\\) toma valores (supostamente conhecido). \\(E=\\left(\\boldsymbol X, \\theta, \\left\\{f(\\boldsymbol x|\\theta)\\right\\}\\right)\\): experimento - “tornar visível algo que antes era invisível” ou, mais especificamente no nosso contexto, observar uma realização \\(\\boldsymbol x \\in \\mathfrak{X}\\) de um vetor aleatório \\(\\boldsymbol X\\) com alguma distribuição \\(f(\\boldsymbol x|\\theta)\\). Essa distribuição pertence, na maioria dos casos, à uma família de distribuições fixada mas que depende do parâmetro desconhecido de interesse \\(\\theta\\). Note que na grande maioria dos problemas do dia a dia de um estatístico ele se utiliza de resultados experimentais para fazer afirmações sobre \\(\\theta\\) e este, por sua vez, é não-observável em geral. \\(\\mathfrak{X}\\) : espaço amostral - conjunto onde \\(\\boldsymbol X\\) toma valores (supostamente conhecido). \\(\\mathcal{F}\\) : \\(\\sigma\\)-álgebra de (sub)conjuntos de \\(\\mathfrak{X}\\). Neste espaço amostral, defini-se uma família \\(\\mathcal{P}=\\{P(\\cdot|\\theta): \\theta \\in \\Theta\\}\\), isto é, um conjunto de distribuições (condicionais) para \\(\\boldsymbol X\\) indexadas por \\(\\theta\\). \\((\\mathfrak{X},\\mathcal{F},\\mathcal{P})\\) : modelo estatístico (clássico). \\(V_X(\\theta)=f(\\boldsymbol x |\\theta)\\) : função de verossimilhança. \\(~\\) 2.1.1 Inferência Frequentista (ou Clássica) \\(\\theta\\) é considerado fixo (apesar de desconhecido) e, portanto, não recebe uma distribuição de probabilidade. Baseia-se no \" princípio\" da amostragem repetida (interpretação frequentista de probabilidade), isto é, supõe que é possivel realizar infinitas vezes o experimento. Assim, o \\(\\boldsymbol x\\) é apenas um dos possiveis resultados (hipóteticos) do experimento. Probabilidade somente é definida em (uma \\(\\sigma-álgebra\\) de) \\(\\mathfrak{X}\\). 2.1.2 Inferência Bayesiana Baseia-se na interpretação subjetivista de probabilidade, de modo que a SUA incerteza sobre algo desconhecido deve ser quantificada (traduzida) em termos de probabilidade. Assim, SUA incerteza sobre o parâmetro (desconhecido) é representada por uma distribuição de probabilidade, \\(\\theta\\) é tratado como uma variável aleatória (v.a.) e SUA distribuição para \\(\\theta\\) antes da realização do experimento, \\(f(\\theta),\\) é chamada de distribuição a priori. Note que a atribuição de uma distribuição a prior para \\(\\theta\\) independe da natureza do parâmetro, ele pode ser a proporção de indivíduos que avalia positivamente o governo atual (quantidade essa que muda a todo instante) ou ainda a milésima casa do \\(\\pi\\) (algum número de 0 a 9, fixo porém desconhecido no momento dessa leitura). A atualização de SUA incerteza sobre \\(\\theta,\\) incorporando uma nova informação trazida pelos dados \\(\\boldsymbol x\\) (representada por \\(f(\\boldsymbol x| \\theta)\\)) é feita pelo Teorema de Bayes: Teorema de Bayes: \\[\\underbrace{f(\\theta| \\boldsymbol x)}_{dist. posteriori}=\\dfrac{f(\\theta)f(\\boldsymbol x|\\theta)}{\\displaystyle \\int_{\\Theta}f(\\boldsymbol x|\\theta)dP_\\theta} \\propto~ \\underbrace{f(\\theta)}_{priori}\\overbrace{f(\\boldsymbol x|\\theta).}^{verossimilhança}\\] Toda a inferência sobre \\(\\theta\\) será baseada exclusivamente em \\(f(\\theta| \\boldsymbol x)\\), não sendo necessário considerar pontos amostrais que poderiam mas não foram observados (como é feito na inferência frequentista). \\(~\\) Observação: será utilizada a notação geral para integral (de Lebesgue): \\[\\displaystyle \\int_{\\Theta}f(\\boldsymbol x|\\theta)dP_\\theta = \\left\\{ \\begin{array}{ll} \\displaystyle \\int_{\\Theta}f(\\boldsymbol x|\\theta) f(\\theta) d\\theta ~&amp;~ (caso~~contínuo)\\\\ \\displaystyle \\sum_{\\Theta}f(\\boldsymbol x|\\theta) f(\\theta) ~&amp;~ (caso~~discreto) \\end{array}\\right.\\] \\(~\\) Exemplo 1.a: Suponha que existem duas moedas, uma delas tem \\(\\theta =1/2\\) (honesta) e a outra \\(\\theta=3/4\\) (viesada). Uma moeda é escolhida e é feito um lançamento da moeda selecionada. Nesse experimento, tem-se \\(X|\\theta \\sim Ber(\\theta)\\), com \\(\\Theta=\\{1/2,3/4\\}\\) e \\(\\mathfrak{X}=\\{0,1\\}\\). Como “chutar” o valor de \\(\\theta\\)? Considere que não existe razão para você acreditar que há algum tipo de preferência na escolha de uma ou outra moeda, isto é, considere que a priori \\(f(\\theta=1/2)\\) \\(=f(\\theta=3/4)\\) \\(=1/2\\). Suponha que o lançamento resultou em cara (\\(x=1\\)). Então \\(f(\\theta = 3/4|X=1)\\) \\(=\\dfrac{f(X=1|\\theta=3/4)f(\\theta=3/4)}{\\sum_\\theta f(X=1|\\theta)f(\\theta)}\\) \\(=\\dfrac{\\dfrac{3}{4}\\dfrac{1}{2}}{\\dfrac{3}{4}~\\dfrac{1}{2}+\\dfrac{1}{2}~\\dfrac{1}{2}}=\\) \\(\\dfrac{3/4}{5/4}=\\dfrac{3}{5}\\) \\(= 1-\\underbrace{f(\\theta=1/2|X=1)}_{2/5}\\). Se, no entando, o resultado do lançamento da moeda fosse coroa (\\(x=0\\)), teríamos \\(P(\\theta=3/4|X=0)\\) \\(=\\dfrac{\\dfrac{1}{4}~\\dfrac{1}{2}}{\\dfrac{1}{4}~\\dfrac{1}{2}+\\dfrac{1}{2}~\\dfrac{1}{2}}\\) \\(=\\dfrac{1/2}{1/2+2/2}=\\dfrac{1}{3}\\). Assim, se sua decisão for escolher o valor mais provável de \\(\\theta\\) após observar \\(x\\), a conclusão seria que a moeda é viesada \\((\\theta=3/4)\\) se for observado cara \\((x=1)\\) e que a moeda é honesta \\((\\theta=1/2)\\) se o resultado for coroa \\((x=0)\\). \\(~\\) Exemplo 1.b: Considere agora que serão realizados \\(n\\) lançamentos da moeda, de modo que agora tem-se \\(X|\\theta \\sim Bin(n,\\theta)\\), \\(\\theta \\in \\{1/2,3/4\\}\\), \\(x \\in \\{0,1,\\ldots,n\\}\\). Suponha que observa-se \\(X=x\\). \\(f(\\theta=3/4|X=x)\\) \\(=\\dfrac{f(x|\\theta=3/4)f(\\theta=3/4)}{\\displaystyle \\sum_{\\theta\\in \\{1/2,3/4\\}}f(x|\\theta)f(\\theta)}\\) \\(=\\dfrac{\\displaystyle \\binom{n}{x}\\left(\\dfrac{3}{4}\\right)^x\\left(\\dfrac{1}{4}\\right)^{n-x}\\dfrac{1}{2}}{\\displaystyle \\binom{n}{x}\\left(\\dfrac{3}{4}\\right)^x\\left(\\dfrac{1}{4}\\right)^{n-x}\\dfrac{1}{2}+\\displaystyle\\binom{n}{x}\\left(\\dfrac{1}{2}\\right)^x\\left(\\dfrac{1}{2}\\right)^{n-x}\\dfrac{1}{2}}\\) \\(=\\dfrac{1}{1+\\left(\\dfrac{2^n}{3^x}\\right)}\\) \\(=\\dfrac{3^x}{3^x + 2^n}\\). theta = c(0.5,0.75) prior=0.5 # priori P(theta[1]) = 1-P(theta[2]) n=5; post = function(x){ (prior*dbinom(x,n,theta)) / sum(prior * dbinom(x,n,theta)) } tibble(x=as.factor(rep(seq(0,n),each=length(theta))), x1=rep(theta,(n+1)),x2=rep(theta,(n+1)),y1=0, y2=as.vector(apply(matrix(seq(0,n)),1,post))) %&gt;% ggplot() + geom_hline(yintercept=0.5,col=&quot;darkgrey&quot;,lty=3) + geom_segment(aes(x=x1, xend=x2, y=y1,yend=y2,colour=x),lwd=2) + xlab(expression(theta)) + ylab(expression(paste(&quot;P(&quot;,theta,&quot;|x)&quot;))) + theme_bw()+ gganimate::transition_states(x) \\(~\\) Note que o Exemplo 1.a é um caso particular desse exemplo com \\(n=1\\). Se novamente sua decisão é baseada no valor mais provável de \\(\\theta\\), temos \\(f(\\theta=3/4|X=x) &gt; \\dfrac{1}{2}\\) \\(\\Longleftrightarrow \\dfrac{3^x}{3^x + 2^n} &gt; \\dfrac{1}{2}\\) \\(\\Longleftrightarrow {3^x} &gt; {2^n}\\) \\(\\Longleftrightarrow \\dfrac{x}{n} = \\bar{x} &gt; \\log_3{2}\\approx 0,63\\). \\(~\\) Exemplo 1.c: Considere que uma moeda será lançada \\(n\\) vezes mas que \\(\\theta\\) é desconhecido, de modo que \\(\\Theta = [0,1]\\). Para simplificar, vamos assumir \\(f(\\theta)=\\mathbb{I}_{[0,1]}(\\theta)\\), isto é, \\(\\theta \\sim Unif(0,1)\\sim Beta(1,1)\\). Essa priori corresponde ao caso em que você acredita que todos os valores possíveis para \\(\\theta\\) são igualmente “prováveis”, assim como nos exemplos anteriores. Novamente, \\(X|\\theta \\sim Bin(n,\\theta)\\) \\(f(\\theta|x)=\\) \\(\\dfrac{f(x|\\theta)f(\\theta)}{\\int_0^1 f(x|\\theta)f(\\theta)d\\theta}=\\) \\(\\dfrac{\\binom{n}{x}\\theta^x(1-\\theta)^{n-x} ~~\\mathbb{I}_{[0,1]}(\\theta)}{\\int_0^1\\binom{n}{x}\\theta^x(1-\\theta)^{n-x}d\\theta}=\\) \\(\\dfrac{\\dfrac{\\Gamma(1+x+1+n-x)}{\\Gamma(1+x)\\Gamma(1+n-x)}~~\\theta^x(1-\\theta)^{n-x}~~\\mathbb{I}_{[0,1]}(\\theta)}{\\underbrace{\\displaystyle \\int_0^1\\dfrac{\\Gamma(1+x+1+n-x)}{\\Gamma(1+x)\\Gamma(1+n-x)}~~\\theta^x(1-\\theta)^{n-x}d\\theta}_{1}}\\) \\(=\\dfrac{\\Gamma(1+x+1+n-x)}{\\Gamma(1+x)\\Gamma(1+n-x)}~~\\theta^x(1-\\theta)^{n-x}~~\\mathbb{I}_{[0,1]}(\\theta)\\). \\(~\\) Logo \\(\\theta|x \\sim Beta(1+x,1+n-x)\\). Nesse exemplo, o valor “mais provável” (com maior densidade a posteriori) para \\(\\theta\\) é a moda da distribuição, \\(Moda(\\theta|x)\\) \\(= \\dfrac{(1+x)-1}{(1+x)+(1+n-x)-2}\\) \\(= \\dfrac{x}{n}\\) \\(=\\bar{x}\\). \\(~\\) Exemplo 1.d Por fim, suponha que no exemplo anterior, sua opinião a priori é representada por uma distribuição beta qualquer com parâmetros \\(a\\) e \\(b\\), \\(a,b &gt; 0\\). Desta forma, \\(X|\\theta \\sim Bin(n,\\theta)\\) e \\(\\theta\\sim Beta(a,b)\\). Calculando a distribuição a posteriori de forma similar ao exemplo anterior, temos que \\(\\theta|X=x \\sim Beta(a+x,b+n-x)\\). \\(~\\) require(transformr) theta = seq(0,1,0.01) a=1; b=1; n=5 post1 = as.vector(apply(matrix(seq(0,n)),1, function(x){dbeta(theta,a+x,b+n-x)})) tibble(x=as.factor(rep(seq(0,n),each=length(theta))), theta=rep(theta,(n+1)),post=post1) %&gt;% ggplot() + geom_line(aes(x=theta,y=post, colour=x),lwd=1.5) + geom_line(aes(x=theta,y=dbeta(theta,a,b),colour=&quot;Prior&quot;),lwd=1,lty=2) + xlab(expression(theta)) + ylab(expression(paste(&quot;f(&quot;,theta,&quot;|x)&quot;))) + theme_bw()+ gganimate::transition_states(x) \\(~\\) Suponha que \\(a=b=1\\) (como no exemplo anterior), \\(n=5\\) e \\(x=2\\), de modo que \\(\\theta|x=2 \\sim Beta(3,4)\\). Algumas medidas resumo da distribuição posterior para esse exemplo são \\(Moda(\\theta|x)\\) \\(=\\dfrac{a+x-1}{a+b+n-2}\\) \\(=\\dfrac{2}{5}\\) \\(=0,4\\); \\(E[\\theta|x]\\) \\(=\\dfrac{a+x}{a+b+n}\\) \\(=\\dfrac{3}{7}\\) \\(=0,43\\); \\(Med(\\theta|x)\\) \\(\\approx \\dfrac{a+x-1/3}{a+b+n-2/3}\\) \\(=\\dfrac{8/3}{19/3}\\) \\(\\approx 0,42\\); \\(Var(\\theta|x)\\) \\(=\\dfrac{(a+x)(b+n-x)}{(a+b+n)^2(a+b+n+1)}\\) \\(=\\dfrac{12}{392}\\) \\(\\approx 0,031\\). \\(~\\) 2.2 Suficiência Muitas vezes, a quantidade de dados é muito grande e desejamos “resumir” a informação trazida pelos dados. Uma forma de fazê-lo sem perder informação sobre o parâmetro de interesse é usar uma estatística suficiente. \\(~\\) Definição: Dizemos que uma função da amostra \\(T:\\mathfrak{X} \\rightarrow \\mathbb{R}^p\\) é uma estatística suficiente (do ponto de vista frequentista) se \\(f\\left(\\boldsymbol x | T(\\boldsymbol x),\\theta\\right) = f\\left(\\boldsymbol x | T(\\boldsymbol x)\\right)\\). \\(~\\) Em palavras, conhecendo o valor da estatística suficiente, a distribuição da amostra (do v.a. \\(\\boldsymbol X\\)) não depende mais do parâmetro \\(\\theta\\). Isso quer dizer que a informação disponível na amostra \\(\\boldsymbol X\\) sobre \\(\\theta\\) está contida em \\(T(\\boldsymbol X)\\). Obter uma estatística suficiente nem sempre é uma tarefa fácil mas o resultado a seguir, conhecido como critério da fatoração permite identificar estatísticas suficientes. \\(~\\) Teorema: A estatística \\(T:\\mathfrak{X} \\rightarrow \\mathbb{R}^p\\) é suficiente para a família de distribuições \\(\\left\\{f(\\cdot|\\theta):\\theta \\in \\Theta\\right\\}\\) se, e somente se, para todo \\(x \\in \\mathfrak{X}\\) e para todo \\(\\theta \\in \\Theta\\), podemos escrever \\(f\\left(\\boldsymbol x | \\theta\\right)\\) \\(= u(\\boldsymbol x) v\\left(T(\\boldsymbol x),\\theta\\right)\\), onde \\(u\\) é uma função positiva que não depende de \\(\\theta\\) e \\(v\\) é uma função não-negativa e depende de \\(\\boldsymbol x\\) somente através de \\(T(\\boldsymbol x)\\). \\(~\\) Exemplo: Seja \\(X_1,\\ldots,X_n\\) v.a. tais que, condicional ao conhecimento de \\(\\theta\\), são c.i.i.d. com \\(X_1|\\theta \\sim Exp(\\theta)\\). Então, \\(f(\\boldsymbol x|\\theta)\\) \\(=\\prod f(x_i|\\theta)\\) \\(=\\prod \\theta e^{-\\theta x_i} ~\\mathbb{I}_{\\mathbb{R+}}(x_i)\\) \\(=\\theta^n e^{-\\theta \\sum x_i} ~\\prod ~\\mathbb{I}_{\\mathbb{R+}}(x_i)\\) \\(= v\\left(\\sum x_i, \\theta\\right) u(\\boldsymbol x)\\). Portanto, \\(T(\\boldsymbol x) = \\sum x_i\\) é estatística suficiente para \\(\\theta\\). De fato, como \\(T(\\boldsymbol X)\\) \\(= \\sum X_i | \\theta\\) \\(\\sim Gama(n,\\theta)\\) e \\(\\left\\{X_1=x_1,\\ldots,X_n=x_n\\right\\}\\) \\(\\subseteq \\left\\{T(\\boldsymbol X) = \\sum X_i = \\sum x_i = t\\right\\}\\), \\(f\\left(\\boldsymbol x| T(\\boldsymbol x),\\theta\\right)\\) \\(=\\dfrac{f\\left(\\boldsymbol{x},T(\\boldsymbol{x})|\\theta\\right)}{f\\left(T(\\boldsymbol{x})|\\theta\\right)}\\) \\(=\\dfrac{f\\left(\\boldsymbol{x}|\\theta\\right)}{f\\left(\\sum{X_i}|\\theta\\right)}\\) \\(=\\dfrac{\\theta^n e^{\\theta \\sum x_i} ~\\prod ~\\mathbb{I}_{\\mathbb{R+}}(x_i)}{\\frac{\\theta^n}{\\Gamma(n)}t^{n-1} e^{\\theta t} ~\\prod ~\\mathbb{I}_{\\mathbb{R+}}(x_i)}\\) \\(= \\dfrac{\\Gamma(n)}{t^{n-1}} ~\\mathbb{I}_{\\mathbb{R}_+}\\left(t\\right)\\), que não depende de \\(\\theta\\). \\(~\\) Sob o enfoque bayesiano, a definição de suficiência é um pouco mais intuitiva que a frequentista. Definição: Dizemos que uma função da amostra \\(T:\\mathfrak{X} \\rightarrow \\mathbb{R}^p\\) é uma estatística suficiente (no sentido bayesiano) se \\(f\\left(\\theta | T(\\boldsymbol x)\\right) = f\\left(\\theta | \\boldsymbol x\\right)\\), para todo \\(x \\in \\mathfrak{X}\\). \\(~\\) Voltando ao exemplo, suponha agora que, a priori, \\(\\theta \\sim Gama(a,b)\\). Então, \\(f(\\theta| \\boldsymbol x)\\) \\(\\propto f(\\boldsymbol x|\\theta)f(\\theta)\\) \\(\\propto \\theta^n e^{-\\theta \\sum x_i} ~~\\theta^{a-1}e^{-b\\theta}\\) \\(\\propto \\theta^{a+n-1} e^{-(b+\\sum x_i)\\theta}\\) Seja \\(T = T(\\boldsymbol X) = \\sum X_i\\), temos que \\(T|\\theta\\sim Gamma(n,\\theta)\\), de modo que \\(f\\left(\\theta| T(\\boldsymbol x)=t\\right)\\) \\(\\propto f(t|\\theta)f(\\theta)\\) \\(\\propto \\theta^n t^{n-1} e^{\\theta t} ~~\\theta^{a-1}e^{-b\\theta}\\) \\(\\propto \\theta^{a+n-1} e^{-(b+t)\\theta}\\) , com \\(t=\\sum x_i\\). Assim, \\(\\theta|\\boldsymbol x\\) \\(\\sim \\theta|T(\\boldsymbol x)\\) \\(\\sim Gamma\\left(a+n,b+\\sum x_i\\right)\\) e, portanto, \\(T(\\boldsymbol X) = \\sum X_i\\) é estatística suficiente para \\(\\theta\\). \\(~\\) Para os casos mais comuns, as definições são equivalentes (Schervish 2012). Pelo teorema da fatoração, temos que \\(f\\left(\\boldsymbol x | \\theta\\right)\\) \\(= u(\\boldsymbol x) v\\left(T(\\boldsymbol x),\\theta\\right)\\) e, portanto \\(f(\\theta|\\boldsymbol x)\\) \\(\\propto f(\\theta) f\\left(\\boldsymbol x | \\theta\\right)\\) \\(\\propto f(\\theta) v\\left(T(\\boldsymbol x),\\theta\\right)\\) que só depende de \\(\\boldsymbol x\\) por meio de \\(T(\\boldsymbol x)\\). \\(~\\) Um dos princípios de inferência estatística é o princípio da suficiência. Segundo este, se \\(T\\) é uma estatística suficiente para \\(\\theta\\) e se dois pontos amostrais \\(\\boldsymbol x, \\boldsymbol y \\in \\mathfrak{X}\\) são tais que \\(T(\\boldsymbol x)=T(\\boldsymbol y)\\) então as inferências baseadas nesses pontos devem ser as mesmas. Adiante, retomaremos esse princípio de forma mais formal. \\(~\\) 2.3 Distribuição a Priori A priori é sempre subjetiva (assim como a escolha do modelo estatístico)! Por exemplo, dizer que os dados seguem uma distribuição normal, é uma escolha subjetiva, muitas vezes baseadas nas facilidades matemáticas que essa distribuição proporciona. Do mesmo modo, suponha que dois indivíduos que consideram que a distribuição do parêmetro é simétrica, com mesmas suposições sobre média e variância. O primeiro pode optar por representar sua distribuição usando uma distribuição Normal, enquanto o segundo pode utilizar uma distribuição T ou Cauchy. Não existe “opinião errada”, existem opiniões diferentes, dado o nível de conhecimento e as experiências prévias do indivíduo. A priori deve ser sua opinião apenas sobre o parâmetro \\(\\theta\\) e não deve depender de fatores como o desenho do experimento ou o objetivo do estudo. 2.3.1 Método do Histograma Muitas vezes, para “extrair” o conhecimento de um especialista, podemos dividir o espaço paramétrico em regiões e pedir para o especialista “ordenar” esses conjuntos, utilizando “pesos” que refletem a crença que o parâmetro esteja em cada uma daquelas regiões. Exemplo 1. (Albert (2009), pág 27) Seja \\(\\theta\\) uma proporção desconhecida \\((\\Theta=[0,1])\\); Considere a partição \\(T = \\left\\{[0,0.1), [0.1,0.2), \\ldots, [0.9,1] \\right\\}\\); Suponha que um especialistas atribui pesos \\(p=(1, 5.2, 8, 7.2, 4.6, 2.1, 0.7, 0.1, 0, 0)\\) a esse intervalos; A piori, nesse caso, é o histograma apresentado a seguir. p=c(1, 5.2, 8, 7.2, 4.6, 2.1, 0.7, 0.1, 0, 0) prior = c(0,p/(sum(p))) tibble(theta=seq(0,1,0.1), prior) %&gt;% ggplot(data=.) + geom_step(aes(x=theta,y=prior),direction=&quot;vh&quot;,color=&quot;red&quot;,lwd=1.5) Voltando ao exemplo da moeda, suponha novamente que foram observados \\(x=2\\) sucessos em \\(n=5\\) lançamentos. A posteriori nesse caso pode ser obtida multiplicando a distribuição a priori pela verossimilhança e “padronizando” a função obtida. Assim: n=5 x=2 p = c(1, 5.2, 8, 7.2, 4.6, 2.1, 0.7, 0.1, 0, 0) p = p/(sum(p)) theta = seq(0,1,0.01) prior = c(rep(p,each=10),0)/sum(c(rep(p,each=10),0)) vero = dbinom(x,n,theta)/sum(dbinom(x,n,theta)) post = (prior * vero)/sum(prior * vero) pH = tibble(theta=rep(theta,3),dens=c(prior,vero,post),Dist=rep(c(&#39;1.priori&#39;,&#39;2.verossimilhança&#39;,&#39;3.posteriori&#39;),each=101)) %&gt;% ggplot(data=.) + geom_line(aes(x=theta,y=dens,colour=Dist),lwd=1.5) pH \\(~\\) 2.3.2 Elicitação de Hiperparâmetros Nessa abordagem, a priori é obtida da seguinte maneira: Escolha uma família de distribuições conveniente. O conceito de “conveniência” aqui pode levar em conta, por exemplo, o suporte da distribuição, se é flexível o suficiente para acomodar diversos tipos de opinião, se permite a obtenção analítica da posteriori e assim por diante; Obtenha um conjunto de medidas resumo (como média, variância, quantis, etc.); Utilize as medidas resumo para calcular hiperparâmetros da distribuição escolhida. \\(~\\) Exemplo: Na seção anterior, a priori dada pelo histograma tem média \\(m=0.31\\) e variância aproximadamente \\(v=0.02\\). Podemos utilizar como priori, por exemplo, uma distribuição beta com essa média e variância, já que a beta tem um suporte conveniente e facilita as contas, como também já vimos. Assim, vamos considerar uma distribuição \\(Beta(a,b)\\) e escolher \\(a\\) e \\(b\\) satisfazendo: \\(E[\\theta]\\) \\(=\\dfrac{a}{a+b}\\) \\(=m\\) \\(\\Longleftrightarrow b=\\left(\\dfrac{1-m}{m}\\right)a\\) \\(Var(\\theta)\\) \\(=\\dfrac{ab}{(a+b)^2(a+b+1)}\\) \\(=0.02\\) \\(\\Longleftrightarrow a=\\dfrac{m(m-m^2-v)}{v}\\) Resolvendo o sistema temos, de forma geral, que \\(a=\\dfrac{m(m-m^2-v)}{v}\\) e \\(b=\\dfrac{(1-m)(m-m^2-v)}{v}\\). Assim, no nosso exemplo, teríamos uma \\(Beta(3,6.7)\\). Além disso, já vimos que, nesse caso, a distribuição a posteriori é \\(Beta(3+x,6.7+n-x)\\). Considerando novamente \\(n=5\\) e \\(x=2\\), temos: n=5; x=2 m=0.31; v=0.02 a=m*(m-m^2-v)/v; b=(1-m)*(m-m^2-v)/v p = c(1, 5.2, 8, 7.2, 4.6, 2.1, 0.7, 0.1, 0, 0) p = p/(sum(p)) theta = seq(0,1,0.01) prior = dbeta(theta,a,b)/sum(dbeta(theta,a,b)) vero = dbinom(x,n,theta)/sum(dbinom(x,n,theta)) post = dbeta(theta,a+x,b+n-x)/sum(dbeta(theta,a+x,b+n-x)) priorH = c(rep(p,each=10),0)/sum(c(rep(p,each=10),0)) tibble(theta=rep(theta,4),dens=c(prior,vero,post,priorH), Dist=rep(c(&#39;1.Priori Beta&#39;,&#39;2.Verossimilhança&#39;,&#39;3.Posteriori&#39;,&#39;0.Priori Histograma&#39;),each=101)) %&gt;% ggplot(data=.) + geom_line(aes(x=theta,y=dens,colour=Dist),lwd=1.5) \\(~\\) 2.3.3 Prioris Conjugadas Como visto no exemplo da moeda, em que a distribuição a priori era \\(Beta(a,b)\\), a posteriori era facilmente obtida e também estava na classe das distribuições \\(Beta\\). Em particular, quando observa-se \\(x\\) sucessos em \\(n\\) realizações de ensaios de Bernoulli, a distribuição a posteriori é \\(Beta(a+x,b+n-x)\\). Isso ocorre pois essa distribuição pertence à uma classe bastante espefícica de distribuições a priori, chamadas distribuições conjugadas. \\(~\\) Definição Seja \\(\\mathcal{P}=\\{f(x|\\theta):\\;\\theta \\in \\Theta\\}\\) uma família de distribuições (condicionais) para \\(\\boldsymbol{X}\\) e considere \\(\\mathcal{C}=\\{h(\\theta|a):\\;a\\in A\\}\\) uma família de distribuições para \\(\\theta\\). Dizemos que (a família) \\(\\mathcal{C}\\) é conjugada para \\(\\mathcal{P}\\) se, \\(\\forall \\;h(\\theta)\\in \\mathcal{C},\\) \\(h(\\theta|\\boldsymbol{x})\\propto f(\\boldsymbol x|\\theta)h(\\theta) \\in \\mathcal{C},\\forall \\boldsymbol x \\in \\mathfrak{X}.\\) \\(~\\) Resultado 1. Seja \\(X\\) v.a. tal que, condicional ao conhecimento de \\(\\theta,\\) \\(X|\\theta \\sim Bin(n,\\theta).\\) Considere que, a priori, \\(\\theta \\sim Beta(a,b).\\) Então, \\(\\theta|X=x \\sim Beta(a+x,b+n-x).\\) Portanto, a família \\(\\mathcal{C}=\\{Beta(a_1,a_2):\\;(a_1,a_2)\\in \\mathbb{R}^2_+\\}\\) é conjugada para \\(\\mathcal{P}=\\{Bin(n,\\theta):\\;\\theta \\in [0,1]\\}.\\) \\(~\\) Esse resultado também vale se \\(X_1,...,X_n\\) são v.a.s condicionalmente independentes e identicamente distribuidas (c.i.i.d.) com \\(X_i|\\theta \\sim Ber(\\theta)\\) \\(X_i|\\theta\\sim Geo(\\theta),\\) \\(i=1,...,n \\; c.i.i.d.\\) \\(X_i|\\theta \\sim BinNeg(k,\\theta)\\) \\(\\theta\\sim Beta(a,b)\\Rightarrow\\) \\(\\theta|\\boldsymbol X=\\boldsymbol x \\sim Beta(a+s,b+f)\\) em que \\(s\\) é o número de sucessos e \\(f\\) é o número de fracassos. \\(~\\) Resultado 2. (generalização do resultado anterior para o caso em que o número de categorias é maior que 2) Seja \\(\\boldsymbol X | \\boldsymbol \\theta \\sim Multinomial(n,\\boldsymbol \\theta)\\), isto é, sua função de probabilidade é dada por \\[f(\\boldsymbol x| \\boldsymbol \\theta)= \\binom{n}{x_1,x_2,...,x_k}~\\prod_{i=1}^{k-1}\\theta^i~\\underbrace{\\left(1-\\sum_{i=1}^{k-1}\\theta_i\\right)^{\\displaystyle n-\\sum_{i=1}^{k-1}x_i}}_{\\displaystyle \\theta_k^{~~x_k}}\\] em que \\(\\theta_i\\in [0,1]\\) com \\(\\sum_{i=1}^K\\theta_i=1\\), \\(x_i \\in \\{0,1,...,n\\}\\) com \\(\\sum_{i=1}^nx_i=n\\) e \\(\\displaystyle \\binom{n}{x_1,x_2,...,x_k}=\\dfrac{n!}{x_1!x_2!...x_k!}\\). Considere que, a priori, \\(\\boldsymbol \\theta \\sim Dirichlet(a_1,...,a_k),\\) \\(a_i &gt; 0, i=1,...,k\\), isto é, a f.d.p. a priori para \\(\\boldsymbol \\theta\\) é dada por \\[f(\\boldsymbol \\theta) = \\dfrac{\\Gamma(\\sum_{i=1}^K a_i)}{\\Gamma(a_1)\\Gamma(a_2)...\\Gamma(a_k)}\\prod_{i=1}^{k-1}\\theta_i^{a_i-1}\\bigg(\\underbrace{1-\\sum_{i=1}^{k-1}\\theta_i}_{\\theta_k}\\bigg)^{a_k-1}.\\] Então, a distribuição a posteriori para \\(\\boldsymbol \\theta\\) é \\(\\boldsymbol \\theta|\\boldsymbol X = \\boldsymbol x \\sim Dirichlet (a_1+x_1,...,a_k+x_k)\\). \\(~\\) Demo: Para verificar o resultado, basta ver que \\(f(\\boldsymbol\\theta|\\boldsymbol x)\\) \\(=\\dfrac{f(\\boldsymbol x| \\boldsymbol \\theta)f(\\boldsymbol \\theta)}{\\int_\\Theta f(\\boldsymbol x| \\boldsymbol \\theta)f(\\boldsymbol \\theta)d\\boldsymbol \\theta}\\) \\(\\propto f(\\boldsymbol x| \\boldsymbol \\theta)f(\\boldsymbol \\theta)\\) \\(\\propto \\prod_{i=1}^{k-1}\\theta_i^{(a_i+x_i-1)}\\left(1-\\sum_{i=1}^{k-1}\\theta_i\\right)^{(a_k+x_k)-1}\\) \\(~\\) Resultado 3. Seja \\(X_1,...,X_n\\) v.a. c.i.i.d tais que \\(X_i|\\theta \\sim Unif(0,\\theta)\\) e considere que, a priori,\\(\\theta \\sim Pareto(a,b)\\). Então \\(\\theta|\\boldsymbol X = \\boldsymbol x \\sim Pareto\\left(a+n,max\\{b,x_{(n)}\\}\\right)\\). \\(~\\) Demo: \\(f(\\boldsymbol x|\\theta)\\) \\(\\overset{ci}{=}\\prod_{i=1}^nf(x_i|\\theta)\\) \\(\\overset{id}{=}\\prod_{i=1}^n\\dfrac{1}{\\theta}\\mathbb{I}_{[0,\\theta]}(x_i)\\) \\(=\\dfrac{1}{\\theta^n}\\mathbb{I}_{[0,\\theta]}(x_{(n)})\\) \\(=\\dfrac{1}{\\theta^n}\\mathbb{I}_{[x_{(n)},+\\infty)}(\\theta)\\) em que \\(x_{(n)}=max\\{x_1,...,x_n\\}\\). \\(~\\) \\(f(\\theta)=\\dfrac{ab^a}{\\theta^{a+1}}\\mathbb{I}_{[b,+\\infty]}(\\theta)\\). Então \\(f(\\theta| \\boldsymbol x)\\) \\(\\propto f(\\boldsymbol x|\\theta)f(\\theta)\\) \\(=\\dfrac{1}{\\theta^{a+n+1}}\\mathbb{I}_{[x_{(n)},+\\infty)}(\\theta)\\mathbb{I}_{[b,+\\infty)}(\\theta)\\) \\(=\\dfrac{1}{\\theta^{a+n+1}}\\mathbb{I}_{[max\\{b,x_{(n)}\\},+\\infty)}(\\theta)\\) \\(~\\) \\(\\Rightarrow \\theta|\\boldsymbol X = \\boldsymbol x \\sim Pareto(a+n,max\\{b,x_{(n)}\\})\\). \\(~\\) Resultado 4. Seja \\(X_1,...,X_n,Y_1,...,Y_m\\) v.a. condicionalmente independentes tais que \\(X_i|\\theta\\sim Exp(\\theta),i=1,...,n\\) e \\(Y_j|\\theta \\sim Poisson(\\theta),j=1,...,m\\). Considere que, a priori, \\(\\theta \\sim Gama(a,b)\\). Então \\(\\theta| \\boldsymbol x,\\boldsymbol y \\sim Gama(a+n+\\sum_jy_j~,~b+m+\\sum_ix_i)\\). Demo: \\(f(\\boldsymbol x, \\boldsymbol y|\\theta)\\overset{ci}{=}f(\\boldsymbol x|\\theta)f(\\boldsymbol y|\\theta)\\overset{ci}{=}\\) \\(\\prod_{i=1}^nf(x_i|\\theta)\\prod_{j=1}^mf(y_i|\\theta)=\\) \\(\\prod_{i=1}^n\\theta e^{-\\theta x_i}\\prod_{j=1}^m\\dfrac{\\theta^{y_j}e^{-\\theta}}{y_j!}=\\) \\(\\dfrac{1}{\\prod_{j=1}^my_j!}\\theta^{n+\\sum_j y_j}e^{-(m+\\sum_ix_i)\\theta}\\) \\(~\\) \\(f(\\theta)=\\dfrac{b^a}{\\Gamma(a)}\\theta^{a-1}e^{-b\\theta}\\) \\(~\\) \\(f(\\theta| \\boldsymbol{x,y})\\propto f(\\boldsymbol x, \\boldsymbol y|\\theta)f(\\theta)\\propto\\) \\(\\theta^{[a+n+\\sum_jy_j]-1}e^{-[b+m+\\sum_ix_i]\\theta}\\) \\(~\\) \\(\\Rightarrow \\theta| \\boldsymbol x,\\boldsymbol y \\sim Gama(a+n+\\sum_jy_j,b+m+\\sum_ix_i)\\) \\(~\\) Resultado 5. Seja \\(~\\mathcal{P}=\\{f(\\boldsymbol x|\\theta):\\; \\theta \\in \\Theta\\}~\\) e \\(~\\mathcal{C}=\\{h(\\theta|a):\\;a\\in A\\}~\\) uma família conjugada para \\(\\mathcal{P}\\). Considere \\(\\mathcal{M}=\\{h(\\theta)=\\sum_{i=1}^mw_ih_i(\\theta):\\) \\(h_i \\in \\mathcal{C} \\; e \\; w_i&gt;0,\\; \\sum_{i=1}^m w_i=1\\}\\). Então \\(\\mathcal{M}\\) é família conjugada para \\(\\mathcal{P}\\). Demo: Como \\(\\mathcal{C}\\) é conjugada para \\(\\mathcal{P}\\), para toda função \\(h_i \\in \\mathcal{C}\\), temos que \\(f_i(\\theta|\\boldsymbol x)\\propto h_i(\\theta)f(\\boldsymbol x|\\theta)\\in \\mathcal{C}\\). Então \\(~\\) \\(h\\in \\mathcal{M}\\) \\(~\\Rightarrow~ f(\\theta|\\boldsymbol x)\\) \\(~\\propto~ h(\\theta)f(\\boldsymbol x|\\theta)\\) \\(~\\propto~\\sum_{i=1}^m w_i\\underbrace{h_i(\\theta)f(\\boldsymbol x|\\theta)}_{\\in \\mathcal{C}}\\) \\(~\\propto~\\sum_{i=1}^m w_i^*f_i(\\theta|\\boldsymbol x)\\in \\mathcal{M}\\). \\(~\\) Exemplo. Seja \\(X|\\theta \\sim Bin(n,\\theta)\\) e \\(f(\\theta)\\) \\(=wf_1(\\theta)+(1-w)f_2(\\theta)\\), com \\(f_1\\sim Beta(a_1,b_1)\\) e \\(f_2\\sim Beta(a_2,b_2)\\). \\(~\\) \\(f(\\theta|x)\\) \\(=\\dfrac{f(x|\\theta)f(\\theta)}{\\int_0^1f(x|\\theta)f(\\theta)}\\) \\(=\\dfrac{f(x|\\theta)[wf_1(\\theta)+(1-w)f_2(\\theta)]}{w\\int_0^1f_1(\\theta)f(x|\\theta)d\\theta+(1-w)\\int_0^1f_2(\\theta)d\\theta}\\) \\(\\propto\\dfrac{w\\binom{n}{x}\\frac{\\Gamma(a_1+b_1)}{\\Gamma(a_1)\\Gamma(b_1)}\\theta^{a_1+x-1}(1-\\theta)^{b_1+n-x-1}+(1-w)\\binom{n}{x}\\frac{\\Gamma(a_2+b_2)}{\\Gamma(a_2)\\Gamma(b_2)}\\theta^{a_2+x-1}(1-\\theta)^{b_2+n-x-1}}{\\underbrace{w\\binom{n}{x}\\frac{\\Gamma(a_1+b_1)}{\\Gamma(a_1)\\Gamma(b_1)}\\frac{\\Gamma(a_1+x)\\Gamma(b_1+n-x)}{\\Gamma(a_1+b_1+n)}}_{A}+\\underbrace{(1-w)\\binom{n}{x}\\frac{\\Gamma(a_2+b_2)}{\\Gamma(a_2)\\Gamma(b_2)}\\frac{\\Gamma(a_2+x)\\Gamma(b_2+n-x)}{\\Gamma(a_2+b_2+n)}}_{B}}\\) \\(\\propto~\\underbrace{\\dfrac{A}{A+B}}_{w^*}Beta(a_1+x,b_1+n-x)+\\underbrace{\\dfrac{B}{A+B}}_{1-w^*}Beta(a_2+x,b_2+n-x)\\). \\(~\\) Primeiramente, suponha que \\(n=5\\), e temos uma mistura das distribuições \\(Beta(5,12)\\) e \\(Beta(10,3)\\), com \\(w=0.5\\). O gráfico a seguir apresenta as distribuições a priori, a verossimilhança e a posteriori para cada possível valor de \\(x\\) em \\(\\left\\{0,1,\\ldots,5\\right\\}\\). a1=5; b1=12 a2=10; b2=3 n=5 w=0.5 theta = seq(0,1,0.01) A = as.vector(apply(matrix(seq(0,n)),1, function(x){w*choose(n,x)*gamma(a1+b1)/(gamma(a1)*gamma(b1))* (gamma(a1+x)*gamma(b1+n-x))/gamma(a1+b1+n)})) B = as.vector(apply(matrix(seq(0,n)),1, function(x){(1-w)*choose(n,x)*gamma(a2+b2)/(gamma(a2)*gamma(b2))* (gamma(a2+x)*gamma(b2+n-x))/gamma(a2+b2+n)})) w2 = A/(A+B) prior2 = as.vector(apply(matrix(seq(0,n)),1, function(x){w*dbeta(theta,a1,b1)+ (1-w)*dbeta(theta,a2,b2)})) post2 = as.vector(as.matrix(mapply(function(x,w2){ w2*dbeta(theta,a1+x,b1+n-x)+ (1-w2)*dbeta(theta,a2+x,b2+n-x)},seq(0,n),w2))) #vero = as.vector(apply(matrix(seq(0,n)),1, # function(x){dbinom(x,prob=theta,size=n)})) # Verossimilhança proporcional visualmente melhor vero = as.vector(apply(matrix(seq(0,n)),1, function(x){dbeta(theta,x+1,n-x+1)})) tibble(x=as.factor(rep(seq(0,n),each=length(theta))), w2=rep(w2,each=length(theta)), theta=rep(theta,(n+1)),vero=vero,prior=prior2,post=post2) %&gt;% ggplot() + geom_line(aes(x=theta,y=post, colour=x),lwd=1.5) + geom_line(aes(x=theta,y=prior,colour=&quot;Prior&quot;),lwd=1,lty=2) + geom_line(aes(x=theta,y=vero,colour=&quot;Verossimilhança&quot;),lwd=1,lty=2)+ xlab(expression(theta)) + ylab(expression(paste(&quot;f(&quot;,theta,&quot;|x)&quot;)))+ theme_bw() + gganimate::transition_states(x) \\(~\\) Agora, suponha que \\(n=5\\) e foi observado \\(x=2\\). Novamente, considere a mistura das distribuições \\(Beta(5,12)\\) e \\(Beta(10,3)\\) mas agora com pesos \\(w\\) variando no conjunto \\(\\left\\{0,0.1,\\ldots,0.9,1\\right\\}\\). x = 2 w = seq(0,1,0.1) A = as.vector(apply(matrix(w),1, function(w){w*choose(n,x)*gamma(a1+b1)/(gamma(a1)* gamma(b1))*(gamma(a1+x)*gamma(b1+n-x))/gamma(a1+b1+n)})) B = as.vector(apply(matrix(w),1, function(w){(1-w)*choose(n,x)*gamma(a2+b2)/(gamma(a2)* gamma(b2))*(gamma(a2+x)*gamma(b2+n-x))/gamma(a2+b2+n)})) w2 = A/(A+B) prior2 = as.vector(apply(matrix(w),1,function(w){ w*dbeta(theta,a1,b1)+(1-w)*dbeta(theta,a2,b2)})) post2 = as.vector(as.matrix(mapply(function(w,w2){ w2*dbeta(theta,a1+x,b1+n-x)+ (1-w2)*dbeta(theta,a2+x,b2+n-x)},w,w2))) vero = as.vector(apply(matrix(rep(x,2*n+1)),1, function(x){dbeta(theta,x+1,n-x+1)})) z&lt;-length(w) tibble(w=as.factor(rep(w,each=length(theta))), w2=rep(w2,each=length(theta)), theta=rep(theta,z), prior = prior2, post = post2, vero = vero) %&gt;% ggplot(colour = w) + geom_line(aes(x=theta,y=post, colour=w),lwd=1.5) + geom_line(aes(x=theta,y=prior,colour=&quot;Priori&quot;)) + geom_line(aes(x=theta,y=vero,colour=&quot;Verossimilhança&quot;),lwd=1,lty=2)+ xlab(expression(theta)) + ylab(expression(paste(&quot;f(&quot;,theta,&quot;|x)&quot;)))+ theme_bw() + gganimate::transition_states(w) \\(~\\) Referências "],
["TeoDec.html", "3 Introdução à Teoría da Decisão 3.1 Conceitos Básicos 3.2 Aleatorização e Decisões Mistas 3.3 Problemas com Dados", " 3 Introdução à Teoría da Decisão A teoria da decisão é uma das possíveis formas de embasar a inferência bayesiana. Sob essa abordagem, considera-se uma função de perda (ou função de utilidade) que quantifica numericamente as consequências de sua decisão para um dado valor do parâmetro. Essa quantificação de “preferência” é novamente subjetiva e é possível fazer uma construção de função de perda similar ao que fizemos com probabilidade. Ou seja, dado um conjunto de suposições, existe uma função de perda que representa numericamente suas preferências para cada decisão e cada possível valor do parâmetro. Essa construção não será feita aqui mas pode ser encontrada no livro Optimal Statistical Decisions (DeGroot,M.H.). \\(~\\) 3.1 Conceitos Básicos \\(d \\in \\mathcal{D}:\\) decisão - uma particular afirmação, por exemplo, sobre \\(\\theta\\). No contexto inferencial, uma decisão pode ser uma estimativa (pontual ou intervalar) para \\(\\theta\\) ou a escolha de uma hipótese específica em um teste de hipóteses. \\(\\mathcal{D}:\\) espaço de decisões - conjunto de todas as possíveis decisões (afirmações). \\(\\theta\\): estado da natureza - quantidade desconhecida ou parâmetro, no contexto de inferência estatística. \\(\\Theta\\): espaço dos estados da natureza - espaço paramétrico. \\(~\\) Exemplo 1. Suponha que você está saindo de casa pela manhã e precisa tomar uma importante decisão: levar ou não seu guarda-chuva. \\(\\mathcal{D}=\\{G,G^c\\}\\) , onde \\(G:\\) levar guarda-chuva. \\(\\Theta=\\{C,C^c\\}\\) , onde \\(C:\\) chuva. Suponha que carregar o guarda-chuva é algo que não lhe agrada mas, por outro lado, você odeia ficar molhado e acredita que a pior situação seria não levá-lo e tomar chuva. Você ficará incomodado se levar o guarda-chuva e chover pois, além de tê-lo carregado, voltou para casa com os sapatos molhados. Note que, nessas circunstâncias, o cenário preferido por você seria não levar o guarda-chuva e não chover. Para quantificar suas preferências, considere uma função de perda \\(L:\\mathcal{D}\\times\\Theta\\longrightarrow\\mathbb{R}\\), de modo que, quanto mais algum cenário lhe gera incômodo, maior sua perda. Um exemplo é apresentado a seguir. Estados da Natureza Decisão \\(C\\) \\(C^c\\) \\(G\\) 2 (ruim) 1 (bom) \\(G^c\\) 3 (pior) 0 (melhor) \\(P(\\theta)\\) p 1-p Uma possível maneira de tomar uma decisão é escolher a decisão “menos prejudicial”. Se levar o Guarda chuva, no pior caso, sua perda é \\(\\displaystyle \\max_\\theta L(G,\\theta)=2\\) e, se não levá-lo, a maior perda possível é \\(\\displaystyle \\max_\\theta L(G^c,\\theta)=3\\). Assim, a decisão que tem a menor dentre as maiores perdas é levar o guarda-chuva. Esse procedimento para tomada de decisões é chamado min-max e consiste em escolher a decisão \\(d&#39;\\) tal que \\(d&#39; = \\displaystyle \\underset{d}{\\text{argmin}} \\max_\\theta L(d,\\theta)\\). Sendo um pouco mais otimista, você pode escolher a decisão que tenha a maior dentre as menores perdas. Esse procedimento é chamado max-min e consiste em escolher a decisão \\(d&#39; = \\displaystyle \\underset{d}{\\text{argmax}} \\min_\\theta L(d,\\theta)\\). No nosso exemplo, esse procedimento também sugere que você sempre carregue o guarda-chuvas. Note que a decisão escolhida pelos dois procedimentos descritos anteriormente sugere que você sempre deve carregar o guarda-chuvas. Contudo, isso pode não ser razoável. Imagine que você estava lendo notícias antes de sair de casa e viu que a probabilidade de chuva era \\(0.01\\). Nesse caso, não parece fazer sentido você levar o guarda-chuva, já que isso vai te trazer um desconforto e a chance de chover é muito baixa. Assim, a probabilidade de chover deveria ser levada em consideração em sua tomada de decisão. Uma maneira de fazer isso é utilizar a perda esperada. Note que \\(\\theta\\) é uma quantidade desconhecida e, pelo que já foi discutido anteriormente, você deve descrever sua incerteza em relação a essa quantidade em termos de probabilidade. Suponha que no exemplo \\(P(C)=p\\), \\(0\\leq p\\leq 1\\). \\(~\\) Para cada decisão \\(d \\in \\mathcal{D}\\), é possível calcular o valor esperado da função de perda (perda esperada ou risco da decisão \\(d\\) contra a priori \\(P\\)) \\[\\rho(d,P) = E\\left[L(d,\\theta) ~|~ P\\right] = \\int_{\\Theta} L(\\theta) dP(\\theta).\\] \\(~\\) No exemplo, temos \\(E\\left[L(G^{},\\theta)\\right]\\) \\(=L(G,C)P(C) + L(G,C^c)P(C^c)\\) \\(=2p+1(1-p)\\) \\(=p+1\\); \\(E\\left[L(G^c,\\theta)\\right]\\) \\(=L(G^c,C)P(C) + L(G^c,C^c)P(C^c)\\) \\(=3p+0(1-p)\\) \\(=3p\\). Deste modo, as perdas esperadas associadas a cada decisão dependem da probabilidade de chuva \\(p\\). Assim, para cada possível valor de \\(p\\), deve-se tomar a decisão que tem menor perda esperada. Por exemplo, se a probabilidade de chuva é \\(p=0.1\\), temos que as perdas esperadas para as decisões de levar ou não o guarda-chuva são, respectivamente, \\(E\\left[L(G,\\theta)\\right]=1.1\\) e \\(E\\left[L(G^c,\\theta)\\right]=0.3\\). Assim, sob essa abordagem, sua decisão seria de não levar o guarda-chuva nesse caso. Por outro lado, se a probabilidade de chuva for \\(p=0.9\\), suas perdas esperadas seriam respectivamente \\(E\\left[L(G,\\theta)\\right]=1.9\\) e \\(E\\left[L(G^c,\\theta)\\right]=2.7\\), de modo que a decisão ótima seria levar o guarda-chuva. O gráfico a seguir apresenta as perdas para cada decisão \\(d\\) e para cada valor de \\(p\\). É possível notar que a decisão ótima é levar o guarda-chuva quando \\(p&gt;0.5\\) e não levá-lo caso contrário. \\(~\\) Vamos denotar por \\(\\rho^*\\) o risco de bayes, isto é, a perda esperada da decisão de Bayes (ou decisão ótima) \\(d^*\\in \\mathcal{D}\\) tal que \\(\\rho^*(P)\\) \\(=\\rho(d^*,P)\\) \\(=\\underset{d\\in\\mathcal{D}}{min}~\\rho(d,P)\\). \\(~\\) Para uma argumentação mais formal sobre a escolha pela decisão que minimiza a perda esperada, ver Optimal Statistical Decisions (DeGroot, M.H.). \\(~\\) \\(~\\) Vamos denotar um problema de decisão por \\(\\left(\\Theta, \\mathcal{D}, L, P\\right)\\), onde \\(\\Theta\\) é o espaço paramétrico, \\(\\mathcal{D}\\) é o espaço de decisões, \\(L: \\mathcal{D} \\times \\Theta \\longrightarrow \\mathbb{R}\\) é uma função de perda e \\(P\\) é a distribuição de probabilidade que representa sua crença sobre a quantidade desconhecida \\(\\theta\\). Equivalentemente, a função de perda \\(L\\) pode ser substituída por uma função de utilidade \\(U\\) (por exemplo, tome \\(U=-L\\)). \\(~\\) A solução para um problema de decisão \\(\\left(\\Theta, \\mathcal{D}, L, P\\right)\\) é a decisão de Bayes, \\({d}^* \\in \\mathcal{D}\\), tal que \\(\\rho^*(P) = \\rho({d}^*,P) = \\displaystyle \\inf_{d \\in \\mathcal{D}} \\rho(d,\\theta)\\), com \\(\\rho(d,P) = \\displaystyle \\int_\\Theta L(d,\\theta)dP(\\theta)\\). \\(~\\) 3.2 Aleatorização e Decisões Mistas Seja \\(D=\\left\\{d_1,d_2,\\ldots\\right\\}\\) um espaço de decisões e considere \\(\\mathcal{M}\\) o conjunto de todas as decisões mistas (ou aleatorizadas), isto é, para toda distribuição de probabilidades \\(Q=\\left\\{q_1,q_2,\\ldots\\right\\}\\), uma decisão \\(d\\in\\mathcal{M}\\) se \\(d\\) consiste em escolher a decisão \\(d_i\\) com probabilidade \\(q_i\\). Assim, a perda associada à uma decisão \\(d\\in\\mathcal{M}\\) é \\(L(d,\\theta) = \\sum q_i L(d_i,\\theta)\\) e o risco dessa decisão é \\(\\rho(d,P)\\) \\(= \\displaystyle \\int_\\Theta L(d,\\theta) dP(\\theta)\\) \\(=\\displaystyle \\int_\\Theta \\sum q_i L(d_i,\\theta) dP(\\theta)\\) \\(=\\displaystyle \\sum q_i \\int_\\Theta L(d_i,\\theta) dP(\\theta)\\) \\(=\\displaystyle \\sum q_i~ \\rho(d_i,\\theta)\\). Considere a decisão \\({d}^* \\in \\mathcal{D}\\) tal que \\(\\rho({d}^*,P) = \\displaystyle \\inf_{d \\in \\mathcal{D}} \\rho(d,\\theta)\\). Então, \\(\\forall ~d \\in \\mathcal{M}\\), \\(\\rho(d,P)\\) \\(=\\displaystyle \\sum q_i~ \\rho(d_i,\\theta)\\) \\(\\geq \\displaystyle \\sum q_i~ \\rho({d}^*,\\theta)\\). Em palavras, para toda decisão aleatorizada \\(d\\in\\mathcal{M}\\), existe uma decisão não aleatorizada \\({d}^*\\in\\mathcal{D} \\subset\\mathcal{M}\\), tal que \\(\\rho({d}^*,P) \\leq \\rho(d,P)\\). \\(~\\) 3.3 Problemas com Dados Suponha que antes de escolher uma decisão \\(d \\in \\mathcal{D}\\), é possível observar um v.a. \\(\\boldsymbol X\\) que (supostamente) está relacionado com \\(\\theta\\) (isto é, \\(\\boldsymbol X\\) traz alguma informação sobre \\(\\theta\\)). Desde modo, considere a família \\(\\mathcal{P}=\\left\\{ f(\\cdot|\\theta) : \\theta \\in \\Theta\\right\\}\\) de funções de distribuição condicionais para \\(\\boldsymbol X\\), isto é, para cada \\(\\theta \\in \\Theta\\) é possível determinar a distribuição condicional de \\(\\boldsymbol X|\\theta\\). Essa distribuição, juntamente com a distribuição a priori \\(f(\\theta)\\), determina totalmente uma distribuição conjunta \\(f(\\boldsymbol x,\\theta) = f(\\boldsymbol x|\\theta) f(\\theta)\\). Pode-se definir uma função de decisão \\(\\delta: \\mathfrak{X} \\longrightarrow \\mathcal{D}\\) que associa a cada resultado experimental \\(\\boldsymbol x \\in \\mathfrak{X}\\) uma decisão \\(d \\in \\mathcal{D}\\). Denote o conjunto de todas as possíveis funções de decisão por \\(\\Delta\\). O risco \\(r(\\delta,P)\\) da função de decisão \\(\\delta \\in \\Delta\\) é dado por \\(r(\\delta,P)\\) \\(=E\\left[L\\left(\\delta,\\theta\\right)\\right]\\) \\(=\\displaystyle \\int_\\Theta \\int_{\\mathfrak{X}} L\\left(\\delta(\\boldsymbol x),\\theta\\right) dP(\\boldsymbol x,\\theta)\\). A função de decisão de Bayes, \\({\\delta}^* \\in \\Delta\\), é tal que \\({\\rho}^*(P)\\) \\(=\\rho({\\delta}^*,P)\\) \\(=\\displaystyle \\inf_{\\delta\\in \\Delta} \\rho(\\delta,P)\\). \\(~\\) Exemplo 1. Seja \\(\\Theta=\\{\\theta_1,\\theta_2\\}\\), \\(\\mathcal{D}=\\{d_1,d_2\\}\\), \\(X|\\theta_1\\sim Ber(3/4)\\), \\(X|\\theta_2 \\sim Ber(1/3)\\), \\(\\mathfrak{X}=\\{0,1\\}\\) e, a priori, \\(P(\\theta=3/4)=P(\\theta=1/3)=1/2\\). Considere a função de perda a seguir. L \\(\\theta_1\\) \\(\\theta_2\\) \\(d_1\\) 0 5 \\(d_2\\) 10 0 Temos que \\(|\\Delta| = 2^2=4\\), de modo que as possíveis funções de decisão são \\(\\delta_1(x)=\\left\\{\\begin{array}{lr} d_1, &amp; x=1\\\\ d_2, &amp;x=0\\end{array}\\right.\\) \\(\\delta_2(x)=\\left\\{\\begin{array}{lr} d_1, &amp; x=0\\\\ d_2, &amp;x=1\\end{array}\\right.\\) \\(\\delta_3(x)=d_1\\) e \\(\\delta_4(x)=d_2\\). Para a função \\(\\delta_1\\), temos x \\(\\theta\\) \\(L(\\delta_1(x),\\theta)\\) \\(P(x|\\theta)\\) \\(P(\\theta)\\) \\(P(x,\\theta)\\) 0 \\(\\theta_1\\) 10 1/4 1/2 1/8 0 \\(\\theta_2\\) 0 2/3 1/2 2/6 1 \\(\\theta_1\\) 0 3/4 1/2 3/8 1 \\(\\theta_2\\) 5 1/3 1/2 1/6 \\(\\rho(\\delta_1)\\) \\(=\\displaystyle \\sum_{x=0}^1\\sum_{i=1}^2L(\\delta_1(x),\\theta_i)\\underbrace{P(X=x|\\theta_i)P(\\theta_i)}_{P(x,\\theta)}\\) \\(=10~\\dfrac{1}{8}+5~\\dfrac{1}{6}\\) \\(=\\dfrac{50}{24}\\) De forma análoga, \\(~\\rho(\\delta_2,P)=130/24\\) , \\(~\\rho(\\delta_3,P)=60/24\\) , \\(~\\rho(\\delta_4,P)=120/24\\) , e, assim. \\({\\delta}^*(x)={\\delta}^*_1(x)=\\left\\{\\begin{array}{rl} d_1, &amp; x=1\\\\ d_2, &amp; x=0\\end{array}\\right.\\) Risco de Bayes: \\(\\rho^*(P)=\\rho({\\delta}^*,P)=50/24\\). \\(~\\) Em problemas mais complicados, pode ser muito trabalhoso (ou impossível) obter a função de decisão dessa forma, chamada forma normal. Sob essa abordagem, é necessário encontrar a função de decisão de bayes \\({\\delta}^*\\) dentre todas as possíveis funções de decisão. Nesses casos, pode ser mais fácil resolver o problema usando a forma extensiva em que, para cada \\(\\boldsymbol x \\in \\mathfrak{X}\\), obtem-se a decisão de Bayes \\({d}_{x}^*\\) que minimiza o risco posterior, definido por \\(r_x(d)\\) \\(= \\displaystyle \\int_\\Theta L(d,\\theta) dP(\\theta|\\boldsymbol x)\\). Assim, é posível obter uma decisão de Bayes \\({d}_x^*\\) para um específico ponto \\(x\\) observado ou, ainda, construir uma função de decisão de Bayes, fazendo \\(~{\\delta}^*(\\boldsymbol x) = {d}_x^*~\\) para cada \\(\\boldsymbol x \\in \\mathfrak{X}\\). A seguir, é mostrado que essa duas formas produzem resultados que minimizam o risco. Note que \\(r(\\delta,P)\\) \\(=E\\left[L\\left(\\delta,\\theta\\right)\\right]\\) \\(=\\displaystyle \\int_\\Theta \\int_{\\mathfrak{X}} L\\left(\\delta(\\boldsymbol x),\\theta\\right) dP(\\boldsymbol x,\\theta)\\) \\(=\\displaystyle \\int_\\Theta \\int_{\\mathfrak{X}} L\\left(\\delta(\\boldsymbol x),\\theta\\right) dP(\\boldsymbol x|\\theta)dP(\\theta)\\) \\(=\\displaystyle \\int_{\\mathfrak{X}} \\left[ \\underbrace{\\int_\\Theta L\\left(\\delta(\\boldsymbol x),\\theta\\right) dP(\\theta|\\boldsymbol x)}_{r_x\\left(\\delta(\\boldsymbol x)\\right)} \\right]dP(\\boldsymbol x)\\). Note que a integral interna (em \\(\\theta\\)) pode ser resolvida para cada \\(\\boldsymbol x\\) fixado. Para cada \\(\\boldsymbol x\\), considere a decisão \\({d}_x^*\\) tal que \\(r_x\\left({d}_x^*\\right)\\) \\(=\\displaystyle \\inf_{d \\in \\mathcal{D}} r_x(d)\\). Assim \\(r(\\delta,P)\\) \\(=\\displaystyle \\int_{\\mathfrak{X}} \\left[ \\underbrace{\\int_\\Theta L\\left(\\delta(\\boldsymbol x),\\theta\\right) dP(\\theta|\\boldsymbol x)}_{r_x\\left(\\delta(\\boldsymbol x)\\right)} \\right]dP(\\boldsymbol x)\\) \\(=\\displaystyle \\int_{\\mathfrak{X}} \\left[ {r_x\\left(\\delta(\\boldsymbol x)\\right)} \\right]dP(\\boldsymbol x)\\) \\(\\geq \\displaystyle \\int_{\\mathfrak{X}} \\left[ {r_x\\left({d}_x^*\\right)} \\right]dP(\\boldsymbol x)\\) \\(= \\displaystyle \\int_{\\mathfrak{X}} \\left[ {r_x\\left({d}_x^*\\right)} \\right]dP(\\boldsymbol x)\\). Assim, a função \\({\\delta}^*(x)={d}^*_{x}\\) é uma função de decisão de Bayes. \\(~\\) No Exemplo 1 \\(~X|\\theta_1 \\sim Ber(3/4)\\) , \\(~X|\\theta_2 \\sim Ber(1/3)\\) e \\(~P(\\theta_1)=P(\\theta_2)=1/2\\). \\(P(\\theta_1|x=0)\\) \\(=\\dfrac{P(X=0|\\theta_1)P(\\theta_1)}{P(X=0|\\theta_1)P(\\theta_1)+P(X=0|\\theta_2)P(\\theta_2)}\\) \\(=\\dfrac{\\frac{1}{4}~\\frac{1}{2}}{\\frac{1}{4}~\\frac{1}{2}+\\frac{2}{3}~\\frac{1}{2}}\\) \\(=\\dfrac{3}{11}\\) \\(P(\\theta_2|X=0)\\) \\(=\\dfrac{8}{11}\\) \\(r_x(d_1,P)\\) \\(=\\displaystyle \\sum_{i=1}^2L(d_1,\\theta_i)P(\\theta_i|X=0)\\) \\(=0~P(\\theta_1|X=0)+10~P(\\theta_2|X=0)\\) \\(=\\dfrac{80}{11}\\) \\(r_x(d_2,P)\\) \\(=5~P(\\theta_1|X=0)+0~P(\\theta_2|X=0)\\) \\(=\\dfrac{15}{11}\\) Logo, para \\(x=0\\), \\({d}_0^*={d}_2\\). De forma análoga, para \\(x=1\\), \\({d}_1^*={d}_2\\) e, assim, \\({\\delta}^*(x)=\\left\\{\\begin{array}{rl} {d}_2, &amp; x=0\\\\ {d}_1, &amp; x=1~.\\end{array}\\right.\\) \\(~\\) "],
["Estimacao.html", "4 Estimação 4.1 Estimação Pontual 4.2 Estimação por Regiões 4.3 Custo das Observações", " 4 Estimação 4.1 Estimação Pontual Todos os problemas de inferência estatística podem ser vistos como um caso particular de Teoria da Decisão. Um problema de estimação pontual consiste em encontrar um “chute” para o valor do parâmetro \\(\\theta\\), de modo que o espaço de decisões é \\(\\mathcal{D}=\\Theta\\). Além disso, nesse tipo de problema é usual considerar funções de perda da forma \\(L(d,\\theta)=s(\\theta)\\Delta(d,\\theta)\\), onde \\(\\Delta\\) é alguma distância (ou uma medida de discrepância) relacionada ao erro por tomar a decisão \\(d\\) quando o valor do parâmetro é \\(\\theta\\) e \\(s\\) é uma função não-negativa relacionada à gravidade do erro para cada \\(\\theta\\) (pode ser constante). \\(~\\) Exemplo Considere um problema de estimação pontual, isto é, \\(\\mathcal{D}=\\Theta\\), onde a função de perda é dada por \\(L(d,\\theta)=(d-\\theta)^2\\), conhecida como perda quadrática. \\(r_x(d)\\) \\(=\\displaystyle \\int_\\Theta(d-\\theta)^2~dP(\\theta|x)\\) \\(=\\displaystyle \\int_\\Theta \\left(d^2 - 2d\\theta + \\theta^2\\right) dP(\\theta|x)\\) \\(=d^2\\displaystyle\\int_\\Theta dP(\\theta|x) - 2d\\int_\\Theta\\theta ~dP(\\theta|x) + \\int_\\Theta \\theta^2 ~dP(\\theta|x)\\) \\(=d^2-2d~E[\\theta|x]+E[\\theta^2|x]=g(d)\\). \\(\\dfrac{\\partial g(d)}{\\partial d}\\) \\(=2d-2E[\\theta|x]=0\\) \\(\\Rightarrow {d}_x^*=E[\\theta|x]\\). Logo, um estimador para \\(\\theta\\) contra a perda quadrática é \\({\\delta}^*(X)=E[\\theta|X]\\). \\(~\\) \\(~\\) Estimador de Bayes para \\(\\theta\\) contra diferentes funções de perda: Perda Quadrática: \\(L_2(d,\\theta)=(d-\\theta)^2\\) \\(~\\Longrightarrow~\\) \\({\\delta}_2^*(X)=E[\\theta|X]\\); Perda Absoluta: \\(L_1(d,\\theta)=|d-\\theta|\\) \\(\\Longrightarrow\\) \\({\\delta}_1^*(X)=Med(\\theta|X)\\); Perda 0-1: \\(L_0(d,\\theta)=c~\\mathbb{I}(d\\neq\\theta)\\) \\(\\Longrightarrow\\) \\({\\delta}_0^*(X)=Moda(\\theta|X)\\). \\(~\\) \\(~\\) Exemplo 1. Voltando à Perda Quadrática: \\(L(d,\\theta)=a(d-\\theta)^2\\), \\(a&gt;0\\). Já vimos que \\(\\delta^*(\\boldsymbol X)=E[\\theta|\\boldsymbol X]\\). É importante notar que esse estimador só faz sentido se \\(E[\\theta|\\boldsymbol X]\\in \\mathcal{D}\\). Nos casos em que isso não ocorre, tomamos um valor \\({d}_x^* \\in \\mathcal{D}\\) próximo a \\(E[\\theta|\\boldsymbol X]\\) tal que \\(r_x\\left({d}_x^*\\right)\\) é mínimo. \\(~\\) O risco a posteriori para esse estimador é \\(r_x\\left(\\delta^*(\\boldsymbol x)\\right)\\) \\(=r_x\\left(E[\\theta|\\boldsymbol x]\\right)\\) \\(=\\displaystyle \\int_\\Theta L\\left(\\delta^*(\\boldsymbol x),\\theta\\right)dP(\\theta|\\boldsymbol x)\\) \\(=\\displaystyle \\int_\\Theta \\left(\\theta-E[\\theta|\\boldsymbol x]\\right)^2 dP(\\theta|\\boldsymbol x)\\) \\(=Var(\\theta|\\boldsymbol x)\\), de modo que o risco de Bayes é dado por \\({\\rho}^*\\left(P\\right)\\) \\(=\\rho\\left(\\delta^*(\\boldsymbol X),P\\right)\\) \\(=\\displaystyle \\int_{\\mathfrak{X}} \\underbrace{ \\int_{\\Theta}(\\theta-E[\\theta|\\boldsymbol{x}])^2dP(\\theta|\\boldsymbol{x})}_{Var[\\theta|\\boldsymbol{x}]}dP(\\boldsymbol{x})\\) \\(=E\\left[Var(\\theta|\\boldsymbol X)\\right]\\). A variância da posteriori \\(Var(\\theta|\\boldsymbol x)\\) pode ser vista como uma medida de informação, no sentido que quanto menor essa variância, mais concentrada é a distribuição e há “menos incerteza” sobre \\(\\theta\\). Nesse sentido, espera-se que ao observar \\(\\boldsymbol X=\\boldsymbol x\\), a variância \\(Var(\\theta|\\boldsymbol x)\\) diminua em relação a variância da priori \\(Var(\\theta)\\). \\[\\underbrace{Var(\\theta)}_{constante}=\\underbrace{E\\left[Var(\\theta|\\boldsymbol X)\\right]}_{\\boldsymbol \\Downarrow}+\\underbrace{Var\\left[E(\\theta|\\boldsymbol X)\\right]}_{\\boldsymbol \\Uparrow}\\] Aparentemente, quando espera-se que a variância da posteriori diminua, a variância do estimador deveria aumentar. Muitas vezes isso é colocado como se o objetivo fosse encontrar o estimador de maior variância, em contradição com a abordagem frequentista. Contudo, há outra interpretação desse resultado: deseja-se obter um estimador que varie bastante de acordo com o valor observado de \\(\\boldsymbol X\\), isto é, a informação trazida pela amostra muda sua opinião sobre \\(\\theta\\). \\(~\\) Exemplo 2. Considere \\(X_1,...X_n\\) c.i.i.d. tais que \\(X_i|\\theta\\sim Poisson(\\theta)\\) e, a priori, \\(\\theta \\sim Gama(a,b)\\). A função de verossimilhança é \\(f(\\boldsymbol x | \\theta)\\propto \\prod {\\theta}^{x_i}~{e}^{-\\theta}\\) e a priori é \\(~f(\\theta)\\propto{\\theta}^{a-1}~{e}^{-b\\theta}\\). Assim, \\(f(\\theta | \\boldsymbol x)\\) \\(\\propto {\\theta}^{\\sum x_i}~{e}^{-n\\theta} ~\\cdot~ {\\theta}^{a-1}~{e}^{-b\\theta}\\) \\(\\propto {\\theta}^{a+\\sum x_i-1}~{e}^{-(b+n)\\theta}\\), de modo que \\(\\theta|\\boldsymbol X=\\boldsymbol x\\sim Gama\\left(a+\\sum x_i,b+n\\right)\\). Como visto anteriormente, o estimador de Bayes contra a perda quadrática é \\(\\delta^*(\\boldsymbol X)=E[\\theta|\\boldsymbol X]=\\dfrac{a+\\sum_iX_i}{b+n}\\). Para calcular o risco de Bayes, note que \\(E[X_i|\\theta]=\\theta\\), de modo que \\(E[X_i]=E\\left[E(X_i|\\theta)\\right]=E[\\theta]=a/b\\). Além disso, \\(Var(\\theta)=\\dfrac{a}{b^2}\\) e \\(Var(\\theta|\\boldsymbol X)=\\dfrac{a+\\sum_iX_i}{(b+n)^2}\\). Então, \\(\\rho^*(P)\\) \\(=E\\left[Var(\\theta|\\boldsymbol X)\\right]\\) \\(=E\\left[\\dfrac{a+\\sum_iX_i}{(b+n)^2}\\right]\\) \\(= \\dfrac{\\left(a+\\sum E[X_i]\\right)}{(b+n)^2}\\) \\(=\\dfrac{\\dfrac{a}{b}\\left(b+n\\right)}{(b+n)^2}\\) \\(=\\dfrac{a}{b(b+n)}\\). Por fim, note que a decisão de Bayes pode ser escrita como uma combinação linear convexa da média da distribuição a priori e do estimador de máxima verossimilhança \\(E[\\theta|\\boldsymbol X]\\) \\(=\\dfrac{a+\\sum_iX_i}{b+n}\\) \\(=\\dfrac{b}{b+n}\\left(\\dfrac{a}{b}\\right)+\\dfrac{n}{b+n}\\bar{X}\\). \\(~\\) Resultado: Seja \\(L(d,\\theta)=\\mathbb{I}(|\\theta-d|&gt; \\varepsilon)\\) \\(=1-\\mathbb{I}(d-\\varepsilon\\leq \\theta \\leq d+\\varepsilon)\\) , \\(\\varepsilon &gt; 0\\). Então, \\(\\delta^*(\\boldsymbol X)\\) é centro do intervalo modal, isto é, o intervalo de tamanho \\(2\\varepsilon\\) de maior densidade a posteriori. Em particular, quando \\(\\varepsilon \\downarrow 0\\), temos que \\({\\delta}^*(\\boldsymbol X)=Moda(\\theta|\\boldsymbol X)\\). Demo: O risco posterior de uma decisão \\(d\\) é \\(r_{\\boldsymbol{x}}(d)\\) \\(=E\\left[L(d,\\theta)|\\boldsymbol{x}\\right]\\) \\(=E\\left[\\mathbb{I}(|\\theta-d|&gt; \\varepsilon)\\right]\\) \\(=E\\left[1-\\mathbb{I}(d-\\varepsilon\\leq \\theta \\leq d+\\varepsilon)|\\boldsymbol x\\right]\\) \\(=1-P(d-\\varepsilon\\leq \\theta \\leq d+\\varepsilon|\\boldsymbol x)\\). O risco \\(r_{\\boldsymbol{x}}(d)\\) é mínimo quando a probabilidade \\(P(d-\\varepsilon\\leq \\theta \\leq d+\\varepsilon|\\boldsymbol x)\\) é máxima. Assim, basta tomar o intervalo \\(\\left[{d}_x^*-\\varepsilon ~;~ {d}_x^*+\\varepsilon\\right]\\) com maior probabilidade a posteriori e o estimador de Bayes nesse caso será o valor central desse intervalo, \\({d}_x^*\\). \\(~\\) Exemplo 3. Considere o exemplo anterior onde \\(\\theta|\\boldsymbol x\\sim Gama(a+\\sum x_i,b+n)\\) e a função de perda do resultado anterior, \\(L(d,\\theta)=\\mathbb{I}(|\\theta-d|&gt; \\varepsilon)\\). Temos que \\(f(\\theta|\\boldsymbol x)\\) \\(\\propto \\theta^{\\overbrace{a+\\sum x_i-1}^{A_x}}e^{-\\overbrace{(b+n)}^{B_x}\\theta}\\) \\(=\\theta^{A_x}e^{-{B_x}\\theta}\\) theta = seq(0,1.2,0.01) #Parâmetros da dist a posteriori gama a1 = 3 b1 = 10 posterior = dgamma(theta, a1, b1 ) # Escolhendo valores de epsilon e calculando a perda mínima associada e=c(0.5,0.4,0.3,0.25,0.2,0.15,0.1,0.05,0) loss &lt;- NULL for(i in 1:length(e)){ loss[i] &lt;- theta[which.min(as.vector(apply(matrix(theta), 1, function(d) sum(posterior*(abs(theta-d)&gt;e[i])))))]} # Criando o gráfico n &lt;- length(e) tibble(x=rep(loss,each=length(theta)), e=rep(round(e,2),each=length(theta)), theta=rep(theta,(n)), post = rep(posterior,n)) %&gt;% ggplot() + geom_segment(aes(x=x, xend=x, y=0,yend=dgamma(x, a1, b1 ),colour=as.factor(e))) + geom_point(aes(x=x, y=0,colour=as.factor(e))) + geom_segment(aes(x=x-e, xend=x+e, y=0,yend=0,colour=as.factor(e))) + geom_line(aes(x=theta,y=post, colour=&quot;Dist. a posteriori&quot;)) + geom_segment(aes(x=(a1-1)/b1, xend=(a1-1)/b1, y=0,yend=dgamma((a1-1)/b1, a1, b1 ), colour = &quot;Moda a posteriori&quot;),lty=2) + xlab(expression(theta)) + ylab(expression(paste(&quot;f(&quot;,theta,&quot;|x)&quot;))) + theme_bw() + labs(colour = &quot;epsilon&quot;) + gganimate::transition_states(rev(e)) Como comentado no resultado anterior, quando \\(\\varepsilon \\downarrow 0\\), temos que \\({\\delta}^*(\\boldsymbol x)=Moda(\\theta|\\boldsymbol x)\\) \\(= \\displaystyle\\sup_{\\theta} f(\\theta|\\boldsymbol x)\\). \\(\\dfrac{\\partial f(\\theta|\\boldsymbol x)}{\\partial \\theta}\\) \\(=(A_x-B_x\\theta)\\theta^{A_x-1}e^{-B_x\\theta}=0\\) \\(\\Leftrightarrow \\theta =\\dfrac{A_x}{B_x}\\) \\({\\delta}^*(\\boldsymbol X) = Moda(\\theta|\\boldsymbol X)\\) \\(=\\dfrac{a+\\sum X_i-1}{b+n}\\) \\(=\\dfrac{b}{b+n}\\left(\\dfrac{a-1}{b}\\right)+\\dfrac{n}{b+n}~\\bar{X}\\). \\(~\\) Resultado. Seja \\(L(d,\\theta)=c_1(d-\\theta)~\\mathbb{I}(d\\geq \\theta)+c_2(\\theta-d)~\\mathbb{I}(d&lt;\\theta)\\) com \\(c_1&gt;0\\), \\(c_2 &gt;0\\). Então, \\({\\delta}^*(\\boldsymbol{x})\\) é tal que \\(P\\left(\\theta\\leq {\\delta}^*(\\boldsymbol{x})\\big|\\boldsymbol x\\right)=\\dfrac{c_1}{c_1+c_2}\\). Em particular, se \\(c_1=c_2=c\\), temos a perda absoluta \\(L(d,\\theta)=c~|d-\\theta|\\) e \\({\\delta}^*(\\boldsymbol{X})=Med(\\theta|\\boldsymbol X)\\). Demo: exercício. \\(~\\) \\(~\\) 4.2 Estimação por Regiões Em um problema de estimação por regiões (ou estimação intervalar, no caso univariado), o objetivo é obter um conjunto de valores razoáveis para \\(\\theta\\). Mais formalmente, temos um problema aonde a decisão consiste em escolher um subconjunto do espaço paramétrico, de modo que \\(\\mathcal{D}=\\mathcal{A}\\), onde \\(\\mathcal{A}\\) é \\(\\sigma\\)-algebra de subconjuntos de \\(\\Theta\\). Uma estimativa por região é comumente chamada na literatura Bayesiana de região de credibilidade (intervalo de credibilidade, no caso univariado) ou região de probabilidade \\(~\\gamma=1-\\alpha\\). \\(~\\) Exemplo 1. Suponha que a distribuição a posteriori é \\(f(\\theta|\\boldsymbol{x})=4\\theta~\\mathbb{I}_{[0,1/2)}(\\theta)+4(1-\\theta)~\\mathbb{I}_{[1/2,1]}(\\theta)\\). Uma possível estimativa intervalar é um intervalo central ou um intervalo simétrico em torno da média (ou da moda) com uma probabilidade \\(\\gamma = 1-\\alpha\\). Nesse caso, vamos considerar um intervalo central no sentido que deixa de fora conjuntos caudais de probabilidade \\(\\alpha/2\\). Note que é possível obter o intervalo de forma analítica nesse exemplo. A seguir, são apresentadas as funções de distribuição \\(F\\) e quantílica \\(Q\\) a posteriori e o intervalo de credibilidade \\(\\alpha\\). \\(F(\\theta|\\boldsymbol x)\\) \\(=\\displaystyle \\int_0^\\theta f(t|x)dt\\) \\(=\\displaystyle \\int_0^\\theta\\left[4t~\\mathbb I_{[0,1/2]}(t)+(4-4t)~\\mathbb I_{(1/2,1]}(t)\\right]dt\\) \\(=\\left\\{\\begin{array}{lcc} 2\\theta^2 &amp;,&amp; \\theta\\leq 1/2\\\\ -2\\theta^2+4\\theta-1 &amp;,&amp; \\theta&gt;1/2\\end{array}\\right.\\) \\(Q(p)=\\left\\{\\begin{array}{lcc} \\sqrt{\\dfrac{p}{2}} &amp;,&amp; p\\leq 1/2\\\\ 1-\\sqrt{\\dfrac{1-p}{2}} &amp;,&amp; p&gt;1/2\\end{array}\\right.\\) \\(I.C.(1-\\alpha)=\\left[\\sqrt{\\dfrac{\\alpha/2}{2}};1-\\sqrt{\\dfrac{\\alpha/2}{2}}\\right]\\). alpha=0.1 theta = seq(0,1,0.01) # Densidade a posteriori dpost = Vectorize(function(t){ 4*t*I(t&gt;=0)*I(t&lt;=0.5)+ 4*(1-t)*I(t&gt;0.5)*I(t&lt;=1) }) # F. Distribuição a posteriori ppost = Vectorize(function(t){ 2*(t^2)*I(t&gt;=0)*I(t&lt;=0.5)+ 4*(1-t)*I(t&gt;0.5)*I(t&lt;=1)+I(t&gt;1) }) # F. Quantílica a posteriori qpost = Vectorize(function(t){ ifelse(t&lt;=0.5, sqrt(t/2)*I(t&gt;0), (1-sqrt((1-t)/2))*I(t&lt;1)+I(t&gt;=1)) }) post = dpost(theta) l = c(qpost((alpha/2)),qpost((1-alpha/2))) X = tibble(theta=theta,Posterior=post) ggplot(data=X,mapping = aes(x=theta,y=Posterior)) + geom_line(lwd=1.5) + geom_area(data=subset(X, theta &gt;= l[1] &amp; theta &lt;= l[2]),fill = &quot;blue&quot;, alpha=0.5)+ theme_bw() \\(~\\) Exemplo 2. Por fim, suponha que a distribuição a posteriori é \\(f(\\theta|\\boldsymbol{x})=(2-4\\theta)~\\mathbb{I}_{[0,1/2)}(\\theta)+(4\\theta-2)~\\mathbb{I}_{[1/2,1]}(\\theta)\\). Vamos construir um intervalo como no Exemplo anterior. \\(F(\\theta|\\boldsymbol x)\\) \\(=\\left\\{\\begin{array}{lcc} 2\\theta(1-\\theta) &amp;,&amp; \\theta\\leq 1/2\\\\ 2\\theta(\\theta-1)+1 &amp;,&amp; \\theta&gt;1/2\\end{array}\\right.\\) \\(Q(p)=\\left\\{\\begin{array}{lcc} \\dfrac{1}{2}-\\dfrac{\\sqrt{1-2p}}{2} &amp;,&amp; p\\leq 1/2\\\\ \\dfrac{1}{2}+\\dfrac{\\sqrt{2p-1}}{2} &amp;,&amp; p&gt;1/2\\end{array}\\right.\\) \\(I.C.(1-\\alpha)=\\left[\\dfrac{1}{2}-\\dfrac{\\sqrt{1-\\alpha}}{2};\\dfrac{1}{2}+\\dfrac{\\sqrt{1-\\alpha}}{2}\\right]\\). alpha=0.1 theta = seq(0,1,0.01) # Densidade a posteriori dpost = Vectorize(function(t){ (2-4*t)*I(t&gt;=0)*I(t&lt;=0.5)+ (4*t-2)*I(t&gt;0.5)*I(t&lt;=1) }) # F. Distribuição a posteriori ppost = Vectorize(function(t){ 2*t*(1-t)*I(t&gt;=0)*I(t&lt;=0.5)+ (2*(t^2)-2*t+1)*I(t&gt;0.5)*I(t&lt;=1)+I(t&gt;1) }) # F. Quantílica a posteriori qpost = Vectorize(function(t){ ifelse(t&lt;=0.5, (0.5-sqrt(1-2*t)/2)*I(t&gt;0), (0.5+sqrt(2*t-1)/2)*I(t&lt;1)+I(t&gt;=1)) }) post = dpost(theta) l = c(qpost((alpha/2)),qpost((1-alpha/2))) X = tibble(theta=theta,Posterior=post) ggplot(data=X,mapping = aes(x=theta,y=Posterior)) + geom_line(lwd=1.5) + geom_area(data=subset(X, theta &gt;= l[1] &amp; theta &lt;= l[2]),fill = &quot;blue&quot;, alpha=0.5)+ theme_bw() Note que, nesse exemplo, as regiões que tem mais densidade a posteriori foram excluídas do intervalo. Isso não faz muito sentido pois essas regiões têm maior chance de conter o \\(\\theta\\) que quaquer outra região de mesmo tamanho. \\(~\\) \\(~\\) Uma função de perda razoável para um problema de estimação por região deve levar em consideração dois fatores: O tamanho da região \\(d \\in \\mathcal{A}\\) (deseja-se uma região que seja menor que o espaço paramétrico); Pertinência de \\(\\theta\\) na região \\(d\\). Assim, considere uma função de perda da forma \\(L(d,\\theta)=\\lambda(d)-k~\\mathbb I_d(\\theta)\\), onde \\(\\lambda(d)\\) é o “tamanho” da região \\(d\\). Por exemplo, a medida de Lebesgue, no caso contínuo, ou a medida de contagem, no caso discreto (no caso geral, considere uma medida que domina a distribuição a posteriori, \\(P(\\theta|\\boldsymbol x) \\ll \\lambda\\)). No caso absolutamente contínuo, o risco a posteriori de uma decisão \\(d \\in \\mathcal{A}\\) é \\({r}_{x}(d)\\) \\(=\\displaystyle\\int_\\Theta \\left[\\lambda(d)-k~\\mathbb I_d(\\theta)\\right]dP(\\theta|\\boldsymbol x)\\) \\(=\\displaystyle \\int_\\Theta\\mathbb I_d(\\theta)d\\theta-\\int_\\Theta k~\\mathbb I_d(\\theta)f(\\theta|\\boldsymbol x)d\\theta\\) \\(=\\displaystyle \\int_d\\left(1-kf(\\theta|\\boldsymbol x)\\right)d\\theta\\). Esse risco é mínimo quando \\(d=\\left\\{\\theta\\in\\Theta:1-kf(\\theta|\\boldsymbol x)\\leq 0\\right\\}\\) \\(\\Leftrightarrow d=\\{\\theta\\in\\Theta:f(\\theta|\\boldsymbol x)\\geq 1/k\\}\\). Assim, a decisão de Bayes contra essa função de perda consiste em escolher uma região \\(d \\in \\mathcal{A}\\) que contêm os pontos do espaço paramétrico com maior densidade a posteriori. \\(~\\) Definição: A região \\(R\\subseteq \\Theta\\) é dita ser uma região HPD (Highest Posterior Density) de probabilidade \\(\\gamma\\) se \\(P(\\theta\\in R|\\boldsymbol x)=\\gamma\\); \\(\\forall \\theta \\in R\\) e \\(\\forall \\theta^\\prime\\notin R\\), \\(f(\\theta|\\boldsymbol x)\\geq f(\\theta^\\prime|\\boldsymbol x)\\). \\(~\\) Voltando ao Exemplo 2. As regiões centrais nesse exemplo tem menor densidade a posteriori. Assim, uma região HPD de probabilidade \\(\\gamma=1-\\alpha\\) é dada por \\(I.C.(1-\\alpha)=\\left[0~;~\\dfrac{1}{2}-\\dfrac{\\sqrt{\\alpha}}{2}\\right]\\bigcup \\left[\\dfrac{1}{2}+\\dfrac{\\sqrt{\\alpha}}{2}~;~1\\right]\\) alpha=0.1 theta = seq(0,1,0.01) # Densidade a posteriori dpost = Vectorize(function(t){ (2-4*t)*I(t&gt;=0)*I(t&lt;=0.5)+ (4*t-2)*I(t&gt;0.5)*I(t&lt;=1) }) # F. Distribuição a posteriori ppost = Vectorize(function(t){ 2*t*(1-t)*I(t&gt;=0)*I(t&lt;=0.5)+ (2*(t^2)-2*t+1)*I(t&gt;0.5)*I(t&lt;=1)+I(t&gt;1) }) # F. Quantílica a posteriori qpost = Vectorize(function(t){ ifelse(t&lt;=0.5, (0.5-sqrt(1-2*t)/2)*I(t&gt;0), (0.5+sqrt(2*t-1)/2)*I(t&lt;1)+I(t&gt;=1)) }) post = dpost(theta) l = c(qpost((1-alpha)/2),qpost((alpha+1)/2)) X = tibble(theta=theta,Posterior=post) ggplot(data=X,mapping = aes(x=theta,y=Posterior)) + geom_line(lwd=1.5) + geom_hline(yintercept=dpost(l[1]), lty=2, col=&quot;darkgray&quot;) + geom_area(data=subset(X, theta &lt;= l[1]),fill = &quot;blue&quot;, alpha=0.5) + geom_area(data=subset(X, theta &gt;= l[2]),fill = &quot;blue&quot;, alpha=0.5)+ theme_bw() Note que na solução anterior, o comprimento do intervalo era \\(\\sqrt{1-\\alpha}\\), enquanto que o comprimento do HPD é \\(1-\\sqrt{\\alpha}\\). Tomando, por exemplo, \\(\\alpha=0.1\\) temos que \\(\\sqrt{1-\\alpha} \\approx 0.95\\) enquanto \\(1-\\sqrt{\\alpha}\\approx 0.68\\). Por conter apenas os pontos com maior densidade, o HPD sempre terá comprimento menor ou igual a qualquer intervalo com mesma probabilidade. \\(~\\) Exemplo 3. Considere \\(X_1,...,X_n\\) c.i.i.d. tais que \\(X_i|\\theta\\sim N(\\theta,1/\\tau)\\) , \\(\\tau=1/\\sigma^2\\) , com \\(\\tau\\) conhecido (fixado). Vimos que se, a priori, \\(\\theta\\sim N(m,1/v)\\) então \\(\\theta|\\boldsymbol x\\sim N\\left(\\underbrace{\\dfrac{vm+n\\tau\\bar x}{v+n\\tau}}_{M_x},\\underbrace{\\dfrac{1}{v+n\\tau}}_{V_x}\\right)\\) e, assim, \\(Z=\\dfrac{\\theta-M_x}{\\sqrt V_x}~\\Bigg|~\\boldsymbol x\\sim N(0,1)\\). O intervalo HPD de probabilidade \\(\\gamma=1-\\alpha=0.95\\) é \\(I.C.(1-\\alpha)=\\) \\(\\left[M-z_{\\alpha/2}\\sqrt V;M+z_{\\alpha/2}\\sqrt V\\right]\\) \\(=\\left[\\dfrac{vm+n\\tau\\bar x}{v+n\\tau}\\pm1.96\\sqrt{\\dfrac{1}{v+n\\tau}}\\right]\\). Uma possível forma de representar falta de informação a priori é tomar o limite \\(~v\\downarrow 0~~\\) (\\(1/v\\uparrow \\infty\\)). Dessa forma, tem-se \\(\\theta|\\boldsymbol x\\sim N(\\bar x,1/(n\\tau))\\sim N(\\bar x,\\sigma^2/n)\\), e o intervalo HPD coincide com o I.C. frequentista \\(I.C.(1-\\alpha)=\\left[\\bar x\\pm 1.96\\dfrac{\\sigma}{\\sqrt{n}}\\right]\\). mx=2; vx=sqrt(3) alpha=0.05 theta = seq(qnorm(0.001,mx,vx),qnorm(0.999,mx,vx),length.out=100) post = dnorm(theta,mx,vx) l = c(qnorm(alpha/2,mx,vx),qnorm(1-alpha/2,mx,vx)) X = tibble(theta=theta,Posterior=post) ggplot(data=X,mapping = aes(x=theta,y=Posterior)) + geom_line(lwd=1.5) + geom_hline(yintercept=dnorm(l[1],mx,vx), lty=2, col=&quot;darkgray&quot;) + geom_area(data=subset(X, theta &gt;= l[1] &amp; theta &lt;= l[2]),fill = &quot;blue&quot;, alpha=0.5)+ theme_bw() \\(~\\) Exemplo 4: Considere \\(X_1,...,X_n\\) c.i.i.d. tais que \\(X_i|\\theta\\sim Unif(0,\\theta)\\). Vimos que se \\(\\theta\\sim Pareto(a,b)\\), então \\(\\theta|\\boldsymbol x\\sim Pareto (a+n,\\max\\{x_{(n)},b\\})\\) \\(f(\\theta|\\boldsymbol x) =\\dfrac{(a+n)[\\max\\{x_{(n)},b\\}]^{a+n}}{\\theta^{a+n+1}}~\\mathbb I_{[\\max\\{x_{(n)},b\\},\\infty)}\\) Note que a função de densidade a posteriori é estritamente decrescente de modo que o extremo inferior da região HPD é \\(\\max\\{x_{(n)},b\\}\\). A função de distribuição a posteriori é \\(F(\\theta|\\boldsymbol x)=1-\\left(\\dfrac{\\max\\{x_{(n)},b\\}}{\\theta}\\right)^{a+n}\\), de modo que o extremo superior do intervalo pode ser obtido fazendo \\(1-\\left(\\dfrac{\\max\\{x_{(n)},b\\}}{\\theta}\\right)^{a+n}=\\gamma\\) \\(\\Leftrightarrow\\dfrac{\\max\\{x_{(n)},b\\}}{\\theta^*}=(1-\\gamma)^{1/(a+n)}\\) \\(\\Leftrightarrow \\theta^*=\\dfrac{\\max\\{x_{(n)},b\\}}{(1-\\gamma)^{1/(a+n)}}\\). \\(I.C.(1-\\alpha)=\\left[\\max\\{x_{(n)},b\\},\\dfrac{\\max\\{x_{(n)},b\\}}{\\alpha^{1/(a+n)}}\\right]\\) ax=2; bx=1 maxt=bx/((alpha/3)^(1/ax)) alpha=0.1 limsup=bx/(alpha^(1/ax)) theta = seq(bx,maxt,0.1) dpareto=Vectorize(function(t){ ax*(bx^ax)*I(t&gt;=bx) / (t^(ax+1)) }) post = dpareto(theta) X = tibble(theta=theta,Posterior=post) ggplot(data=X,mapping = aes(x=theta,y=Posterior)) + geom_line(lwd=1.5) + xlim(c(0,maxt))+ geom_hline(yintercept=dpareto(limsup), lty=2, col=&quot;darkgray&quot;) + geom_area(data=subset(X, theta &lt;= limsup),fill = &quot;blue&quot;, alpha=0.5)+ theme_bw() \\(~\\) \\(~\\) 4.3 Custo das Observações Suponha agora que o custo para observar uma amostra de tamanho \\(n\\) é dado por uma função custo \\(c(n)\\) e, antes de observar \\(X_1,\\ldots,X_n\\), você precisa decidir qual o tamanho amostral ótimo, \\(n^*\\). Desta forma, considere a função de perda \\(L(d,\\theta,n) = L(d,\\theta) + c(n)\\) com risco \\(\\rho_n(\\delta,P)\\) \\(= E\\left[L(d,\\theta,n)\\right]\\) \\(= E\\left[L(d,\\theta) + c(n)\\right]\\) \\(= \\rho_n(\\delta,P) + c(n)\\). Note que (supostamente, por simplicidade) o custo \\(c(n)\\) não depende de \\(\\theta\\). Se \\(\\delta^*\\) é função de decisão de Bayes contra \\(L(d,\\theta)\\) e a priori \\(P\\), o tamanho amostral ótimo \\(n^*\\) é o valor que minimiza \\(\\rho_n(P)\\) \\(= \\rho(\\delta,P) + c(n)\\) \\(= \\rho^*(P) + c(n)\\). \\(~\\) Exemplo. Considere o exemplo visto anteriorimente em que \\(\\mathcal{D}=\\{d_1,d_2\\}\\), \\(\\Theta=\\{\\theta_1,\\theta_2\\}=\\{3/4,1/3\\}\\), \\(P(\\theta_1)=1/2\\) e a função de perda é \\(L(d,\\theta)=10~\\mathbb{I}(d_1,\\theta_2) + 5~\\mathbb{I}(d_2,\\theta_1)\\). Se \\(X|\\theta \\sim Ber(\\theta)\\), a função de decisão de Bayes é \\(\\delta^*(x)=d_1~\\mathbb{I}(x=1)+d_2~\\mathbb{I}(x=0)\\). \\(~\\) Suponha agora que é possível observar \\(X_1,\\ldots,X_n\\) v.a. c.i.i.d. tais que \\(X_i|\\theta \\sim Ber(\\theta)\\). Note que \\(T(\\boldsymbol X)=\\sum X_i\\) é suficiente para \\(\\theta\\) com \\(T(\\boldsymbol X)|\\theta \\sim Bin(n,\\theta)\\) e \\(f(\\theta_1|T(\\boldsymbol X)=t)\\) \\(=\\dfrac{f(t|\\theta_1)P(\\theta_1)}{\\displaystyle \\sum_{i\\in\\{1,2\\}} f(t|\\theta_i)P(\\theta_i)}\\) \\(=\\dfrac{f(t|\\theta_1)}{\\displaystyle \\sum_{i\\in\\{1,2\\}} f(t|\\theta_i)}\\) \\(=\\dfrac{\\binom{n}{t}\\left(\\frac{3}{4}\\right)^t\\left(\\frac{1}{4}\\right)^{n-t}}{\\binom{n}{t}\\left(\\frac{3}{4}\\right)^t\\left(\\frac{1}{4}\\right)^{n-t}+\\binom{n}{t}\\left(\\frac{1}{3}\\right)^t\\left(\\frac{2}{3}\\right)^{n-t}}\\) \\(=\\dfrac{1}{1+\\left(\\frac{1}{6}\\right)^t\\left(\\frac{8}{3}\\right)^{n}}\\) \\(=p_x\\). \\(~\\) O risco posterior das decisões \\(d_1\\) e \\(d_2\\) são, respectivamente, \\(r_x(d_1)=10(1-p_x)\\) e \\(r_x(d_2)=5p_x\\), de modo que decide-se por \\(d_1\\) se \\(r_x(d_1)\\leq r_x(d_2)\\) \\(~\\Longleftrightarrow~ 10(1-p_x) \\leq 5p_x\\) \\(~\\Longleftrightarrow~ p_x \\geq \\frac{10}{15}= \\frac{2}{3}\\) \\(~\\Longleftrightarrow~ \\dfrac{1}{1+\\left(\\frac{1}{6}\\right)^t\\left(\\frac{8}{3}\\right)^{n}} \\geq \\frac{2}{3}\\) \\(~\\Longleftrightarrow~ \\left(\\frac{1}{6}\\right)^t\\left(\\frac{8}{3}\\right)^{n} \\leq \\frac{1}{2}\\) \\(~\\Longleftrightarrow~ \\left(\\frac{1}{6}\\right)^t\\left(\\frac{8}{3}\\right)^{n} \\leq \\frac{1}{2}\\) \\(~\\Longleftrightarrow~ -t\\log(6) \\leq n\\log\\left(\\frac{3}{8}\\right)-\\log\\left(2\\right)\\) \\(~\\Longleftrightarrow~ t\\geq -n\\log_6\\left(\\frac{3}{8}\\right)+\\log_6\\left(2\\right) = k_n\\), e a função de decisão de Bayes é \\({\\delta}^*(\\boldsymbol X) = \\left\\{ \\begin{array}{ccl} d_1 &amp;,&amp; \\sum X_i ~\\geq~ k_n ~~\\approx~~ 0.55 n + 0.39 \\\\ d_2 &amp;,&amp; \\text{caso contrário} \\end{array}\\right.\\) \\(~\\) O risco de Bayes neste caso é \\({\\rho}^*(P)\\) \\(= E\\left[L\\left(\\delta^*(x),\\theta\\right)\\right]\\) \\(=10~P\\left(\\delta^*(x)=d_1,\\theta=\\theta_2\\right)+5~P\\left(\\delta^*(x)=d_2,\\theta=\\theta_1\\right)\\) \\(=10\\dfrac{1}{2}~P\\left(\\sum X_i ~\\geq~ k_n ~\\Big|~ \\theta=\\dfrac{1}{3}\\right)+5~\\dfrac{1}{2}~P\\left(\\sum X_i ~&lt;~ k_n ~\\Big|~ \\theta=\\dfrac{3}{4}\\right)\\) \\(=5~P\\left(Bin\\left(n,\\frac{1}{3}\\right) ~\\geq~ k_n \\right)+2.5~P\\left(Bin\\left(n,\\frac{3}{4}\\right) ~&lt;~ k_n \\right)\\). \\(~\\) Suponha agora que há um custo \\(c(n)\\) por essas \\(n\\) observações e que a função de perda é dada por \\(L(d,\\theta,n) = L(d,\\theta) + c(n)\\). Essa função custo \\(c: \\mathbb{N} \\rightarrow \\mathbb{R}\\) pode depender de questões além das financeiras, como, por exemplo, o tempo de coleta da amostra ou algum risco aos envolvidos no experimento. Considere, por simplicidade, uma função de custo linear \\(c(n) = 0.02n\\), de modo que o risco é \\({\\rho}_n(P)\\) \\(= {\\rho}^*(P) + c(n)\\) \\(=5~P\\left(Bin\\left(n,\\frac{1}{3}\\right) ~\\geq~ k_n \\right)+2.5~P\\left(Bin\\left(n,\\frac{3}{4}\\right) ~&lt;~ k_n \\right) + 0.02n\\). A seguir é apresentado um gráfico desse risco para alguns valores de \\(n\\) e é possível notar que o tamanho amostral ótimo é \\({n}^*=20\\). tibble(n=seq(0,80), kn=-n*log(3/8,6)+log(2,6), risco=5*(1-pbinom(kn,n,1/3))+2.5*pbinom(kn,n,3/4)+0.02*n) %&gt;% ggplot() + geom_point(aes(x=n,y=risco)) + geom_point(aes(x=n[which.min(risco)],y=min(risco)),col=&quot;red&quot;,cex=2.5) \\(~\\) No exemplo anterior, foi apresentado uma maneira de considerar custos das observações e obter um tamanho amostral ótimo para determinado problema de decisão. Quando o custo está relacionado somente a quantidades monetárias, funções de custo lineares não são as mais adequadas. Para uma discussão bastante didática sobre esse problema, veja o artigo O Paradoxo de São Petersburgo (Peixoto, C. M. e Wechsler, S.) no Boletim da ISBrA, 6(2). \\(~\\) "],
["Test.html", "5 Testes de Hipóteses 5.1 Conceitos Básicos 5.2 Revisão: Abordagem Frequentista 5.3 Abordagem Bayesiana (via Teoria da Decisão) 5.4 Probabilidade Posterior de \\(H_0\\) 5.5 Fator de Bayes 5.6 Teste de Jeffreys 5.7 Hipóteses Precisas 5.8 FBST - Full Bayesian Significance Test 5.9 P-value - Nivel de Significância Adaptativo", " 5 Testes de Hipóteses 5.1 Conceitos Básicos Uma hipótese estatística é uma afirmação sobre o parâmetro \\(\\theta\\) (ou a família \\(\\mathcal{P}\\)). No caso usual, tem-se duas hipóteses: \\(H_0: ~\\theta\\in\\Theta_0~\\), chamada de hipótese nula, e \\(H_1: ~\\theta\\in\\Theta_1={\\Theta}_0^c~\\), chamada hipótese alternativa. \\(~\\) Um teste de hipótese é uma regra de decisão \\(\\varphi: \\mathfrak{X} \\longrightarrow \\{0,1\\}\\), onde \\(\\varphi(\\boldsymbol{x})=1\\) significa rejeitar \\(H_0\\) (aceitar \\(H_1\\)) e \\(\\varphi(\\boldsymbol x)=0\\), não rejeitar (aceitar) \\(H_0\\). \\(~\\) Se rejeita-se \\(H_0\\) (aceita-se \\(H_1\\)) quando \\(H_0\\) é verdadeira, comete-se um erro do tipo I. Por outro lado, se não rejeita-se \\(H_0\\) (aceita \\(H_0\\)) quando \\(H_0\\) é falso, ocorre um erro do tipo II. \\(~\\) O conjunto \\(\\varphi^{-1}(1)=\\{\\boldsymbol{x} \\in \\mathfrak{X} :~ \\varphi(\\boldsymbol{x})=1\\}\\) recebe o nome de região de rejeição (ou região crítica). A função de poder do teste \\(\\varphi\\) é \\({\\pi}_\\varphi(\\theta)\\) \\(=P\\left(\\varphi^{-1}(1)|\\theta\\right)\\) $=P( | )$. \\(~\\) Dizemos que um teste \\(\\varphi\\) tem nível de significância \\(\\alpha\\) se \\(\\displaystyle\\sup_{\\theta\\in\\Theta_0}\\pi_\\varphi(\\theta)\\leq \\alpha\\). Se \\(\\alpha=\\displaystyle\\sup_{\\theta\\in\\Theta_0}\\pi_\\varphi(\\theta)\\) dizemos que o teste é de tamanho \\(\\alpha\\). \\(~\\) Uma hipótese é dita simples se contém apenas um ponto, \\(H:\\theta=\\theta_0\\). Caso contrário é chamada de hipótese composta. No caso em que \\(H:\\theta\\in\\Theta_0\\) é tal que \\(\\dim(\\Theta_0)&lt;\\dim(\\Theta)\\), diz-se que \\(H\\) é uma hipótese precisa (“sharp”). \\(~\\) 5.2 Revisão: Abordagem Frequentista Um teste de hipótese “ideal” seria aquele que as probabilidades de erros tipo I e tipo II são iguais a zero, isto é, \\(\\pi_\\varphi(\\theta)=0\\), \\(\\forall \\theta \\in \\Theta_0\\), e \\(\\pi_\\varphi(\\theta)=1\\), \\(\\forall \\theta \\in \\Theta_1\\). Contudo, não é possível obter tais testes em geral. A solução usual é fixar um nível de significância \\(\\alpha\\) e considerar apenas a classe de teste de nível \\(\\alpha\\), isto é, testes tais que \\(\\displaystyle\\sup_{\\theta\\in\\Theta_0}\\pi_\\varphi(\\theta) \\leq \\alpha\\). Os testes ótimos sob o ponto de vista frequentista são aqueles na classe de testes de nível alpha que tenha maior função poder \\({\\pi}_\\varphi(\\theta)\\) para \\(\\theta \\in \\Theta_1\\). Um teste que satisfaz isso é chamado de Teste Uniformememte Mais Poderoso (UMP) mas testes com essa propriedade também só podem ser obtidos em casos específicos. \\(~\\) Exemplo. Considere que \\(\\Theta=[0,1]\\) e deseja-se testar \\(H_0: \\theta \\leq 0.5\\) contra \\(H_1: \\theta &gt; 0.5\\). O gráfico a seguir ilustra as funções poder dos quatro testes disponíveis para esse problema. Supondo (apenas para fins didáticos) que \\(\\alpha=0.5\\), temos que o teste UMP de nível \\(\\alpha\\) é o teste 2. O teste 4, apesar de ser mais poderoso, não é um teste de nível \\(\\alpha\\). \\(~\\) Uma das situações onde é possível obter o teste mais poderoso é o caso que as hipóteses nula e alternativa são simples, isto é, \\(H_0:\\theta=\\theta_0\\) contra \\(H_1:\\theta=\\theta_1\\). Nesses casos, pode-se considerar o Lema de Neyman-Pearson, que afirma que o teste mais poderoso é dado por \\({\\varphi}^*(\\boldsymbol x)=\\left\\{\\begin{array}{rl} 1,&amp; \\dfrac{f(x|\\theta_0)}{f(x|\\theta_1)}\\leq k\\\\ 0,&amp; c.c.\\end{array}\\right.~.\\) Além disso, o teste \\({\\varphi}^*\\) minimiza a combinação linear das probabilidades de erro \\(a\\alpha+b\\beta\\) com \\(k=b/a\\), \\(\\alpha={\\pi}_{{\\varphi}^*}(\\theta_0)\\) \\(=P(\\textrm{&#39;erro tipo I&#39;})\\) e \\(\\beta=1-{\\pi}_{{\\varphi}^*}(\\theta_1)\\) \\(=P(\\textrm{&#39;erro tipo II&#39;})\\). \\(~\\) Como dito anteriorimente, usualmente é fixado um nível \\(\\alpha\\) e isso permite encontrar o valor de \\(k\\) de modo que o teste construído a partir do lema é o teste mais poderoso de nível \\(\\alpha\\). Assim, \\(\\alpha\\) \\(={\\pi}_{\\varphi^*}(\\theta_0)\\) \\(=P\\left(\\boldsymbol X \\in {\\varphi}^{-1}(\\{1\\})|\\theta_0\\right)\\) \\(=P\\left(\\left\\{\\boldsymbol x: \\dfrac{f(\\boldsymbol x|\\theta_0)}{f(\\boldsymbol x|\\theta_1)} \\leq k\\right\\}\\Big|\\theta_0\\right)\\). Suponha que foi observado \\(\\boldsymbol X = \\boldsymbol x_o\\), é possível calcular o nível descritivo (ou p-value) da seguinte forma: \\(p(\\boldsymbol x_o)\\) \\(=P\\left(\\left\\{\\boldsymbol x: \\dfrac{f(\\boldsymbol x|\\theta_0)}{f(\\boldsymbol x|\\theta_1)} \\leq \\dfrac{f(\\boldsymbol x_o|\\theta_0)}{f(\\boldsymbol x_o|\\theta_1)}\\right\\}\\Big|\\theta_0\\right)\\) \\(~\\) É possível obter testes UMP em alguns casos particulares. Em especial, nos casos em que a família de distribuições para \\(\\boldsymbol X\\) condicional a \\(\\theta\\) possui a propriedade de razão de verossimilhanças monótona, é possível construir testes UMP para hipóteses do tipo \\(H_1: \\theta \\leq \\theta_0\\) contra \\(H_1: \\theta &gt; \\theta_0\\). Para problemas onde as hipóteses são da forma \\(H_1: \\theta = \\theta_0\\) contra \\(H_1: \\theta \\neq \\theta_0\\), bastante comuns no dia a dia de um estatístico, não existe teste UMP, em geral. \\(~\\) Nos casos em que não existe um teste UMP, o teste mais utilizado sob a abordagem frequentista certamente é o teste da razão de verossimilhança generalizada (RVG). Primeiramente, considere a razão de verossimilhanças generalizada, dada por \\(\\lambda(\\boldsymbol x)=\\dfrac{\\displaystyle \\sup_{\\theta\\in\\Theta_0} f(\\boldsymbol x|\\theta)}{\\displaystyle \\sup_{\\theta\\in\\Theta} f(\\boldsymbol x|\\theta)}\\). Note que \\(0\\leq \\lambda(\\boldsymbol x) \\leq 1\\), \\(\\forall ~\\boldsymbol x \\in \\mathfrak{X}\\) e \\(\\forall ~\\Theta_0 \\subseteq \\Theta\\). Um teste RVG é qualquer teste da forma \\({\\varphi}_{RV}(\\boldsymbol x)=\\left\\{\\begin{array}{rl} 1,&amp; \\lambda(\\boldsymbol x) \\leq k\\\\ 0,&amp; c.c.\\end{array}\\right.~.\\) \\(~\\) Novamente, \\(k\\) pode ser escolhido de modo que o teste resultante seja de nível \\(\\alpha\\), isto é, \\(\\displaystyle \\sup_{\\theta \\in \\Theta_0} P\\left(\\lambda(\\boldsymbol x) \\leq k \\Big | \\theta\\right) \\leq \\alpha\\). Do mesmo modo, se foi observado \\(\\boldsymbol X=\\boldsymbol x_o\\), um p-value é \\(p(\\boldsymbol x_o)\\) \\(=\\displaystyle \\sup_{\\theta \\in \\Theta_0}P\\left(\\left\\{\\boldsymbol x: \\lambda(\\boldsymbol x) \\leq \\lambda(\\boldsymbol x_o)\\right\\}\\big|\\theta_0\\right)\\). Por fim, em casos onde é difícil fazer os cálculos de forma exata e o tamanho amostral \\(n\\) é razoavelmente grande, é possível usar a distribuição assintótica da RVG \\(~-2\\log \\lambda(\\boldsymbol x)\\overset{\\mathcal{D}}{~\\longrightarrow~}\\chi_d^2\\), onde \\(d=\\dim(\\Theta)-\\dim(\\Theta_0)\\). \\(~\\) \\(~\\) 5.3 Abordagem Bayesiana (via Teoria da Decisão) Sob a abordagem de teoria da decisão, podemos ver um teste de hipóteses como um problema de decisão onde temos duas possíveis decisões \\(\\mathcal{D}=\\{d_0,d_1\\}\\), onde \\(d_0\\) é decidir por \\(H_0:\\theta \\in \\Theta_0\\) e \\(d_1\\) é decidir por \\(H_1:\\theta \\in \\Theta_1\\), com \\(\\Theta=\\Theta_0\\cup\\Theta_1\\). Um teste de hipóteses nesse contexto é uma função de decisão \\(\\varphi: \\mathfrak{X} \\longrightarrow \\{0,1\\}\\), de modo que quando \\(\\varphi(\\boldsymbol x)=i\\), decide-se por \\(d_i\\), \\(i\\in \\{0,1\\}\\). \\(~\\) Primeiramente, considere o contexto apresentado no Lema de Neyman-Pearson, onde \\(\\Theta=\\{\\theta_0,\\theta_1\\}\\) e deseja-se testar \\(H_0: \\theta=\\theta_0\\) contra \\(H_1: \\theta = \\theta_1\\). Considere que, a priori, \\(f(\\theta_0) = \\pi\\), a função de verossimilhança é \\(f(\\boldsymbol x |\\theta)\\) e a função de perda apresentada na tabela a seguir. \\(L(d,\\theta)\\) \\(\\theta_0\\) \\(\\theta_1\\) \\(d_0\\) \\(0\\) \\(b\\) \\(d_1\\) \\(a\\) \\(0\\) Então, o risco de uma função de decisão \\(\\varphi\\) é \\(\\rho(\\varphi,P)\\) \\(=E\\left[L(\\varphi(\\boldsymbol X),\\theta)\\right]\\) \\(= \\pi~E\\left[L(\\varphi(\\boldsymbol X),\\theta)\\big|\\theta_0)\\right] + (1-\\pi)E\\left[L(\\varphi(\\boldsymbol X),\\theta)\\big|\\theta_1)\\right]\\) \\(= a~\\pi~P\\left(\\varphi(\\boldsymbol x)=1\\big|\\theta_0\\right) + b~(1-\\pi)~P\\left(\\varphi(\\boldsymbol x)=0\\big|\\theta_0\\right)\\) \\(= a~\\pi~\\alpha_\\varphi + b~(1-\\pi)~\\beta_\\varphi\\) Como o risco acima é uma combinação linear das probabilidades dos erro tipo I e tipo II, podemos aplicar o Lema de Neyman-Pearson e obter a função de decisão \\(\\varphi^*\\) que minimiza o risco \\({\\varphi}^*(\\boldsymbol x)=\\left\\{\\begin{array}{rl} 1,&amp; \\dfrac{f(x|\\theta_0)}{f(x|\\theta_1)}\\leq \\dfrac{b~(1-\\pi)}{a~\\pi}\\\\ 0,&amp; c.c.\\end{array}\\right.~.\\) Esse resultado é apresentado por DeGroot (1986) e é uma espécie de Lema de Neyman-Pearson Generalizado. \\(~\\) A solução para esse mesmo problema pode também ser obtida usando a forma extensiva. O risco posterior para as suas decisões é \\(r_x(d_0) = b f(\\theta_1|\\boldsymbol x)\\) e \\(r_x(d_1) = a f(\\theta_0|\\boldsymbol x)\\), de modo que rejeitamos \\(H_0\\) (decidimos por \\(d_1\\) ou \\(\\varphi(\\boldsymbol x)=1\\)) se \\(r_x(d_1) \\leq r_x(d_0)\\) \\(\\Longleftrightarrow a f(\\theta_0|\\boldsymbol x) \\leq b f(\\theta_1|\\boldsymbol x)\\) \\(\\Longleftrightarrow a f(\\theta_0|\\boldsymbol x) \\leq b \\left[1-f(\\theta_0|\\boldsymbol x)\\right]\\) \\(\\Longleftrightarrow f(\\theta_0|\\boldsymbol x) \\leq \\dfrac{b}{a+b}\\) De modo que o teste de Bayes também pode ser apresentado como \\({\\varphi}^*(\\boldsymbol x)=\\left\\{\\begin{array}{rl} 1,&amp; f(\\theta_0|\\boldsymbol x) \\leq \\dfrac{b}{a+b} \\\\ 0,&amp; c.c.\\end{array}\\right.~.\\) A interpreção nesse caso é mais direta, a hipótese é rejeitada se sua probabilidade posterior é “pequena”. Como vimos, essas soluções são equivalentes. De fato, \\(f(\\theta_0|\\boldsymbol x)\\) \\(=\\dfrac{f(\\theta_0)f(\\boldsymbol x|\\theta_0)}{f(\\boldsymbol x)}\\) \\(=\\pi~\\dfrac{f(\\boldsymbol x|\\theta_0)}{f(\\boldsymbol x)}\\); \\(f(\\theta_1|\\boldsymbol x)\\) \\(=\\dfrac{f(\\theta_1)f(\\boldsymbol x|\\theta_1)}{f(\\boldsymbol x)}\\) \\(=(1-\\pi)~\\dfrac{f(\\boldsymbol x|\\theta_1)}{f(\\boldsymbol x)}\\). Assim, \\(r_x(d_1) \\leq r_x(d_0)\\) \\(\\Longleftrightarrow a \\pi~\\dfrac{f(\\boldsymbol x|\\theta_0)}{f(\\boldsymbol x)} \\leq b (1-\\pi)~\\dfrac{f(\\boldsymbol x|\\theta_1)}{f(\\boldsymbol x)}\\) \\(\\Longleftrightarrow \\dfrac{f(\\boldsymbol x|\\theta_0)}{f(\\boldsymbol x|\\theta_1)} \\leq \\dfrac{b (1-\\pi)}{a \\pi}\\). \\(~\\) \\(~\\) Considere agora um caso mais geral, onde \\(\\Theta=\\Theta_0 \\dot{\\cup} \\Theta_1\\) e deseja-se testar \\(H_0: \\theta \\in \\Theta_0\\) contra \\(H_1: \\theta \\in \\Theta_1\\). Considere também a função de perda mais geral apresentada a seguir, com \\(a_0 \\leq a_1\\) e \\(b_0 \\leq b_1\\). \\(L(d,\\theta)\\) \\(\\Theta_0\\) \\(\\Theta_1\\) \\(d_0\\) \\(a_0\\) \\(b_1\\) \\(d_1\\) \\(a_1\\) \\(b_0\\) O risco posterior de cada uma das decisões é \\(r_x(d_0,\\theta)\\) \\(=a_0P(\\theta\\in\\Theta_0|x)+b_1P(\\Theta_1|x)\\) \\(=a_0P(\\theta\\in\\Theta_0|x)+b_1\\left[1- P(\\Theta_1|x)\\right]\\) \\(=a_0P(\\theta\\in\\Theta_0|x)+b_1-b_1P(\\Theta_0|x)\\), \\(r_x(d_1,\\theta)\\) \\(=a_1P(\\theta\\in\\Theta_0|x)+b_0-b_0P(\\Theta_0|x)\\), De modo que rejeita-se \\(H_0\\), \\(\\varphi(\\boldsymbol x)=1\\), se \\(r_x(d_1,P)\\leq r_x(d_0,P)\\) \\(\\Leftrightarrow (a_1-b_0)P(\\Theta_0|x)+b_0 \\leq (a_0-b_1)P(\\Theta_0|x)+b_1\\) \\(\\Leftrightarrow P(\\Theta_0|x) \\leq \\dfrac{(b_1-b_0)}{(a_1-a_0)+(b_1-b_0)}\\) Assim, o teste de bayes nesse caso é \\({\\varphi}(\\boldsymbol x)=\\left\\{\\begin{array}{rl} 1,&amp; P(\\Theta_0|x) \\leq \\dfrac{(b_1-b_0)}{(a_1-a_0)+(b_1-b_0)} \\\\ 0,&amp; c.c.\\end{array}\\right.~.\\) \\(~\\) \\(~\\) 5.4 Probabilidade Posterior de \\(H_0\\) Resultado. Seja \\(\\Theta=\\Theta_0 \\dot{\\cup} \\Theta_1\\) e suponha que deseja-se testar \\(H_0: \\theta \\in \\Theta_0\\) contra \\(H_1: \\theta \\in \\Theta_1\\) considerando a função de perda a seguir, com \\(a_0 \\leq a_1\\) e \\(b_0 \\leq b_1\\). \\(L(d,\\theta)\\) \\(\\Theta_0\\) \\(\\Theta_1\\) \\(d_0\\) \\(a_0\\) \\(b_1\\) \\(d_1\\) \\(a_1\\) \\(b_0\\) Então, o teste de bayes é \\({\\varphi}(\\boldsymbol x)=\\left\\{\\begin{array}{rl} 1,&amp; P(\\Theta_0|x) \\leq \\dfrac{(b_1-b_0)}{(a_1-a_0)+(b_1-b_0)} \\\\ 0,&amp; c.c.\\end{array}\\right.\\). \\(~\\) Exemplo 1. Considere \\(X_1,\\ldots,X_n\\) c.i.i.d. tais que \\(X_i|\\theta \\sim Ber(\\theta)\\) com \\(\\Theta = \\left\\{1/2,3/4\\right\\}\\). Suponha que, a priori, \\(f(\\theta=1/2)=f(\\theta=3/4)=1/2\\) e deseja-se testar \\(H_0: \\theta=1/2\\) contra \\(H_1: \\theta=3/4\\). Tem-se que \\(T(\\boldsymbol X)=\\sum X_i~|~\\theta\\sim Bin(n,\\theta)\\) é uma estatística suficiente para \\(\\theta\\). Então, \\(P(\\theta=1/2|T(\\boldsymbol X)=t)\\) \\(=\\dfrac{f(t|\\theta=1/2)f(\\theta=1/2)}{\\displaystyle\\sum_{\\theta \\in \\left\\{1/2~,~3/4\\right\\}} f(t|\\theta)f(\\theta)}\\) \\(=\\dfrac{\\displaystyle\\binom{n}{t}\\left(\\dfrac{1}{2}\\right)^n}{\\displaystyle\\binom{n}{t}\\left(\\dfrac{1}{2}\\right)^n+\\binom{n}{t}\\left(\\dfrac{3}{4}\\right)^t\\left(\\dfrac{1}{4}\\right)^{n-t}}\\) \\(=\\dfrac{1}{1+\\dfrac{3^t}{2^n}}\\). \\(~\\) Considere a função de perda \\(L(d,\\theta) = a_0~\\mathbb{I}(d_0,\\Theta_0) + b_1~\\mathbb{I}(d_0,\\Theta_1) + a_1~\\mathbb{I}(d_1,\\Theta_0) + b_0~\\mathbb{I}(d_1,\\Theta_1)\\) como no resultado anterior. Então, rejeita-se \\(H_0\\) se \\(P(\\theta \\in \\Theta_0 | \\boldsymbol x) &lt; K\\), com \\(K = \\dfrac{b_1-b_0}{(a_1-a_0)+(b_1-b_0)}\\). Assim, \\(P(\\theta=1/2|T=t)\\leq K\\) \\(~\\Longleftrightarrow~ \\dfrac{1}{1+\\frac{3^t}{2^n}} \\leq K\\) \\(~\\Longleftrightarrow~ {1+\\dfrac{3^t}{2^n}} \\geq \\dfrac{1}{K}\\) \\(~\\Longleftrightarrow~ 3^t\\geq 2^n\\left(\\dfrac{1}{K}-1\\right)\\) \\(~\\Longleftrightarrow~ t\\geq n\\log_3(2)+\\log_3\\left(\\dfrac{1-K}{K}\\right)\\) \\(~\\Longleftrightarrow~ t\\geq nlog_3(2)+log_3\\left(\\dfrac{a_1-a_0}{b_1-b_0}\\right)\\). \\(~\\) Tomando \\(a_1=b_1=1\\) e \\(a_0=b_0=0\\), rejeita \\(H\\) se \\(\\sum X_i \\geq n\\log_3(2)+\\log_3(1)\\) \\(~\\Longleftrightarrow~ \\sum X_i \\geq n\\log_3(2)\\) \\(~\\Longrightarrow~ \\bar{X} \\geq \\log_3(2)\\approx 0,631\\). \\(~\\) O teste de Bayes é \\({\\varphi}(\\boldsymbol x) =\\left\\{\\begin{array}{rl} 1,&amp; f(\\theta=1/2|\\boldsymbol x) \\leq \\dfrac{(b_1-b_0)}{(a_1-a_0)+(b_1-b_0)} = \\dfrac{1}{2} \\\\ 0,&amp; c.c.\\end{array}\\right.\\) \\(~\\Longrightarrow~ {\\varphi}(\\boldsymbol x) =\\left\\{\\begin{array}{rl} 1,&amp; \\bar{X} \\geq \\log_3(2) \\\\ 0,&amp; c.c.\\end{array}\\right.\\). \\(~\\) \\(~\\) Exemplo 2: \\(X_1,...,X_n\\) c.i.i.d. tais que \\(X_i|\\theta\\sim N(\\theta,{\\sigma}_0^2)\\) com \\({\\sigma}_0^2\\) conhecido. Suponha que, a priori, \\(\\theta \\sim N(m,v^2)\\) e \\(\\bar{X}\\) é estatística suficiente para \\(\\theta\\) com \\(\\bar{X}|\\theta \\sim \\left(\\theta,{\\sigma}_0^2/n\\right)\\), de modo que \\(\\theta|\\boldsymbol X \\sim N\\left(\\dfrac{{\\sigma}_0^2~m+nv^2~\\bar x}{{\\sigma}_0^2+nv^2}~,~\\dfrac{{\\sigma}_0^2~v^2}{{\\sigma}_0^2+nv^2}\\right)\\). Suponha ainda que o objetivo é testar \\(H_0: \\theta\\leq \\theta_0\\) contra \\(H_1:\\theta &gt; \\theta_0\\). \\(~\\) Utilizando novamente o resultado anterior, temos \\(P\\left(\\theta\\in\\Theta_0|\\boldsymbol x\\right)\\) \\(= P\\left(\\theta \\leq \\theta_0|\\boldsymbol x\\right)\\) \\(= P\\left(Z\\leq\\dfrac{\\theta_0-\\frac{{\\sigma}_0^2~m+nv^2~\\bar x}{{\\sigma}_0^2+nv^2}}{\\sqrt{\\frac{{\\sigma}_0^2~v^2}{{\\sigma}_0^2+nv^2}}}~\\Bigg|~\\bar x\\right)\\) \\(= \\Phi\\left(\\dfrac{\\theta_0-\\frac{{\\sigma}_0^2~m+nv^2~\\bar x}{{\\sigma}_0^2+nv^2}}{\\sqrt{\\frac{{\\sigma}_0^2~v^2}{{\\sigma}_ 0^2+nv^2}}}\\right)\\) \\(= \\Phi\\left(\\dfrac{({\\sigma}_0^2+nv^2)\\theta_0-{\\sigma}_0^2~m-nv^2~\\bar x}{{\\sigma}_0~v~\\sqrt{{\\sigma}_ 0^2+nv^2}}\\right)\\), e deve-se rejeitar \\(H_0\\) se \\(P\\left(\\theta\\in\\Theta_0|\\boldsymbol x\\right) \\leq \\dfrac{(b_1-b_0)}{(a_1-a_0)+(b_1-b_0)} = K\\) \\(~\\Longleftrightarrow~\\Phi\\left(\\dfrac{({\\sigma}_0^2+nv^2)\\theta_0-{\\sigma}_0^2~m-nv^2~\\bar x}{{\\sigma}_0~v~\\sqrt{{\\sigma}_ 0^2+nv^2}}\\right) \\leq K\\) \\(~\\Longleftrightarrow~ \\bar x ~\\geq~ \\dfrac{({\\sigma}_0^2+nv^2)\\theta_0-{\\sigma}_0^2~m}{nv^2} - {\\Phi}^{-1}(K)\\dfrac{{\\sigma}_0~\\sqrt{{\\sigma}_ 0^2+nv^2}}{nv}\\) \\(~\\Longleftrightarrow~ \\bar x ~\\geq~ \\dfrac{{\\sigma}_0^2(\\theta_0-m)+nv^2\\theta_0}{nv^2} - {\\Phi}^{-1}(K)\\dfrac{{\\sigma}_0~\\sqrt{{\\sigma}_ 0^2+nv^2}}{nv}\\). \\(~\\) Se \\(a_0=b_0=0\\) e \\(a_1=b_1=1\\), então \\(\\Phi^{-1}(K=1/2)=0\\) e rejeita-se \\(H_0\\) se \\(\\bar x ~\\geq~ \\dfrac{{\\sigma}_0^2(\\theta_0-m)+nv^2\\theta_0}{nv^2} ~\\underset{n\\uparrow\\infty}{\\longrightarrow}~ \\theta_0\\). \\(~\\) \\(~\\) 5.5 Fator de Bayes Voltando ao resultado, tem-se que rejeita-se \\(H_0\\) se \\(r_x(d_0) \\geq r_x(d_1)\\) \\(~\\Longleftrightarrow~ a_0P(\\Theta_0|\\boldsymbol x)+b_1P(\\Theta_1|\\boldsymbol x) \\geq a_1P(\\Theta_0|\\boldsymbol x)+b_0P(\\Theta_1|\\boldsymbol x)\\) \\(~\\Longleftrightarrow~ \\dfrac{P(\\Theta_0|\\boldsymbol x)}{P(\\Theta_1|\\boldsymbol x)}\\leq\\dfrac{b_1-b_0}{a_1-a_0}\\) \\(~\\Longleftrightarrow~ BF(\\boldsymbol x)\\) \\(=\\dfrac{\\frac{P(\\Theta_0|\\boldsymbol x)}{P(\\Theta_1|\\boldsymbol x)}}{\\frac{P(\\Theta_0)}{P(\\Theta_1)}}\\) \\(=\\dfrac{\\frac{P(\\Theta_0|\\boldsymbol x)}{P(\\Theta_0)}}{\\frac{P(\\Theta_1|\\boldsymbol x)}{P(\\Theta_1)}}\\) \\(=\\dfrac{f(\\boldsymbol x | \\Theta_0)}{f(\\boldsymbol x | \\Theta_1)}\\) \\(\\leq \\dfrac{(b_1-b_0)}{(a_1-a_0)}\\dfrac{P(\\Theta_1)}{P(\\Theta_0)}\\), onde \\(BF\\) é o Fator de Bayes, frequentemente utilizado na literatura bayesiana para testar hipóteses. Ele pode ser visto como uma razão de chances que representa o aumento na chance da hipótese nula ser mais plausível que a hipótese alternativa após observar os dados em relação a sua opinião a priori. O \\(BF\\) também pode ser reescrito como \\(BF(\\boldsymbol x)\\) \\(=\\dfrac{f_0(\\boldsymbol x)}{f_1(\\boldsymbol x)}\\) \\(=\\dfrac{f(\\boldsymbol x | \\Theta_0)}{f(\\boldsymbol x | \\Theta_1)}\\) \\(=\\dfrac{\\displaystyle \\int_{\\Theta}f(\\boldsymbol x|\\theta) f(\\theta|\\Theta_0) d\\theta} {\\displaystyle \\int_{\\Theta} f(\\boldsymbol x|\\theta)f(\\theta|\\Theta_1)d\\theta}\\) \\(=\\dfrac{\\displaystyle \\int_{\\Theta_0}f(x|\\theta)dP_0(\\theta)}{\\displaystyle \\int_{\\Theta_1}f(x|\\theta)dP_1(\\theta)}\\) \\(=\\dfrac{E\\left[f(\\boldsymbol x|\\theta)|\\theta\\in\\Theta_0\\right]}{E\\left[f(\\boldsymbol x|\\theta)|\\theta \\in \\Theta_1\\right]}\\). \\(~\\) No exemplo 1. Lembrando que, a priori, \\(P(\\theta=1/2)=P(\\theta=3/4)=1/2\\) e considerando novamente \\(a_0=b_0=0\\) e \\(a_1=b_1=1\\), temos que devemos rejeitar \\(H_0\\) se \\(BF(\\boldsymbol x)&lt;\\frac{(b_1-b_0)}{(a_1-a_0)}\\frac{P(\\theta=1/2)}{P(\\theta=3/4)}=1\\). Então, \\(BF(\\boldsymbol x)=\\dfrac{P(\\theta=1/2|\\boldsymbol x)}{P(\\theta=3/4|\\boldsymbol x)}\\dfrac{1/2}{1/2}\\) \\(=\\dfrac{\\frac{1}{1+3^t/2^n}}{\\frac{3^t/2^n}{1+3^t/2^n}}\\) \\(=\\dfrac{2^n}{3^t}\\leq 1\\) \\(~\\Longleftrightarrow~ \\bar{x} \\geq \\log_3(2)\\), de modo que a decisão baseada no fator de Bayes concorda com o resultado baseado na probabilidade a posteriori da hipótese. \\(~\\) No exemplo 2. \\(\\theta|\\boldsymbol X \\sim N\\left(\\dfrac{{\\sigma}_0^2~m+nv^2~\\bar x}{{\\sigma}_0^2+nv^2}~,~\\dfrac{{\\sigma}_0^2~v^2}{{\\sigma}_0^2+nv^2}\\right)\\) e o objetivo é testar \\(H_0: \\theta\\leq \\theta_0\\) contra \\(H_1:\\theta &gt; \\theta_0\\). A probabilidade a posteriori da hipótese \\(H_0\\) é \\(P\\left(\\theta\\in\\Theta_0|\\boldsymbol x\\right)\\) \\(= \\Phi\\left(\\dfrac{({\\sigma}_0^2+nv^2)\\theta_0-{\\sigma}_0^2~m-nv^2~\\bar x}{{\\sigma}_0~v~\\sqrt{{\\sigma}_ 0^2+nv^2}}\\right)\\), e, a priori, \\(P(\\theta \\in \\Theta_0)\\) \\(=P(\\theta \\leq \\theta_0)\\) \\(= \\Phi\\left(\\dfrac{\\theta_0-m}{v}\\right)\\), de modo que o fator de Bayes nesse caso é \\(BF(\\boldsymbol x)\\) \\(= \\dfrac{P(\\Theta_0|\\boldsymbol x)}{P(\\Theta_1|\\boldsymbol x)} \\dfrac{P(\\Theta_1)}{P(\\Theta_0)}\\) \\(= \\dfrac{\\Phi\\left(\\frac{({\\sigma}_0^2+nv^2)\\theta_0-{\\sigma}_0^2~m-nv^2~\\bar x}{{\\sigma}_0~v~\\sqrt{{\\sigma}_0^2+nv^2}}\\right)}{\\left[1-\\Phi\\left(\\frac{({\\sigma}_0^2+nv^2)\\theta_0-{\\sigma}_0^2~m-nv^2~\\bar x}{{\\sigma}_0~v~\\sqrt{{\\sigma}_0^2+nv^2}}\\right)\\right]} ~ \\dfrac{\\left[1-\\Phi\\left(\\frac{\\theta_0-m}{v}\\right)\\right]}{\\Phi\\left(\\frac{\\theta_0-m}{v}\\right)}\\). \\(~\\) m=0; v2=1 # Média e Variância da Priori sigma02=1 # Variância Populacional (conhecido) n=3 # tamanho amostral theta0=1 # H0: theta &lt;= theta0 a0=0; b0=0; a1=1; b1=1 # Função de Perda K1=(b1-b0)/(a1-a0+b1-b0) # corte Prob. Posterior K2=((b1-b0)*(1-pnorm((theta0-m)/sqrt(v2)))) / ((a1-a0)*pnorm((theta0-m)/sqrt(v2))) #corte Fator de Bayes K3=((sigma02+n*v2)*theta0-sigma02*m)/(n*v2) - qnorm(K1)*sqrt(sigma02*(sigma02+n*v2))/(n*sqrt(v2)) # corte xbar # Probabilidade a Posteriori de H0 (como função de Xbar) postH = function(xbar){ pnorm(((sigma02 + n*v2)*theta0 - sigma02*m - n*v2*xbar)/ sqrt(sigma02*v2*(sigma02+n*v2))) } # Fator de Bayes de H0 (como função de Xbar) bf = function(xbar){ (postH(xbar)*(1-pnorm((theta0-m)/sqrt(v2))))/ ((1-postH(xbar))*pnorm((theta0-m)/sqrt(v2))) } xbar=seq(0.5,2.5,0.001) PP=postH(xbar) BF=bf(xbar) FS=(max(PP)-min(PP))/(max(BF)-min(BF)) # var. aux. para transformção dos eixos tibble(xbar,PP,BF) %&gt;% ggplot() + geom_line(aes(x=xbar,y=PP,colour=&quot;Prob. Posterior&quot;)) + geom_line(aes(x=xbar,y=((BF-min(BF))*FS+min(PP)),colour=&quot;Fator de Bayes&quot;))+ scale_y_continuous(sec.axis = sec_axis(~./FS-min(PP)/FS+min(BF), name = &quot;BF&quot;))+ geom_hline(aes(yintercept=K1),lty=2, col=&quot;darkgrey&quot;) + geom_point(aes(x=K3,y=K1,colour=&quot;Prob. Posterior&quot;)) + geom_hline(aes(yintercept=((K2-min(BF))*FS+min(PP))),lty=2, col=&quot;darkgrey&quot;) + geom_point(aes(x=K3,y=((K2-min(BF))*FS+min(PP)),colour=&quot;Fator de Bayes&quot;)) + geom_vline(aes(xintercept=K3),lty=2, col=&quot;darkgrey&quot;) + theme_bw() + labs(colour = &quot;&quot;) Nesse exemplo, é possível ver que tanto o Fator de Bayes quanto a probabilidade posterior da hipótese nula “ordenam” o espaço amostral, representado aqui pela estatística suficiente, \\(\\bar{X}\\). Deste modo, quanto menores os valores dessas estatísticas de teste, mais desfavorável é o ponto amostral para a hipótese nula. Como visto anteriormente, as regras de decisão baseadas nessas estatísticas são equivalentes e, portanto, a ordenação do espaço amostral é a mesma. \\(~\\) \\(~\\) Problema: Suponha agora que, nesse mesmo exemplo, deseja-se testar \\(H_0:\\theta=0\\) contra \\(H_1: \\theta\\neq 0\\). Como a posteriori é Normal, temos que \\(P(\\theta \\in \\Theta_0|\\boldsymbol x)\\) \\(=P(\\theta=0|\\boldsymbol x)=0\\) , \\(\\forall~ \\boldsymbol x\\in \\mathfrak{X}~\\) e, desta forma, a hipótese nula \\(H_0\\) sempre é rejeitada. De fato, para qualquer cenário em que a hipótese \\(H_0\\) tem medida nula a priori, \\(P(\\theta \\in \\Theta_0)=0\\), tem-se que, a posteriori, \\(P(\\theta \\in \\Theta_0|\\boldsymbol x)=0\\). Isso ocorre frequentemente nos casos em que \\(H_0\\) é uma hipótese precisa, isto é, \\(dim(\\Theta_0)&lt;dim(\\Theta)\\). Neste cenário, é necessário definir procedimentos alternativos para testar hipóteses. \\(~\\) \\(~\\) 5.6 Teste de Jeffreys O teste de Jeffreys (1961?) consiste em atribuir uma probabilidade positiva para o conjunto que define a hipótese nula, \\(p_0=P(\\theta \\in \\Theta_0)&gt;0\\). \\(~\\) Exemplo 2. Suponha que deseja-se testar \\(H_0: \\theta=0\\) contra \\(H_1: \\theta\\neq 0\\). Suponha que sua opinião a priori é \\(\\theta \\sim Normal(0,2)\\). Contudo, já foi visto que \\(P(\\theta=0|\\boldsymbol x)=0\\), \\(\\forall \\boldsymbol x \\in \\mathfrak{X}\\). Deste modo, você opta por atribuir uma probabilidade positiva \\(p_0=0.2\\) para o ponto \\(\\theta=0\\), ou seja, você vai considerar uma distribuição mista \\(f(\\theta)=p_0\\mathbb{I}(\\theta=0)+(1-p_0)f_N(\\theta)\\), onde \\(f_N\\) é a densidade da \\(Normal(0,1)\\). Sua função de distribuição a prioi, \\(F(\\theta)=p_0~\\mathbb{I}(\\theta\\geq0)+(1-p_0)~\\Phi\\left(\\theta/\\sqrt{2}\\right)\\), está representada no gráfico a seguir. theta=c(seq(-5,-0.001,0.001),seq(0.001,5,0.001)) p=0.2 pprior = function(t){ p*I(t&gt;=0)+(1-p)*pnorm(t,0,2)*I(t!=0) } tibble(theta,Prior=pprior(theta)) %&gt;% ggplot()+geom_line(aes(x=theta,y=Prior))+ geom_point(aes(x=0,y=(1-p)*pnorm(0,0,2)))+ geom_point(aes(x=0,y=(1-p)*pnorm(0,0,2)+p)) Exercício. Calcule \\(P(\\theta=0|\\boldsymbol X=\\boldsymbol x)\\). \\(~\\) Exemplo 3. Seja \\(X_1,\\ldots,X_n\\) c.i.i.d. tais que \\(X_i|\\theta \\sim Ber (\\theta)\\) e considere que, a priori, \\(\\theta\\sim Beta(a,b)\\). Como \\(X=\\sum X_i\\) é estatística suficiente com \\(X\\big|\\theta \\sim Bin(n,\\theta)\\), tem-se que \\(\\theta\\big|x=\\sum x_i\\sim Beta\\left(a+\\sum x_i,b+n-\\sum x_i\\right)\\). A distribuição marginal de \\(X\\) é chamada distribuição preditiva a priori e pode ser calculada por \\(f(x)\\) \\(=\\displaystyle \\int_0^1 f(x,\\theta)d\\theta\\) \\(=\\displaystyle \\int_0^1 f(x|\\theta)f(\\theta)d\\theta\\) \\(=\\displaystyle \\binom{n}{x}~\\dfrac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}~\\int_0^1 \\theta^{a+x-1}(1-\\theta)^{b+n-x-1}d\\theta\\) \\(=\\displaystyle \\binom{n}{x}~\\dfrac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}~\\dfrac{\\Gamma(a+x)\\Gamma(b+n-x)}{\\Gamma(a+b+n)}\\) \\(=\\displaystyle \\binom{n}{x} \\dfrac{\\beta(a+x,b+n-x)}{\\beta(a,b)}~\\mathbb{I}_{\\{0,\\ldots,n\\}}(x)\\) \\(\\Longrightarrow X \\sim Beta-Binomial(n,a,b)\\). \\(~\\) Suponha agora que deseja-se testar \\(H_0: \\theta=\\theta_0\\) contra \\(H_1:\\theta\\neq \\theta_0\\), com \\(\\theta_0=1/2\\), utilizando o teste de Jeffreys. Desta forma, considere \\(p_0=P(\\theta=1/2)=1/2\\) e sua priori de Jeffreys é \\(f_J(\\theta)=p_0~\\mathbb{I}(\\theta=\\theta_0) +(1-p_0)f_\\beta(\\theta)~\\mathbb{I}(\\theta\\neq\\theta_0)\\), onde \\(f_\\beta\\) é a densidade da \\(Beta(a,b)\\). A distribuição preditiva com relação a priori \\(f_J\\) é \\(f_J(x)\\) \\(=\\displaystyle p_0f(x|\\theta_0)~\\mathbb{I}(\\theta=\\theta_0)+ (1-p_0)\\overbrace{\\int_0^1f(x|\\theta)f_\\beta(\\theta)~\\mathbb{I}(\\theta\\neq\\theta_0)d\\theta}^{f(x)}\\) \\(=\\displaystyle p_0\\binom{n}{x}{\\theta}_0^x(1-\\theta_0)^{n-x}~\\mathbb{I}(\\theta=\\theta_0) + (1-p_0)\\binom{n}{x}\\dfrac{\\beta(a+x,b+n-x)}{\\beta(a,b)}~\\mathbb{I}(\\theta\\neq\\theta_0)\\), de modo que a distribuição a posteriori é \\(f_J(\\theta| x)\\) \\(= \\dfrac{f( x|\\theta)f_J(\\theta)}{f_J(x)}\\) \\(= \\dfrac{p_0\\binom{n}{x} (1/2)^n}{f_J(x)}~\\mathbb{I}(\\theta=1/2) +\\dfrac{(1-p_0)\\binom{n}{x}\\theta^{a+x-1}(1-\\theta)^{b+n-x-1}}{\\beta(a,b)~f_J(x)}~\\mathbb I(\\theta\\neq 1/2)\\). \\(~\\) A probabilidade posterior da hipótese \\(H_0:\\theta=1/2\\) é \\(p_x=P(\\theta=1/2|x)\\) \\(=\\dfrac{p_0\\binom{n}{x}(1/2)^n}{p_0\\binom{n}{x}(1/2)^n+(1-p_0)\\binom{n}{x}\\frac{\\beta(a+x,b+n-x)}{\\beta(a,b)}}\\) \\(=\\dfrac{1}{1+\\dfrac{(1-p_0)}{p_0}\\dfrac{\\beta(a+x,b+n-x)}{(1/2)^n\\beta(a,b)}}\\). E, assim, o Fator de Bayes é dado por \\(B_j(x)=\\dfrac{\\dfrac{p_x}{1-p_x}}{\\dfrac{p_0}{1-p_0}}\\) \\(=\\dfrac{\\dfrac{1}{\\dfrac{(1-p_0)}{p_0}\\dfrac{\\beta(a+x,b+n-x)}{(1/2)^n\\beta(a,b)}}}{\\dfrac{p_0}{(1-p_0)}}\\) \\(=\\dfrac{(1/2)^n\\beta(a,b)}{\\beta(a+x,b+n-x)}\\). Note que, nesse caso, \\(BF(x)\\) não depende da probabilidade a priori \\(p_0\\) da hipótese \\(H_0\\). theta0=1/2 n=6; p=1/2 a=1;b=1 x=seq(0,n) # Fator de Bayes para cada x BF=(theta0^x)*((1-theta0)^(n-x))*beta(a,b)/beta(a+x,b+n-x) # Probabilidade a posteriori para cada x PP=(1 + (((1-p)*beta(a+x,b+n-x))/(p*(theta0^x)*((1-theta0)^(n-x))*beta(a,b))) )^(-1) tab=t(tibble(BF=round(BF,4),PP=round(PP,4))) colnames(tab)=x kable(tab, booktabs=TRUE, escape=FALSE) 0 1 2 3 4 5 6 BF 0.1094 0.6562 1.6406 2.1875 1.6406 0.6562 0.1094 PP 0.0986 0.3962 0.6213 0.6863 0.6213 0.3962 0.0986 Na tabela acima, são calculados \\(P(\\theta=1/2|x)\\) e \\(BF(x)\\) para cada \\(x\\) com \\(n=6\\), \\(p_0=1/2\\) e os parâmetros da Beta sendo \\(a=b=1\\). Considerando \\(a_0=b_0=0\\) e \\(a_1=b_1=1\\), os valores de corte para a probabilidade a posteriori e o \\(BF\\) são, respectivamente, \\(1/2\\) e \\(1\\). Desta forma, rejeita-se a hipótese nula para os valores “extremos” \\(\\left\\{0,1,5,6\\right\\}\\). \\(~\\) \\(~\\) 5.7 Hipóteses Precisas Probabilidade a posteriori da hipótese \\(H_0\\), \\(P(\\Theta_0|\\boldsymbol x)\\). Fator de Bayes \\(BF(\\boldsymbol x)\\). No caso absolutamente contínuo, quando \\(H_0\\) é hipótese precisa, \\(P(\\Theta_0|\\boldsymbol x)=0\\). Isso faz com que os testes anteriores sempre levem à rejeição de \\(H_0\\). Primeira alternativa: teste de Jeffreys. Problema: a priori deve dar probabilidade positiva à hipótese nula, conduzindo assim a uma priori “artificial” (mista). Serão apresentados dois procedimentos alternativos de teste: FBST e P-value. O primeiro deles foi pensado especificamente para hipóteses precisas \\(\\left(dim(\\Theta_0)&lt;dim(\\Theta)\\right)\\) mas ambos podem ser aplicados para hipóteses gerais. \\(~\\) \\(~\\) 5.8 FBST - Full Bayesian Significance Test Essa solução foi apresentada por Pereira e Stern em 1999. Suponha que o objetivo é testar \\(H_0:\\theta\\in\\Theta_0\\) contra \\(H_1:\\theta \\in \\Theta_1=\\Theta_0^c\\). Seja \\(T_x=\\left\\{\\theta\\in\\Theta ~:~f(\\theta|\\boldsymbol x)\\geq \\underset{\\theta\\in\\Theta_0}{sup}f(\\theta|\\boldsymbol x)\\right\\}\\) a região tangente à hipóteses \\(H_0\\), formada pelos pontos densidade posterior maior ou igual que qualquer ponto da hipótese nula. Se esse conjunto é “grande” (muito provável), a hipótese nula está em uma região de pouca densidade posterior e deve ser rejeitada. Assim, a medida de evidência (de Pereira-Stern) ou e-value é definido por \\(Ev(\\Theta_0,\\boldsymbol x)\\) \\(=1-P\\left(\\theta\\in T_x \\big|\\boldsymbol x \\right)\\), e deve-se rejeitar \\(H_0\\) se o e-value for “pequeno”. \\(~\\) Exemplo. \\(X_1,...,X_n\\) c.i.i.d. \\(N(\\theta,{\\sigma}_0^2)\\), com \\({\\sigma}_0^2\\) conhecido. Novamente, considere \\(\\theta\\sim N(m,v^2)\\), de modo que \\(\\theta|\\boldsymbol x \\sim N\\left(\\dfrac{{\\sigma}_0^2m+nv^2\\bar{x}}{{\\sigma}_0^2+nv^2},\\dfrac{{\\sigma}_0^2v^2}{{\\sigma}_0^2+nv^2}\\right)\\) e denote a média e a variância da posteriori por \\(M_x\\) e \\(V_x\\), respectivamente. Suponha que o interesse é testar \\(H_0:\\theta=\\theta_0\\) contra \\(H_1:\\theta\\neq\\theta_0\\). Sem perda de generalidade, suponha que \\(M_x \\geq \\theta_0\\). Então, como a normal é simétrica em torno de \\(M_x\\), a região tangente é da forma \\(T_x=[\\theta_0,2M_x-\\theta_0]\\). Note que quanto mais próximo \\(M_x\\) está de \\(\\theta_0\\), menor a região \\(T_x\\) e, portanto, maior o valor da evidência em favor de \\(H_0\\). O valor da evidência pode ser calculado por \\(Ev(\\Theta_0,x)=\\) \\(1-P\\left(\\theta_0\\leq \\theta\\leq2M-\\theta_0|x\\right)=\\) \\(1-P\\left(\\dfrac{\\theta_0-M}{\\sqrt V}\\leq Z\\leq \\dfrac{2M-\\theta_0-M}{\\sqrt V}|x\\right)=\\) \\(2\\Phi\\left(-\\dfrac{|\\theta_0-M|}{\\sqrt V}\\right)=\\) \\(2\\Phi\\left(-\\dfrac{\\left|\\dfrac{{\\sigma}_0^2m+nv^2\\bar{x}}{{\\sigma}_0^2+nv^2}-\\theta_0\\right|}{\\dfrac{{\\sigma}_0 v}{\\sqrt{{\\sigma}_0^2+nv^2}}}\\right)=\\) \\(2\\Phi\\left(-\\dfrac{\\sqrt{{\\sigma}_0^2+nv^2}}{{\\sigma}_0 v}\\dfrac{|{\\sigma}_0^2(m-\\theta_0)+nv^2(\\bar x-\\theta_0)|}{\\sqrt{{\\sigma}_0^2+nv^2}}\\right)=\\) \\(2\\Phi\\left(-\\dfrac{1}{\\sqrt{{\\sigma}_0^2+nv^2}}\\left|\\dfrac{{\\sigma}_0}{v}(m-\\theta_0)+\\dfrac{\\sqrt n v}{{\\sigma}_0}(\\bar x-\\theta_0)\\right|\\right)=\\) \\(2\\Phi\\left(-\\dfrac{1}{\\sqrt{{\\sigma}_0^2+nv^2}}\\left|\\dfrac{(m-\\theta_0)}{v/{\\sigma}_0}+\\sqrt nv\\dfrac{(\\bar x-\\theta_0)}{{\\sigma}_0/\\sqrt n}\\right|\\right)\\) \\(~\\) Sob a abordagem frequentista, temos que o p-value é \\(p(\\boldsymbol x)\\) \\(= 1-P\\left(-\\dfrac{|\\bar X-\\theta_0|}{{\\sigma}_0/\\sqrt n}\\leq Z \\leq \\dfrac{|\\bar X-\\theta_0|}{{\\sigma}_0/\\sqrt n}\\right)\\) \\(=2\\Phi\\left(-\\dfrac{|\\bar X-\\theta_0|}{{\\sigma}_0/\\sqrt n}\\right)\\) \\(\\Longleftrightarrow -\\dfrac{|\\bar X-\\theta_0|}{{\\sigma}_0/\\sqrt n}=\\Phi^{-1}\\left(\\dfrac{p-valor}{2}\\right)\\), de modo que, nesse exemplo, podemos escrever \\(Ev(\\Theta_0,x)=\\) \\(2\\Phi\\left(-\\dfrac{1}{\\sqrt{{\\sigma}_0^2+nv^2}}~\\left|\\dfrac{(m-\\theta_0)}{v/{\\sigma}_0}+\\sqrt nv~\\Phi\\left(\\dfrac{p(\\boldsymbol x)}{2}\\right)\\right|\\right)\\). A seguir, são apresentados gráficos do e-value e do p-value como função de \\(\\bar{x}\\) e do e-value como função do p-value usando da relação anterior. sigma02=4 m=0; v2=1 theta0 = 0 n=3 p=seq(0,1,length.out=5000) ep = function(p){ 2*pnorm(-abs(sqrt(sigma02/v2)*(m-theta0) + sqrt(n*v2)*qnorm(p/2))/ sqrt(sigma02+n*v2)) } graf=tibble(pv=p,ev=ep(p)) %&gt;% ggplot() + geom_line(aes(x=pv,y=ev),lwd=1.5) + geom_segment(x=0.05,xend=0.05,y=0,yend=round(ep(0.05),2),lty=2) + geom_segment(x=0,xend=0.05,y=round(ep(0.05),2),yend=round(ep(0.05),2),lty=2) + scale_y_continuous(breaks=c(0.00,round(ep(0.05),2),0.25,0.50,0.75,1.00)) + scale_x_continuous(breaks=c(0.00,0.05,0.25,0.50,0.75,1.00)) + theme_bw() if(knitr::is_latex_output()){ graf } else { plotly::ggplotly(graf) } Suponha que um estatístico frequentista decida rejeitar \\(H_0\\) se o p-value for menor que 0.05. Para que a decisão baseada no e-value concorde com o resultado frequentista (para esse particular exemplo), deve-se rejeitar a hipótese se o e-value for menor que 0.2, aproximadamente. Quando a variância da priori ou o tamanho amostral aumentam, os valores dessas duas medidas se aproximam. \\(~\\) Resultados Assintóticos (para esse exemplo) Suponha que \\(H_0: \\theta=\\theta_0\\) seja falso, isto é, o “verdadeiro” valor do parâmetro é \\(\\theta^* \\neq \\theta_0\\). Quando \\(n\\uparrow\\infty\\), pela Lei dos Grandes Números, \\(\\bar{X} ~\\overset{q.c.}{\\longrightarrow}~ \\theta^*\\) \\(~\\Longrightarrow~ \\dfrac{\\sqrt{n}|\\bar{X}-\\theta_0|}{{\\sigma}_0} ~{\\longrightarrow}~ +\\infty\\) \\(~\\Longrightarrow~ p(\\boldsymbol X)= 2\\Phi\\left(-\\dfrac{\\sqrt{n}|\\bar{X}-\\theta_0|}{{\\sigma}_0}\\right) ~{\\longrightarrow}~ 0\\), com probabilidade 1. Por outro lado, sob \\(H_0: \\theta=\\theta_0\\), pelo Teorema Central do Limite, \\(\\dfrac{\\sqrt{n}(\\bar{X}-\\theta_0)}{{\\sigma}_0} ~\\overset{\\mathcal{D}}\\longrightarrow~ Z \\sim N(0,1)\\) \\(~\\Longrightarrow~ p(\\boldsymbol X)= 2\\Phi\\left(-\\dfrac{\\sqrt{n}|\\bar{X}-\\theta_0|}{{\\sigma}_0}\\right) ~\\overset{\\mathcal{D}}\\longrightarrow~ U=2\\Phi\\left(-|Z|\\right) \\sim Unif(0,1)\\). \\(~\\) Esses resultados para o p-value são bastante conhecidos. No contexto desse exemplo, é possível obter resultados similares para o e-value. Novamente, considere que \\(H_0\\) é falso e, sem perda de generalidade, \\(\\theta=\\theta^*&gt;\\theta_0\\). Note que \\(\\dfrac{{\\sigma}_0(m-\\theta_0)}{v\\sqrt{{\\sigma}_0^2+nv^2}} ~\\longrightarrow~ 0\\) e, pela LGN, \\(\\bar{X} ~\\overset{q.c.}{\\longrightarrow}~ \\theta^*\\) \\(~\\Longrightarrow~ (\\bar{X}-\\theta_0) ~{\\longrightarrow}~ (\\theta^*-\\theta_0) &gt;0\\) \\(~\\Longrightarrow~ \\dfrac{nv(\\bar{X}-\\theta_0)}{{\\sigma}_0^2\\sqrt{{\\sigma}_0^2+nv^2}} ~{\\longrightarrow}~ +\\infty\\) \\(~\\Longrightarrow~ Ev(\\Theta_0,\\boldsymbol X)=2\\Phi\\left(-\\left|\\dfrac{{\\sigma}_0(m-\\theta_0)}{v{\\sqrt{{\\sigma}_0^2+nv^2}}}+\\dfrac{nv(\\bar x-\\theta_0)}{{\\sigma}_0{\\sqrt{{\\sigma}_0^2+nv^2}}}\\right|\\right) ~{\\longrightarrow}~ 2\\Phi\\left(-\\infty\\right)=0\\). Além disso, \\(\\dfrac{v\\sqrt{n}}{\\sqrt{{\\sigma}_0^2+nv^2}} ~\\longrightarrow~ 1\\) e, sob \\(H_0: \\theta = \\theta_0\\), \\(\\dfrac{v\\sqrt{n}}{\\sqrt{{\\sigma}_0^2+nv^2}}\\dfrac{\\sqrt{n}(\\bar{X}-\\theta_0)}{{\\sigma}_0} ~\\overset{\\mathcal{D}}\\longrightarrow~ Z \\sim N(0,1)\\), de modo que \\(Ev(\\Theta_0,\\boldsymbol{X})=2\\Phi\\left(-\\left|\\dfrac{{\\sigma}_0(m-\\theta_0)}{v{\\sqrt{{\\sigma}_0^2+nv^2}}}+\\dfrac{nv(\\bar x-\\theta_0)}{{\\sigma}_0{\\sqrt{{\\sigma}_0^2+nv^2}}}\\right|\\right) ~{\\longrightarrow}~ 2\\Phi\\left(-|Z|\\right)\\sim Unif(0,1)\\). Esse resultado pode não valer em outros contextos. Por exemplo, quando \\(dim(\\Theta_0)\\geq 2\\), a distribuição de \\(Ev(\\Theta_0,\\boldsymbol{X})\\) sob \\(H_0\\) não é \\(Unif(0,1)\\), em geral. \\(~\\) \\(~\\) 5.9 P-value - Nivel de Significância Adaptativo Recentemente, o p-value e a utilização do famoso nível \\(\\alpha=0.05\\) têm sido muito questionados, não apenas na área de testes de hipóteses mas na ciência como um todo. A ideia de fixar um nível de significância é que a probabilidade de erro tipo I fica “controlada” e a probabilidade do erro tipo II diminui quanto maior o tamanho amostral. Por essa razão, é comum nas áreas de planejamento de experimentos e amostragem, o cálculo do tamanho amostral para um determinado estudo. Infelizmente, na maior parte dos problemas do dia a dia de um estatístico, não há um planejamento cuidadoso ou as amostras disponíveis são “amostras de conveniência”. Simultaneamente, com a “revolução da informação”, a quantidade de dados disponível é cada vez maior. A consequência disso no cenário de testes de hipóteses é que os testes ficam muito poderosos e há uma tendência maior de rejeitar a hipótese nula. \\(~\\) Exemplo. Seja \\(X_1,\\ldots,X_n\\) c.i.i.d. tais que \\(X_i|\\theta \\sim Ber(\\theta)\\), \\(\\theta \\sim Beta(a,b)\\) de modo que \\(\\theta|x=\\sum x_i \\sim Beta(a+x,b+n-x)\\) e suponha que deseja-se testar \\(H_0: \\theta= 1/2\\). A seguir, para diferentes tamanhos amostrais \\(n\\) e supondo que em todos os casos \\(\\bar{x}_n=0.55\\), são apresentados os testes para esse caso vistos até aqui: p-value do teste RVG, probabilidade posterior e \\(BF\\) do teste de Jeffreys e e-value do FBST. a=1; b=1 p=0.5 alpha=0.05 theta0=0.5 xbar=0.55 N=c(1,5,10,20,30,40,50,100,150,300,seq(500,2000,250)) p_v=Vectorize(function(n){ x=n*xbar l = c(min(x,n-x),max(x,n-x)) pbinom(l[1],n,theta0) + 1-pbinom(l[2],n,theta0) }) Nalpha=seq(max(N[(p_v(N)-alpha)&gt;0]),min(N[(p_v(N)-alpha)&lt;0])) Nalpha=Nalpha[which.min(abs(p_v(Nalpha)-alpha))] bf=Vectorize(function(n){ x=n*xbar # exp(log(BF)) exp(x*log(theta0) + (n-x)*log(1-theta0) + lbeta(a,b) - lbeta(a+x,b+n-x)) }) prob_post=Vectorize(function(n){ x=n*xbar l = log(1-p)+lbeta(a+x,b+n-x)-log(p)-x*log(theta0)-(n-x)*log(1-theta0)-lbeta(a,b) 1/(1+exp(l)) }) e_v=Vectorize(function(n){ x=n*xbar f_Tx=function(t){ dbeta(t,a+x,b+n-x)-dbeta(theta0,a+x,b+n-x) } moda=(a+x-1)/(a+b+n-2) if(theta0==moda){ return(1) } if(theta0&lt;moda){ Tx=c(theta0,uniroot(f=f_Tx,lower=moda,upper=1)$root) }else{ Tx=c(uniroot(f=f_Tx,lower=0,upper=moda)$root,theta0) } pbeta(Tx[1],a+x,b+n-x)+1-pbeta(Tx[2],a+x,b+n-x) }) Dados=tibble(n=rep(N,4), Evidencia=c(p_v(N),prob_post(N),bf(N),e_v(N)), Estatistica=factor(rep(c(&quot;p-value&quot;,&quot;Prob. Post.&quot;,&quot;BF&quot;,&quot;e-value&quot;), each=length(N)),levels=c(&quot;Prob. Post.&quot;,&quot;BF&quot;,&quot;e-value&quot;,&quot;p-value&quot;)), corte=c(p_v(Nalpha),rep(NA,4*length(N)-1))) ggplot(Dados)+ geom_line(aes(x=n,y=Evidencia, colour=Estatistica),lwd=1.5)+ geom_vline(xintercept=Nalpha,lty=2,col=&quot;darkgrey&quot;)+ facet_wrap(~Estatistica, scales=&quot;free_y&quot;)+ geom_hline(data=subset(Dados,Estatística=&quot;p-value&quot;),aes(yintercept=corte), lty=2, col=&quot;darkgrey&quot;)+ theme_bw() Note que todas as medidas de suporte da hipótese tendem a zero conforme aumenta o tamanho amostral. Isso indica que se \\(|\\bar{x}_n-\\theta_0|=\\varepsilon\\) e for fixado um valor de corte para essas medidas que não dependa do tamanho amostral (por exemplo, o \\(\\alpha=0.05\\) para o p-value), existe um \\(n^*\\) tal que \\(H_0\\) será rejeitado para todo \\(n\\geq n^*\\). No gráfico, a linha vertical tracejada indica o valor \\(n^*\\) para o p-value considerando o corte \\(\\alpha=0.05\\). \\(~\\) Como visto anteriormente, o Lema de Neyman-Pearson Generalizado (DeGroot, 1986) garante que os testes Bayesianos (baseados na probabilidade posterior ou no BF) minimizam \\(a\\alpha + b\\beta\\). Baseado nesse resultado, O professor Carlos A. B. Pereira recentemente propôs um novo procedimento de teste para evitar o problema descrito anteriormente. Seja \\(BF(\\boldsymbol x) = \\dfrac{f_0(\\boldsymbol x)}{f_1(\\boldsymbol x)}\\) \\(=\\dfrac{\\displaystyle\\int_{\\Theta_0} f(\\boldsymbol x|\\theta) dP_0(\\theta)}{\\displaystyle \\int_{\\Theta_1} f(\\boldsymbol x|\\theta) dP_1(\\theta)}\\), onde \\(P_i\\) é a medida de probabilidade a priori para \\(\\theta\\) restrito à hipótese \\(H_i\\), \\(i=0,1\\); Defina \\(\\alpha_n = P\\left(\\left\\{\\boldsymbol x : BF(\\boldsymbol x)\\leq\\dfrac{b}{a}\\right\\} ~\\Big|~ \\Theta_0\\right)\\) e \\(\\beta_n = P\\left(\\left\\{\\boldsymbol x : BF(\\boldsymbol x)&gt;\\dfrac{b}{a}\\right\\} ~\\Big|~ \\Theta_1\\right)\\); Suponha que foi observado \\(\\boldsymbol X=\\boldsymbol x_o\\). O P-value é dado por \\(\\text{P-value}(\\boldsymbol x_o) = P\\left(\\left\\{\\boldsymbol x : BF(\\boldsymbol x)\\leq BF(\\boldsymbol x_o)\\right\\} ~\\Big|~ \\Theta_0\\right)\\); O procedimento de teste consiste em rejeitar \\(H_0\\) se \\(\\text{P-value}(\\boldsymbol x) &lt; \\alpha_n\\). \\(~\\) Voltando ao Exemplo. As distribuções preditivas sob \\(H_0: \\theta=\\theta_0=1/2\\) e \\(H_1:\\theta \\neq 1/2\\) são \\(f_0(\\boldsymbol x)\\) \\(= f(\\boldsymbol x | \\theta_0)\\) \\(=\\displaystyle \\binom{n}{x} {\\theta}_0^x (1-{\\theta}_0)^{n-x}\\) \\(=\\displaystyle \\binom{n}{x} {(1/2)^{n}}\\) ; \\(f_1(\\boldsymbol x)\\) \\(=\\displaystyle \\int_{\\Theta\\setminus\\theta_0} f(\\boldsymbol x|\\theta) f(\\theta) d\\theta\\) \\(=\\displaystyle \\int_0^1 \\binom{n}{x} \\dfrac{{\\theta}_0^{a+x-1} (1-{\\theta}_0)^{b+n-x-1}}{\\beta(a,b)}~d\\theta\\) \\(=\\displaystyle \\binom{n}{x}\\dfrac{\\beta(a+x,b+n-x)}{\\beta(a,b)}\\) . Deste modo, \\(BF(\\boldsymbol x)\\) \\(=\\dfrac{f_0(\\boldsymbol x)}{f_1(\\boldsymbol x)}\\) \\(=\\dfrac{\\beta(a,b)~{\\theta}_0^x (1-{\\theta}_0)^{n-x}}{\\beta(a+x,b+n-x)}\\) \\(=\\dfrac{\\beta(a,b)~(1/2)^{n}}{\\beta(a+x,b+n-x)}\\), e, assim, \\(\\alpha_n = \\displaystyle {(1/2)^{n}} \\sum_{\\left\\{\\boldsymbol x: BF(\\boldsymbol x)\\leq\\frac{b}{a}\\right\\}}\\binom{n}{x}\\), \\(\\beta_n = \\displaystyle \\dfrac{1}{{\\beta(a,b)}} \\sum_{\\left\\{\\boldsymbol x: BF(\\boldsymbol x)&gt;\\frac{b}{a}\\right\\}}\\binom{n}{x}\\beta(a+x,b+n-x)\\), \\(\\text{P-value}(\\boldsymbol x_0) = \\displaystyle {(1/2)^{n}} \\sum_{\\left\\{\\boldsymbol x: BF(\\boldsymbol x)\\leq BF(\\boldsymbol x_o)\\right\\}}\\binom{n}{x}\\) \\(~\\) Supondo novamente que foi observado \\(\\bar{x}=0.55\\), o gráfico abaixo apresenta esses valores para diversos tamanhos amostrais. a=1; b=1 a1=1; b1=1 p=0.5 alpha=0.05 theta0=0.5 xbar=0.55 N=c(2,5,seq(10,150,10),seq(150,1000,50)) bf=Vectorize(function(x,n){ exp(x*log(theta0) + (n-x)*log(1-theta0) + lbeta(a,b) - lbeta(a+x,b+n-x)) }, vectorize.args = c(&quot;x&quot;)) alphaN = Vectorize(function(n){ x=n*xbar s=seq(0,n) s=s[bf(s,n)&lt;=b1/a1] (0.5)^n*sum(choose(n,s)) }) betaN = Vectorize(function(n){ x=n*xbar s=seq(0,n) s=s[bf(s,n)&gt;b1/a1] sum(extraDistr::dbbinom(s,n,a,b)) }) P_v=Vectorize(function(n){ x=n*xbar s=seq(0,n) s=s[bf(s,n)&lt;=bf(x,n)] (0.5)^n*sum(choose(n,s)) }) Dados=tibble(n=N, alpha=alphaN(N), beta=betaN(N), Pvalue=P_v(N)) ggplot(Dados)+ geom_line(aes(x=n,y=Pvalue, colour=&quot;P-value&quot;),lwd=1.2)+ geom_line(aes(x=n,y=alpha, colour=&quot;alpha&quot;),lwd=1.2)+ geom_line(aes(x=n,y=beta, colour=&quot;beta&quot;),lwd=1.2)+ geom_line(aes(x=n,y=alpha+beta, colour=&quot;alpha+beta&quot;),lwd=1.2)+ theme_bw() + labs(colour=&quot;&quot;) \\(~\\) \\(~\\) "],
["medprob.html", "A Breve Resumo de Medida e Probabilidade A.1 Conceitos Básicos A.2 Valor Esperado de \\(X\\) (OU uma ideia da tal Integral de Lebesgue) A.3 Funções de Variáveis Aleatórias A.4 Probabilidade Condicional", " A Breve Resumo de Medida e Probabilidade Essa seção tem o objetivo de apresentar as ideias de probabilidade como uma medida e da integral de Lebesgue. Para maiores detalhes, ver Ash and Doleans-Dade (2000), Billingsley (1986), Shiryaev (1996) ou, para uma versão mais resumida, os Apêndices de Schervish (2012). A.1 Conceitos Básicos \\(\\Omega\\): espaço amostral (um conjunto não vazio). \\(\\mathcal{A}\\): \\(\\sigma\\)-álgebra de subconjuntos de \\(\\Omega\\), isto é, \\(\\Omega \\in \\mathcal{A}\\); \\(A \\in \\mathcal{A} \\Longrightarrow A^{c} \\in \\mathcal{A}\\); \\(\\displaystyle A_1, A_2, \\ldots \\in \\mathcal{A} \\Longrightarrow \\bigcup_{i\\geq1} A_i \\in \\mathcal{A}\\). Os elementos de \\(\\mathcal{A}\\) são chamados de eventos e serão denotados por \\(A, B, C, \\ldots, A_1, A_2, \\ldots\\) Uma coleção de eventos \\(A_1,A_2,\\ldots\\) forma uma partição de \\(\\Omega\\) se \\(A_i \\cap A_j = \\emptyset\\), \\(\\forall i \\neq j\\), e \\(\\displaystyle \\bigcup_{i=1}^{\\infty} A_i = \\Omega\\). \\((\\Omega, \\mathcal{A})\\): espaço mensurável. Usualmente, denota-se a \\(\\sigma\\)-álgebra gerada por um conjunto \\(\\mathcal{C}\\) como \\(\\sigma(\\mathcal{C})\\). Por exemplo: \\(\\sigma(\\Omega) = \\{\\emptyset,\\Omega\\}~~\\) (\\(\\sigma\\)-ágebra trivial); Para \\(A \\subset \\Omega\\), \\(\\sigma(A) = \\{\\emptyset, A, A^c, \\Omega\\}\\); \\(\\sigma(\\mathbb{N}) = \\mathcal{P}(\\mathbb{N})~~\\) (partes de \\(\\mathbb{N}\\), todos o subconjuntos de \\(\\mathbb{N}\\)); \\(\\sigma\\left(\\left\\{(-\\infty,x): x \\in \\mathbb{R}\\right\\}\\right) = \\mathcal{B}\\left(\\mathbb{R}\\right)~~\\) (borelianos de \\(\\mathbb{R}\\)) \\(~\\) Definição: A função \\(\\mu: \\mathcal{A} \\longrightarrow \\bar{\\mathbb{R}}_+\\) é uma medida se 1. \\(\\mu(\\emptyset) = 0\\); 2. \\(\\displaystyle A_1, A_2, \\ldots \\in \\mathcal{A}\\) com \\(A_i \\bigcap A_j = \\emptyset\\) , \\(\\forall i \\neq j\\) , \\(\\displaystyle \\mu\\left(\\bigcup_{i \\geq 1} A_i\\right) = \\sum_{i \\geq 1} \\mu\\left(A_i\\right)\\). \\((\\Omega,\\mathcal{A}, \\mu)\\) é chamado de espaço de medida. \\(~\\) Exemplo 1 (medida de contagem): Seja \\(\\Omega\\) um conjunto não vazio e \\(A\\subseteq \\Omega\\). Defina \\(\\nu(A)=|A|\\) como o número de elementos (cardinalidade) de \\(A\\). Assim, \\(\\nu(\\Omega) &gt; 0\\), \\(\\nu(\\emptyset)=0\\) e, se \\((A_n)_{n \\geq 1}\\) é uma sequência de eventos disjuntos, então \\(\\nu(\\cup A_n) = \\sum \\nu(A_n)\\). Note que \\(\\nu(A)=\\infty\\) é possivel se \\(\\Omega\\) tem infinitos elementos. \\(~\\) Exemplo 2 (medida de Lebesgue): Seja \\(\\Omega=\\mathbb{R}\\) e \\(A\\subseteq \\Omega\\) um intervalo. Se \\(A\\) é limitado, defina \\(\\mu(A)\\) como o comprimento do intervalo A. Se \\(A\\) não é limitado, \\(\\mu(A)=\\infty\\). Note que \\(\\mu(\\mathbb{R})=\\infty\\), \\(\\mu(\\emptyset)=0\\) e, se \\(A_1 \\cap A_2 = \\emptyset\\) e \\(A_1 \\cup A_2\\) é um intervalo (ou uma união de intervalos disjuntos), então \\(\\mu(A_1 \\cup A_2) = \\mu(A_1) + \\mu(A_2)\\). \\(~\\) Exemplo 3: Seja \\(f: \\mathbb{R} \\longrightarrow \\mathbb{R}_+\\) uma função contínua e não nula. Para cada intervalo \\(A\\), defina \\(\\displaystyle \\mu(A) = \\int_A f(x) dx = \\int_{\\mathbb{R}} \\mathbb{I}_A(x) f(x) dx\\). Então, \\(\\mu(\\mathbb{R})&gt;0\\), \\(\\mu(\\emptyset)=0\\) e, se \\(A_1 \\cap A_2 = \\emptyset\\) e \\(A_1 \\cup A_2\\) é um intervalo (ou uma união de intervalos disjuntos), então \\(\\mu(A_1 \\cup A_2) = \\mu(A_1) + \\mu(A_2)\\). \\(~\\) Se \\(\\mu(\\Omega) &lt; \\infty\\) dizemos que \\(\\mu\\) é uma medida finita. Se existe uma partição enumerável de \\(\\Omega\\), \\(A_1,A_2,\\ldots\\), tal que cada elemento da partição tem medida finita, \\(\\mu(A_i)&lt;\\infty\\), \\(\\forall i\\), dizemos que \\(\\mu\\) é uma medida \\(\\sigma\\)-finita. \\(~\\) Definição: Seja \\((\\Omega,\\mathcal{A})\\) um espaço mensurável e \\(\\mu_1\\) e \\(\\mu_2\\) medidas nesse espaço. Dizemos que \\(\\mu_2\\) é absolutamente contínua com relação à \\(\\mu_1\\) se, \\(\\forall A \\in \\mathcal{A}\\), \\(\\mu_1(A)=0\\) \\(~\\Rightarrow~ \\mu_2(A)=0\\). Nesse caso, dizemos que \\(\\mu_2\\) é dominada por \\(\\mu_1\\) ou que \\(\\mu_1\\) é uma medida dominante para \\(\\mu_2\\) e denotamos \\(\\mu_2 \\ll \\mu_1\\). \\(~\\) Teorema (de Radon-Nikodin): Seja \\(\\mu_2 \\ll \\mu_1\\) com \\(\\mu_1\\) \\(\\sigma\\)-finita. Então, \\(\\exists f: \\Omega \\longrightarrow [0,+\\infty]\\) tal que, \\(\\forall A \\in \\mathcal{A}\\), \\[\\mu_2(A) = \\int_A f(x) d\\mu_1(x).\\] Além disso, se \\(g:\\Omega \\longrightarrow \\mathbb{R}\\) é \\(\\mu_2\\)-integrável, então \\[\\int g(x) d\\mu_2(x) = \\int g(x) f(x) d\\mu_1(x).\\] A função \\(f=\\frac{d\\mu_2}{d\\mu_1}\\) é chamada de derivada de Radon-Nikodin da medida \\(\\mu_2\\) com relação à medida \\(\\mu_1\\) e é única \\(\\mu_1\\)-q.c. (ou seja, é única em todo conjunto \\(\\Omega\\) com eventual excessão de um conjunto \\(C\\) tal que \\(\\mu_1(C)=0\\)). \\(~\\) \\(~\\) Definição: \\(P: \\mathcal{A} \\longrightarrow [0,1]\\) é uma medida de probabilidade se 1. \\(P(\\Omega) = 1\\); 2. \\(\\displaystyle A_1, A_2, \\ldots \\in \\mathcal{A}\\) com \\(A_i \\bigcap A_j = \\emptyset\\) , \\(\\displaystyle P\\left(\\bigcup_{i \\geq 1} A_i\\right) = \\sum_{i \\geq 1} P\\left(A_i\\right)\\). \\((\\Omega, \\mathcal{A}, P)\\): espaço de probabilidade \\(~\\) Definição: Seja \\((\\Omega,\\mathcal{A})\\) e \\((\\mathfrak{X},\\mathcal{F})\\) dois espaços mensuráveis. Uma função \\(X: \\Omega \\longrightarrow \\mathfrak{X}\\) é chamado de quantidade aleatória se é uma função mensurável, isto é, se \\(\\forall B \\in \\mathcal{F}\\), \\(A = X^{-1}(B) \\in \\mathcal{A}\\). Se \\(\\mathfrak{X} = \\mathbb{R}\\) e \\(\\mathcal{F}=\\mathcal{B}\\) (\\(\\sigma\\)-álgebra de Borel), \\(X\\) é chamada variável aleatória (v.a.). A medida de probabilidade induzida por \\(X\\) recebe o nome de distribuição de \\(X\\). Se \\(B \\in \\mathcal{F}\\) e \\(A = \\{\\omega \\in \\Omega : X(\\omega) \\in B\\} \\in \\mathcal{A}\\), a medida induzida por \\(X\\) é \\[P_X(B) = P(\\{\\omega \\in \\Omega : X(\\omega) \\in B\\}) = P(A)~.\\] \\(~\\) \\(~\\) Exemplo 1: Seja \\(\\Omega=\\mathfrak{X}=\\mathbb{R}\\) com a \\(\\sigma\\)-álgebra de Borel e \\(f\\) uma função não negativa tal que \\(\\displaystyle\\int f(x) dx = 1\\). Defina \\(\\displaystyle\\mu(A)= \\int_A f(x) dx\\) e \\(X(\\omega)=\\omega\\). Então, \\(X\\) é uma variável aleatória contínua com função de densidade de probabilidade (f.d.p.) \\(f\\) e \\(\\mu_x = \\mu\\). Além disso, \\(\\mu_X\\) é absolutamente contínua com relação à medida de Lebesgue \\((\\mu_X \\ll \\lambda)\\) e \\(\\frac{d\\mu_X}{d\\lambda}=f\\). \\(~\\) Exemplo 2: Seja \\(\\Omega=\\mathbb{R}\\) com a \\(\\sigma\\)-álgebra de Borel, \\(\\mathfrak{X} = \\{x_1,x_2,\\ldots\\}\\) um conjunto enumerável. Seja \\(f\\) uma função não negativa definida em \\(\\mathfrak{X}\\) tal que \\(\\displaystyle \\sum_{i=1}^{\\infty} f(x_1) = 1\\). Defina \\(\\displaystyle \\mu(A) = \\sum_{\\{i: x_i \\in A\\}} f(x_i)\\). Então \\(X\\) é uma variável aleatória discreta com função de probabilidade (f.d.p.) \\(f\\) e \\(\\mu_X=\\mu\\). Além disso, \\(\\mu_X\\) é absolutamente contínua com relação à medida de contagem \\((\\mu_X \\ll \\nu)\\) e \\(\\frac{d\\mu_X}{d\\nu}=f\\). \\(~\\) A.2 Valor Esperado de \\(X\\) (OU uma ideia da tal Integral de Lebesgue) Por simplicidade, considere o espaço \\(\\Big(\\Omega = [0,1]~,~~ \\mathcal{A} = \\mathcal{B}\\left([0,1]\\right)~,~~ P=\\lambda\\Big)\\). Seja \\(X: \\Omega \\longrightarrow \\mathbb{R}_+\\) uma variável aleatória discreta, assumindo valores não negativos \\(\\mathfrak{X}=\\{x_1,x_2,\\ldots,x_k\\}\\) com probabilidades \\(\\{p_1,p_2,\\ldots,p_k\\}\\). Nos cursos básicos de probabilidade é visto que o valor esperado (ou esperança) de \\(X\\) é \\(E[X] =\\) \\(\\sum x_i P(X=x_i) =\\) \\(\\sum x_i p_i\\). Podemos definir essa v.a. como \\(X(\\omega) = \\left\\{\\begin{array}{lccc} x_1, &amp; 0 &amp; \\leq \\omega \\leq &amp; p_1 \\\\ x_2, &amp; p_1 &amp; &lt; \\omega \\leq &amp; p_1+p_2 \\\\ \\vdots &amp; &amp; &amp; \\\\ x_j, &amp; \\sum_{i=1}^{j-1} p_j &amp; &lt; \\omega \\leq &amp; \\sum_{i=1}^{j} p_j \\\\ \\vdots &amp; &amp; &amp; \\\\ x_k, &amp; 1-p_k &amp; &lt; \\omega \\leq &amp; 1 \\end{array}\\right.\\) Assim, temos que \\(P_X(X=x_1) =\\) \\(P\\left(\\{\\omega \\in \\Omega : X(\\omega)=x_1\\}\\right) =\\) \\(\\lambda\\left([0,p_1]\\right) =\\) \\(p_1\\), \\(P_X(X=x_j) =\\) \\(P\\left(\\{\\omega \\in \\Omega : X(\\omega)=x_j\\}\\right) =\\) \\(\\lambda\\left(\\left[\\sum_{i=1}^{j-1} p_i,\\sum_{i=1}^{j} p_i\\right]\\right) =\\) \\(p_j ~,~\\) \\(j \\in \\{2,\\ldots,k\\}\\). \\(~\\) Definição: Uma função mensurável \\(X: \\Omega \\longrightarrow \\mathbb{R}_+\\) é dita simples se assumir um número finito de valores. \\(~\\) Definição: Considere um espaço de probabilidade \\((\\Omega, \\mathcal{A}, P)\\), \\(X:\\Omega\\longrightarrow \\mathbb{R}_+\\) v.a. assumindo valores \\(\\{x_1,x_2,\\ldots,x_k\\}\\) e \\(A_1,A_2,\\ldots,A_k\\) eventos disjuntos em \\(\\mathcal{A}\\). Seja \\(\\displaystyle X(\\omega) = \\sum_{i=1}^{k} x_i ~\\mathbb{I}_{A_i}(\\omega)\\), uma função simples com \\(A_i = X^{-1}(x_i)\\), \\(i=1,\\ldots,k\\). A integral de Lebesgue de \\(X\\) em relação à medida \\(P\\) é \\[E[X] = \\int_\\Omega X dP = \\sum_{i=1}^{k} x_i P(A_i).\\] \\(~\\) Propriedades: se \\(X, Y: \\Omega \\longrightarrow \\mathbb{R}_+\\) são funções simples, então 1. \\(\\displaystyle\\int_\\Omega X dP \\geq 0\\); 2. \\(\\displaystyle\\int_\\Omega cX dP = c\\int_\\Omega X dP\\); 3. \\(\\displaystyle\\int_\\Omega (X+Y) dP = \\int_\\Omega X dP + \\int_\\Omega Y dP\\). \\(~\\) Demo 1. Segue de \\(x_i \\geq 0\\) e \\(P(A_i) \\geq 0\\). Demo 2. Para \\(X\\) v.a. temos \\(X =\\displaystyle \\sum_{i=1}^kx_i~\\mathbb{I}_{A_i}\\) e \\(cX = \\displaystyle\\sum_{i=1}^k c~x_i ~\\mathbb{I}_{A_i}\\). Logo, \\(\\displaystyle\\int_\\Omega cX~dP = \\sum_{i=1}^k c~x_i~P(A_i)\\) \\(=\\displaystyle c\\sum_{i=1}^kx_i P(A_i) = c\\int_\\Omega X dP\\). Demo 3. \\(X = \\sum_{i=1}^kx_i~\\mathbb{I}_{A_i}\\) e \\(Y = \\sum_{j=1}^ly_j~\\mathbb{I}_{B_j}\\). \\(X + Y\\) \\(=\\displaystyle \\sum_{i=1}^k x_i ~\\mathbb{I}_{A_i} + \\sum_{j=1}^l y_j~\\mathbb{I}_{B_j}\\) \\(=\\displaystyle\\sum_{i=1}^k\\sum_{j=1}^lx_i~\\mathbb{I}_{A_i\\cap B_j} + \\sum_{i=1}^k\\sum_{j=1}^ly_j~\\mathbb{I}_{A_i\\cap B_j}\\) \\(=\\displaystyle\\sum_{i=1}^k\\sum_{j=1}^l(x_i+y_j)~\\mathbb{I}_{A_i\\cap B_j}\\). \\(\\displaystyle \\int_\\Omega (X + Y) dP\\) \\(=\\displaystyle \\sum_{i=1}^k\\sum_{j=1}^l (x_i + y_j)P(A_i\\cap B_j)\\) \\(=\\displaystyle\\sum_{i=1}^k\\sum_{j=1}^l x_iP(A_i\\cap B_j) + \\sum_{i=1}^k\\sum_{j=1}^l y_jP(A_i\\cap B_j)\\) \\(=\\displaystyle\\sum_{i=1}^k x_i P(A_i) + \\sum_{j=1}^l y_j P(B_j)\\) \\(=\\displaystyle\\int_\\Omega X dP + \\int_\\Omega Y dP\\). \\(~\\) \\(~\\) A generalização da integral de Lebesgue é feita usando resultados como o Lema de Fatou e os teoremas da convergência monótona e da convergência dominada. Aqui será apresentado apenas uma ideia dessa extensão. Para maiores detalhes, veja as referências citadas anteriormente (Ash and Doleans-Dade 2000; Schervish 2012; Billingsley 1986; Shiryaev 1996). \\(~\\) \\(~\\) Definição: Seja \\(X:\\Omega\\longrightarrow \\mathbb{R}_+\\) uma função mensurável não negativa e considere o conjunto de funções \\(\\mathcal{C}_X\\) \\(= \\{ f:\\Omega\\longrightarrow \\mathbb{R}_+~,~~f~~\\text{simples}~,~~f \\leq X\\}\\). O valor esperado de \\(X\\) é \\[E[X]=\\int_\\Omega XdP=\\sup\\left\\{\\int_\\Omega fdP: f\\in \\mathcal{C}_X\\right\\}~.\\] \\(~\\) Resultado: Para toda função \\(X:\\Omega \\longrightarrow \\mathbb{R}_+\\), existe uma sequência \\((f_n)_{n\\geq 1}\\) de funções simples não-negativas tais que \\(f_n(w)\\leq f_{n+1}(w),\\) \\(\\forall w \\in \\Omega,\\) \\(\\forall n \\in \\mathbb{N}\\) com \\(f_n(w)\\uparrow X(w),\\) \\(\\forall w \\in \\Omega.\\) \\(~\\) Exemplo de sequência \\((f_n)_{n\\geq 1}\\) atendendo as condições anteriores Para cada \\(n\\), considere \\(1+n2^n\\) conjuntos em \\(\\mathcal{A}:\\) \\(E_j^n = \\left\\{w \\in \\Omega: \\dfrac{j}{2^n} \\leq X(w) \\leq \\dfrac{j+1}{2^n} \\right\\}\\), \\(j = 0,1,...,n2^n-1.\\) \\(E_{n2^n}^n = \\Big\\{ w \\in \\Omega: X(w)\\geq n \\Big\\}\\) e defina \\(\\displaystyle X_n(w) = \\sum_{j=0}^{n2^n} \\dfrac{j}{2^n} ~\\mathbb{I}_{E_j^n}(w)\\). Pode-se provar que \\((X_n)_{n\\geq 1}\\) é tal que \\(X_n\\) é simples, \\(\\forall n \\geq 1\\) \\(X_n \\leq X_{n+1}\\) \\(X_{n}(w) \\uparrow X(w)\\) \\(~\\) \\(~\\) Resultado: \\(X,Y: \\Omega \\longrightarrow\\mathbb{R}_+,\\) com \\(X\\leq Y\\). Então \\(E[X] \\leq E[Y]\\). Demo: Como \\(X \\leq Y\\) (isto é, \\(X(w) \\leq Y(w)\\) \\(\\forall w \\in \\Omega\\)), \\(\\mathcal{C}_X \\subseteq \\mathcal{C}_Y\\) \\(\\Rightarrow \\sup\\left\\{\\displaystyle\\int_\\Omega f~dP:~ f\\in \\mathcal{C}_X\\right\\} \\leq \\sup\\left\\{\\displaystyle\\int_\\Omega g~dP:~ g\\in \\mathcal{C}_Y\\right\\}\\) \\(\\Rightarrow \\displaystyle\\int_\\Omega XdP \\leq \\displaystyle\\int_\\Omega YdP\\). \\(~\\) Definição: Seja \\(X:\\Omega \\longrightarrow\\mathbb{R}_+\\) e \\(E \\in \\mathcal{A}\\) definimos \\(E(X~\\mathbb{I}_E) = \\displaystyle\\int_EXdP\\) \\(=\\displaystyle\\int_\\Omega X~\\mathbb{I}_EdP\\). Se \\(E,F \\in \\mathcal{A}\\) com \\(E\\subseteq F\\), \\(\\displaystyle\\int_E XdP \\leq \\int_F XdP.\\) \\(~\\) \\(~\\) Propriedades: se \\(X, Y: \\Omega \\longrightarrow \\mathbb{R}_+\\) são funções mensuráveis positivas, então 1. \\(\\displaystyle\\int_\\Omega cXdP =\\) \\(c\\int_\\Omega XdP, c\\geq 0\\); 2. \\(\\displaystyle\\int_\\Omega (X+Y)dP =\\) \\(\\int_\\Omega XdP + \\int_\\Omega YdP\\). Demo 1. Seja \\(X_n\\uparrow X,\\) \\(X_n \\geq 0\\) simples. Então \\(cX_n\\uparrow cX,\\) \\(cX_n \\geq 0,\\) simples. \\(\\displaystyle\\int_\\Omega cX dP\\) \\(=\\underset{n\\rightarrow\\infty}{lim}\\int_\\Omega cX_n dP\\) \\(=\\displaystyle\\lim_{n\\rightarrow\\infty}c\\int_\\Omega X_n dP\\) \\(=\\displaystyle c\\lim_{n\\rightarrow\\infty}\\int_\\Omega X_n dP\\) \\(=\\displaystyle c\\int_\\Omega X dP\\). Demo 2. Exercício. \\(~\\) Exemplo: Suponha que \\(X\\) assume valores em \\(\\mathbb{N}\\). Pode-se escrever \\(X =\\displaystyle\\sum_{i=1}^\\infty i ~\\mathbb{I}_{A_i}~\\), com \\(A_i = X^{-1}\\left(\\{i\\}\\right)\\). Defina \\(X_n =\\displaystyle\\sum_{i=1}^{n-1} i ~\\mathbb{I}_{A_i}+n~\\mathbb{I}_{\\underset{j=n}{\\cup} A_j}\\). Então \\(X_n\\) é simples, \\(X_n \\geq 0~\\), \\(X_n \\leq X_{n+1}\\) e \\(X_n \\uparrow X\\), de modo que \\(E(X)\\) \\(=\\displaystyle\\int_\\Omega X dP\\) \\(=\\displaystyle\\lim_{n \\rightarrow\\infty}\\int_\\Omega X_n dP\\). Além disso, \\(\\displaystyle\\int_\\Omega X_n dP\\) \\(=\\displaystyle\\sum_{i=1}^{n-1} i~P(A_i) + n~P\\left(\\bigcup_{j=n}^{\\infty} A_j\\right)\\) \\(=\\displaystyle\\sum_{i=1}^{n-1}i~P(X = i) + n~P(X \\geq n)\\) \\(=\\displaystyle\\sum_{i=1}^{n-1} \\sum_{j=1}^{i} P(X = i) + n~P(X \\geq n)\\) \\(\\displaystyle=\\sum_{j=1}^{n-1} \\sum_{i=j}^{n-1} P(X = i) + n~P(X \\geq n)\\) \\(=\\displaystyle\\sum_{j=1}^{n-1}P(j \\leq X \\leq n-1) + n~P(X \\geq n)\\) \\(=\\displaystyle\\sum_{j=1}^n P(X \\geq j)\\), então, \\(E(X)\\) \\(\\displaystyle=\\lim_{n\\rightarrow \\infty}\\sum_{j=1}^nP(X \\geq j)\\) \\(\\displaystyle=\\sum_{j=1}^{\\infty}P(X \\geq j)\\). \\(~\\) Seja \\(X: \\Omega \\longrightarrow \\mathbb{R}\\) e \\(X^-,X^+: \\Omega \\longrightarrow \\mathbb{R}\\) dados por \\(X^- = \\max\\{-X,0\\}~\\) (parte negativa de \\(X\\)) e \\(X^+ = \\max\\{X,0\\}~\\) (parte positiva de \\(X\\)) \\(~\\) \\(~\\) Note que \\(X = X^+ - X^-\\) \\(~\\) Se \\(\\displaystyle\\int_\\Omega X^+ dP &lt; \\infty\\) ou \\(\\displaystyle\\int_\\Omega X^- dP &lt; \\infty\\), definimos \\(E[X]\\) \\(=\\displaystyle\\int X dP\\) \\(=\\displaystyle\\int_\\Omega X^+dP - \\int_\\Omega X^- dP\\) \\(=E\\left[X^+\\right] - E\\left[X^-\\right]\\). \\(~\\) Além disso, seja \\(|X| = X^+ + X^-\\). Então, \\(E\\left[~|X|~\\right] &lt; \\infty\\) se \\(E(X^+) &lt; \\infty\\) e \\(E(X^-) &lt; \\infty\\), e, nesse caso, dizemos que \\(X\\) é integrável. \\(~\\) Propriedades: se \\(X, Y: \\Omega \\longrightarrow \\mathbb{R}\\) são funções mensuráveis, então 1. \\(X \\leq Y \\Rightarrow E(X) \\leq E(Y)\\); 2. \\(c \\in \\mathbb{R},\\) \\(E(cX) = cE(X)\\); 3. \\(X,Y\\) integráveis. \\(E(X+Y) = E(X) + E(Y)\\). Demo 1. \\(X \\leq Y \\Rightarrow\\) \\(\\left\\{\\begin{array}{c}X^+ \\leq Y^+\\\\ X^- \\geq Y^-\\end{array}\\right.\\) \\(E(X) =\\) \\(E(X^+) - E(X^-)\\) \\(\\leq E(Y^+) - E(Y^-)\\) \\(=E(Y).\\) Demo 2. \\((cX)^+ =\\) \\(\\left\\{\\begin{array}{rcl}cX^+ &amp;,&amp; c \\geq 0\\\\ -cX^- &amp;,&amp; c &lt; 0 \\end{array}\\right.\\) \\((cX)^- =\\) \\(\\left\\{\\begin{array}{rcl}cX^- &amp;,&amp; c \\geq 0\\\\ -cX^+ &amp;,&amp; c &lt; 0 \\end{array}\\right.\\) Para \\(c&lt;0\\), \\(E[cX]\\) \\(= E[(cX)^+] - E[(cX)^-]\\) \\(= E[-cX^-] - E[-cX^+]\\) \\(= -cE[X^-] + cE[X^+]\\) \\(= cE[X]\\). Demo 3. \\(\\displaystyle\\int_\\Omega \\left(X^+ + Y^+\\right) dP &lt; \\infty\\) ou \\(\\displaystyle\\int_\\Omega \\left(X^- + Y^-\\right) dP &lt; \\infty\\) \\(X + Y\\) \\(= (X + Y)^+ - (X+Y)^-\\) \\(= X^+ - X^- + Y^+ - Y^-\\) \\(\\Rightarrow (X+Y)^+ + X^- + Y^-\\) \\(= X^+ + Y^+ + (X+Y)^-\\) \\(\\Rightarrow \\displaystyle\\int_\\Omega (X+Y)^+dP + \\int_\\Omega X^-dP + \\int_\\Omega Y^-dP\\) \\(=\\displaystyle\\int_\\Omega X^+dP + \\int_\\Omega Y^+dP + \\int_\\Omega (X+Y)^-dP\\). \\(|X+Y|\\) \\(= |X^+-X^-+Y^+-Y^-|\\) \\(\\leq X^++X^-+Y^++Y^-\\) \\(\\Rightarrow \\displaystyle\\int_\\Omega (X+Y)^+dP - \\int_\\Omega(X+Y)^-dP\\) \\(=\\displaystyle \\int_\\Omega X^+dP -\\int_\\Omega X^-dP + \\int_\\Omega Y^+dP -\\int_\\Omega Y^-dP\\). \\(\\Rightarrow \\displaystyle\\int_\\Omega(X+Y)dP = \\int_\\Omega XdP + \\int_\\Omega YdP\\) \\(~\\) \\(~\\) A.3 Funções de Variáveis Aleatórias Considere agora uma v.a. \\(X: \\Omega \\longrightarrow \\mathbb{R}\\) e uma função real \\(g: \\mathbb{R} \\longrightarrow \\mathbb{R}\\). Defina \\(Y = g(X)\\). Então \\[(\\Omega, \\mathcal{A},P) \\overset{X}{\\longrightarrow}(\\mathbb{R},\\mathcal{B}(\\mathbb{R}),P_X)\\overset{g}{\\longrightarrow}(\\mathbb{R},\\mathcal{B}(\\mathbb{R}),P_Y)\\] \\[(\\Omega, \\mathcal{A},P)\\overset{Y = g(X)}{\\longrightarrow}(\\mathbb{R},\\mathcal{B}(\\mathbb{R}),P_Y)\\] Logo, se \\(g\\) é uma função mensurável, \\(Y=g(X)\\) também é v.a. e as medidas induzidas por X e Y são \\[P_X(A) = P(X^{-1}(A)) = P\\left(\\{w \\in \\Omega : X(w) \\in A\\}\\right)\\] \\[P_Y(B) = P_X(g^{-1}(B)) = P_X\\left(\\{x \\in \\mathbb{R} : g(x) \\in B\\}\\right) = P\\left(\\{w \\in \\Omega : g\\left(X(w)\\right) \\in B\\}\\right).\\] Assim, uma pergunta natural é como obter o valor esperado de \\(Y\\). \\(E(Y) = \\int_\\Omega YdP=\\) \\(\\int_\\Omega g(X)dP \\overset{?}{=}\\) \\(\\int_{\\mathbb{R}}gdP.\\) \\(~\\) Seja \\(g\\) simples \\(g = \\sum_{i=1}^kg_i~\\mathbb{I}_{B_i},\\) \\(g_1,...,g_k \\in \\mathbb{R}\\) e \\(B_1,...,B_k \\in \\mathcal{B}(\\mathbb{R})\\) \\(\\int_\\Omega YdP =\\) \\(\\int_\\Omega g(x)dP=\\) \\(\\int_\\Omega \\left(\\sum_{i=1}^k g_i ~\\mathbb{I}_{B_i}(x)\\right)dP=\\) \\(\\int_\\Omega \\left(\\sum_{i=1}^k g_i ~\\mathbb{I}_{X^{-1}(B_i)}\\right)dP \\overset{def}{=}\\) \\(\\sum_{i=1}^kg_iP(X^{-1}(B_i))=\\) \\(\\sum_{i=1}^kg_iP_X(B_i)=\\) \\(\\int_{\\mathbb{R}}\\left(\\sum_{i=1}^kg_i~\\mathbb{I}_{B_i}\\right)dP=\\) \\(\\int_{\\mathbb{R}} gdP_X.\\) Seja \\(g\\) não negativa \\(g \\geq 0,\\) e \\((g_n)_{n\\geq1},\\) \\(g_n \\geq 0\\) simples tal que \\(g_n\\uparrow g.\\) Como \\(g_n\\) é simples: \\(\\int_\\Omega g_n(x)dP=\\) \\(\\int_{\\mathbb{R}}g_ndP_X\\) \\(\\overset{ limite}{\\Rightarrow} \\int_\\Omega g(x)dP=\\) \\(\\int_{\\mathbb{R}}gdP_X.\\) Agora \\(g: \\mathbb{R} \\longrightarrow \\mathbb{R}.\\) \\(\\int_\\Omega g^+(x)dP=\\) \\(\\int_{\\mathbb{R}}g^+dP_X,\\) \\(\\int_\\Omega g^-(x)dP=\\) \\(\\int_{\\mathbb{R}}g^-dP_X,\\) logo, \\(\\int_\\Omega g(x)dP=\\) \\(\\int_{\\mathbb{R}}gdP_X.\\) Suponha agora \\(X\\) v.a. discrtea assumindo valores em \\(\\{x_1,x_2,...\\}\\) com probabilidade \\(1\\). \\(P(X \\in A) =\\) \\(\\underset{i:x_i\\in A}{\\sum}P(X=x_i)\\) Vamos “verificar” que \\(E[g(X)]=\\) \\(\\sum_{i=1}^\\infty g(x_i)P(X=x_i)\\) \\(g\\) simples \\(g = \\sum_{i=1}^kg_i~\\mathbb{I}_{B_i},\\) \\(g_1,...,g_k \\in \\mathbb{R}\\) \\(B_1,...,B_k \\in \\mathcal{B}(\\mathbb{R})\\) \\(E[g(X)] =...\\) \\(\\sum_{i=1}^k g_i P(X \\in B_i)=\\) \\(\\sum_{i=1}^k g_i \\sum_{j:x_j \\in B_i}^k P(X = x_j)=\\) \\(\\sum_{i=1}^k g_i \\sum_{j=1}^\\infty \\mathbb{I}_{B_i}(x_j)P(X=x_j)=\\) \\(\\sum_{j=1}^\\infty \\underbrace{\\left(\\sum_{i=1}^k g_i ~\\mathbb{I}_{B_i}(x_j)\\right)}_{g(x_j)}P(X = x_j).\\) \\(g\\geq 0,\\) \\(g_n\\geq0,\\) \\(g_n\\) simples tal que \\(g_n \\uparrow g\\) \\(\\int_\\Omega g(X)dP=\\) \\(\\underset{n\\rightarrow\\infty}{lim}\\int_\\Omega g_n(X)dP=\\) \\(\\underset{n\\rightarrow\\infty}{lim}\\left\\{\\sum_{j=1}^\\infty g_n(x_j)P(X=x_j)\\right\\}=\\) \\(\\sum_{j=1}^\\infty g(x_j)P(X = x_j)\\) Suponha agora \\(X\\) v.a. absolutamente contínua com densidade \\(f_X,\\) \\(P(X\\in A)=\\) \\(\\int_Af_X(t)dt.\\) Assim, em geral, vale que: \\(X\\) discreto: \\(E[g(X)] =\\) \\(\\sum_{j=1}^\\infty g(x_j)P(X=x_j)\\) e se \\(X\\) contínua (absolutamente): \\(E[g(X)] =\\) \\(\\int_{\\mathbb{R}} g(x_j)f_X(x)dx\\) Esses resultados valem também se \\(X: \\Omega \\longrightarrow \\mathbb{R}^k\\) e \\(g: \\mathbb{R}^k\\longrightarrow \\mathbb{R}.\\) Exemplos \\(X \\sim Poisson(\\lambda)\\) \\(E[X] =\\) \\(\\sum_{x=0}^\\infty xP(X=x)=\\) \\(\\sum_{x=0}^\\infty x\\dfrac{e^{-\\lambda}\\lambda^x}{x!}=\\) \\(\\sum_{x=1}^\\infty \\dfrac{e^{-\\lambda}\\lambda^x}{(x-1)!}\\) \\(\\lambda \\sum_{x=1}^\\infty \\dfrac{e^{-\\lambda}\\lambda^{x-1}}{(x-1)!} \\Rightarrow\\) \\(E(X) = \\lambda.\\) Ainda no Exemplo, considere \\(g(\\mu) = e^\\mu\\) \\(E[g(x)]=\\) \\(\\sum_{x=0}^\\infty g(x)P(X=x)=\\) \\(\\sum_{x=0}^\\infty e^x \\dfrac{e^{-\\lambda}\\lambda^x}{x!}=\\) \\(e^{-\\lambda}\\sum_{x=0}^\\infty \\dfrac{(\\lambda e)^x}{x!}=\\) \\(e^{-\\lambda}e^{\\lambda e}\\underbrace{\\sum_{x=0}^{\\infty} \\dfrac{e^{-\\lambda e}(\\lambda e)^x}{x!}}_{1}=\\) \\(e^{\\lambda e - \\lambda}=\\) \\(e^{\\lambda(e-1)}\\). \\(X \\sim Beta(a.b)\\) \\(E[g(X)]\\). \\(g(x) = x^n(1-x)^m\\) \\(E[X] =\\) \\(\\int_{-\\infty}^\\infty xf_X(x)dx=\\) \\(\\int_0^1 x \\dfrac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}x^{a-1}(1-x)^{b-1}dx=\\) \\(\\dfrac{\\Gamma (a+1)\\Gamma(b)}{\\Gamma(a+1+b)}\\dfrac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}\\int_0^1\\dfrac{\\Gamma(a+1+b)}{\\Gamma(a+1)\\Gamma(b)}x^{(a+1)-1}(1-x)^(b-1)dx\\) \\(=\\dfrac{\\Gamma (a+1)\\Gamma(b)}{\\Gamma(a+1+b)}\\dfrac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}\\) Definição: Uma função \\(F: \\mathbb{R} \\longrightarrow [0,1]\\) é uma função de distribuição (f.d.) se \\(F\\) é não-decrescente e contínua à direita; \\(\\underset{x\\downarrow-\\infty}{lim}F(x)=0\\) e \\(\\underset{x\\uparrow+\\infty}{lim}F(x)=1\\) Preposição: Se \\(X\\) é uma v.a., então \\(F_X(x)=P_X(X\\leq x)\\) é uma f.d. Recíprocamente, se \\(F_X\\) é uma f.d, então existe uma v.a. \\(X\\) com f.d. \\(F_X.\\) Podemos usar uma f.d. \\(F\\) para criar uma medida em \\((\\mathbb{R},\\mathcal{B}(\\mathbb{R})).\\) Defina \\(P((a,b]))=F(b)-F(a)\\) e extenda essa medida para a \\(\\sigma\\)-álgebra usando o teorema de extensão de Caratheodory. Reciprocamente, se \\(P\\) é uma medida de probabilidade em \\((\\mathbb{R},\\mathcal{B}(\\mathbb{R}))\\) então \\(F(x)=P((-\\infty,x])\\) é uma f.d. \\(f: \\mathbb{R}\\longrightarrow \\mathbb{R}\\) mensuravel, \\(\\int f(x)dF(x)=\\) \\(\\int f(x)dP(x)\\) Se \\(P\\) é uma probabilidade em \\((\\mathbb{R}^k,\\mathcal{B}(\\mathbb{R}^k))\\) então uma f.d. conjunta pode ser definida por \\(F(x_1,...,x_k)=\\) \\(P((-\\infty,x_1]\\times ...\\times (-\\infty,x_k]),\\) f.d. conjunta do vector aleatório \\(\\boldsymbol{X} = (X_1,...,X_K).\\) Definição: \\((\\Omega, \\mathcal{A}, P)\\) espaço de probabilidade e \\((\\mathfrak{X},\\mathfrak{F},\\mathcal{V})\\) espaço mensurável. Considere \\(X: \\Omega \\longrightarrow \\mathfrak{X}\\) uma v.a. e \\(P_X\\) a medida induzida por \\(X\\) de \\(P\\), i.e. \\(P_X(B) = P(X^{-1}(B)).\\) Suponha que \\(P_X &lt;&lt; \\mathcal{V}\\). Então, a derivada de Radom-Nicodin \\(f_X = \\dfrac{d\\mu_X}{d\\mathcal{V}}\\) é a densidade de \\(X\\) com respeito a \\(\\mathcal{V}\\). Proposição: Se \\(h: \\mathfrak{X}\\longrightarrow\\mathbb{R}\\) é mensurável e \\(f_X = \\dfrac{dP_X}{d\\mathcal{V}},\\) então \\(\\int h(x)dF_X(x)=\\) \\(\\int h(x)f_X(x)d\\mathcal{V}.\\) \\(X \\sim Geo(\\theta)\\) \\(P(X=x)=\\) \\((1-\\theta)^{x-1}\\theta ~\\mathbb{I}_{\\{1,2...\\}}(x)\\) como \\(X\\) é inteira não-negativa, vale que: \\(E(X)=\\) \\(\\sum_{i=1}^\\infty P(X \\geq 1)=\\) \\(\\sum_{i=1}^\\infty \\left\\{\\sum_{j=1}^\\infty P(X=j)\\right\\}=\\) \\(\\sum_{i=1}^\\infty \\left\\{\\sum_{j=1}^\\infty (1-\\theta)^{j-1}\\theta\\right\\}=\\) \\(\\sum_{i=1}^\\infty (1-\\theta)^{i-1}\\Rightarrow\\) \\(E(x)=\\dfrac{1}{\\theta}\\) Se \\(X\\) é contínua não-negativa, então \\(E(X)=\\) \\(\\int_0^\\infty P(X&gt;t)dt.\\) Exemplo \\(X\\sim Exp(\\lambda)\\) \\(f_X(x)=\\lambda e^{\\lambda x}~\\mathbb{I}_{\\mathbb{R}_+}(x)\\) \\(P(X &gt; t)=\\) \\(\\int_t^\\infty \\lambda e^{-\\lambda s}ds=\\) \\(e^{-\\lambda t}\\) Assim, \\(E(X)=\\) \\(\\int_0^\\infty P(X&gt;t)dt=\\) \\(\\dfrac{1}{\\lambda}\\underbrace{\\int_0^\\infty \\lambda e^{-\\lambda t}dt}_{1} \\Rightarrow\\) \\(E(X)=\\dfrac{1}{\\lambda}\\) \\((X,Y)\\) absolutamente contínuo com densidade \\(f(x,y)=\\) \\(\\dfrac{1}{y}e^{-y}~\\mathbb{I}_{(0,y)}(x)~\\mathbb{I}_{\\mathbb{R}_+}(y);\\) \\(g(x,y)=xy\\) \\(E(g(X,Y))=?\\) \\(E(XY)=\\) \\(\\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty xyf(x,y)dxdy=\\) \\(\\int_{-\\infty}^\\infty \\left[\\int_{-\\infty}^\\infty xy\\dfrac{1}{y}e^{-y}dx\\right]dy=\\) \\(\\int_{0}^\\infty \\dfrac{y^2}{2}e^{-y}dy=\\) \\(\\dfrac{1}{2}\\dfrac{\\Gamma(3)}{1^3}\\int_0^\\infty \\dfrac{1^3}{\\Gamma(3)}y^2e^{-y}dy \\Rightarrow\\) \\(E(XY)=1\\) \\((X_1,...,X_k) \\sim DIR(a_1,...a_k)\\) \\(g(X_1,...,X_k) = X_1^{n_1}X_2^{n_2}\\cdots X_k^{n_k}(1-X_1-...-X_k)^{n_0}\\) \\(E[g(X_1,...,X_k)]=\\) \\(\\int_{S_k} X_1^{n_1}\\cdots X_k^{n_k}(1-X_1-...-X_k)^{n_0}\\) \\(\\underbrace{\\dfrac{\\Gamma(a_0+a_1+...+a_k)}{\\Gamma(a_0)\\Gamma(a_1)...\\Gamma(a_k)}}_{c(a_0,a_1,...,a_k)}\\) \\(x_1^{a_1-1}x_2^{a_2-1}...x_k^{a_k-1}\\) \\((1-x_1-...-x_k)^{a_0-1}dx,\\) onde \\(S_k = \\left\\{(y_1,y_2,...,y_k)\\in \\mathbb{R}^K_+: y_1+...+y_k \\leq 1\\right\\}\\) Então, \\(E[g(y_1,...,y_k)]=\\) \\(c(a_0,a_1,...,a_k)\\) \\(\\int_{S_K}x_1^{a_1+n_1-1}...x_k^{a_k+n_k-1}\\) \\((1-x_1-...-x_k)^{a_0+n_0-1}dx\\) \\(\\Rightarrow E[g(x_1,...,x_k)]=\\) \\(\\dfrac{c(a_0,...,a_k)}{c(a_0+n_0,a_1+n_1,...,a_k+n_k)}\\) n lançamentos de uma moeda. Dizemos que ocorre um “rum” de tamanho \\(k\\) se são observadas \\(k\\) caras consecutivas. \\(X:\\) Número de lançamentos de “run” de tamanho \\(k\\) observados. \\(n=4\\) \\(cc\\bar{c}c\\) \\(k=2\\) \\(ccc\\bar{c}\\) Definimos \\(X_i=\\left\\{\\begin{array}{ll} 1, &amp; \\text{ se ocorre rum de tamanho k iniciando no i=ésimo lançamento}\\\\ 0 &amp; c.c. \\end{array}\\right.\\) \\(X=\\sum_{i=1}^{n-k+1}X_i\\) \\(E(X) = E\\left(\\sum_{i=1}^{n-k+1}X_i\\right)=\\) \\(=\\sum_{i=1}^{n-k+1}E(X_i)=\\) \\(\\sum_{i=1}^{n-k+1}\\left\\{1P(X_i=1)+0P(X_i=0)\\right\\}=\\) \\(\\sum_{i=1}^{n-k+1}P(X_i=1)=\\) \\(\\sum_{i=1}^{n-k+1}p^k \\Rightarrow\\) \\(E(X)=(n-k+1)p^k.\\) Problema dos pareaentos (\\(n\\) objetos) \\(X:\\) NÚmero de pareamentos \\(X = X_1+X_2+...+X_n\\) onde \\(X_i=\\left\\{\\begin{array}{ll} 1, &amp; \\text{há areamento na i-ésima posição}\\\\ 0, &amp; c.c.\\end{array}\\right.\\) \\(E(X)=\\) \\(E\\left(\\sum_{i=1}^n X_i\\right)=\\) \\(\\sum_{i=1}^n E(X_i)=\\) \\(\\sum_{i=1}^nP(X_i=1)=\\) \\(\\sum_{i=1}^n \\dfrac{(n-1)!}{n!} \\Rightarrow\\) \\(E(X)=1\\) Resultado: \\(X_1,X_2,...,X_k\\) são v.a. independentes com \\(E(X_i)&lt;\\infty,\\) \\(i=1,...,k\\) Então, \\(E(X_1*X_2\\dots*X_k) =\\) \\(E(X_1)E(X_2)\\cdots E(X_k)\\) Resultado \\((\\Omega,\\mathcal{A})\\) espaço mensurável. \\(P_1,P_2: \\mathcal{A}\\longrightarrow [0,1)\\) probabilidades. \\(X: \\Omega \\longrightarrow \\mathbb{R}\\) v.a. \\(\\int_\\Omega X dP1\\) e \\(\\int_\\Omega X dP2\\) \\(P=\\alpha P_1 +(1-\\alpha)P_2,\\) \\(0&lt;\\alpha&lt;1.\\) Então; \\(\\int_\\Omega XdP =\\) \\(\\alpha \\int_\\Omega XP_1 + (1-\\alpha)\\int_\\Omega XdP_2\\) \\(X\\) simples \\(X=\\sum_{i=1}^kX_i~\\mathbb{I}_{A_i}\\) \\(\\int_\\Omega XdP=\\) \\(\\sum_{i=1}^kx_iP(A_i)=\\) \\(\\sum_{i=1}^k x_i[\\alpha P(A_i)+(1-\\alpha)P_2(A_i)]=\\) \\(\\alpha \\sum_{i=1}^k x_iP(A_i)+(1-\\alpha)\\sum_{i=1}^k x_iP_2(A_i)=\\) \\(\\alpha \\int_\\Omega XdP_1+(1-\\alpha)\\int_\\Omega XdP_2\\) \\(X \\geq 0\\) \\(X_n \\uparrow X,\\) \\(X_n \\geq 0,\\) simples. \\(\\int_\\Omega XdP=\\) \\(\\underset{n\\rightarrow\\infty}{lim}\\int_\\Omega X_n dP=\\) \\(\\underset{n\\rightarrow\\infty}{lim}\\left\\{\\alpha\\int_\\Omega X_ndP_1+(1-\\alpha)\\int_\\Omega X_ndP_2\\right\\}=\\) \\(\\alpha \\underset{n\\rightarrow\\infty}{lim}\\int_\\Omega X_ndP_1 + (1-\\alpha)\\int_\\Omega X_n dP_2=\\) \\(\\alpha \\int XdP_1 + (1-\\alpha)\\int_\\Omega XdP_2.\\) \\(P_1(\\left\\{x_1,x_2,...,\\right\\})=1\\), \\(P_2\\) “possui” função densidade de probabilidade \\(f_x,\\) e \\(X:\\Omega \\longrightarrow \\mathbb{R}\\) tal que \\(P(X \\in A)=\\) \\(\\alpha P_1(X^{-1}(A))+(1-\\alpha)P_2(X^{-1}(A))\\) Então: \\(E(X)=\\) \\(\\int_\\Omega XdP=\\) \\(\\alpha \\int_\\Omega XdP_1 + (1-\\alpha)\\int_\\Omega XdP_2=\\) \\(\\alpha \\sum_{i=1}^\\infty x_iP_1(X=x_i)+(1-\\alpha)\\int_{-\\infty}^\\infty x f_X(x)dx\\) Exemplo \\(F_X(t)=\\left\\{\\begin{array}{ll} 0, &amp; t&lt;0\\\\ \\dfrac{1}{15}+\\dfrac{2}{3}t, &amp; 0\\leq t &lt; 1\\\\ 1, &amp; t \\geq 1\\end{array}\\right.\\) IMAGEM FA F \\(\\dfrac{1}{15}=P(X=0)=\\) \\(\\underbrace{\\alpha}_{1/3} P_1(X=0) \\Rightarrow\\) \\(P_1(X=0)=\\dfrac{1}{5},\\) e portanto, \\(P_1(X=1)=\\dfrac{4}{5}\\) \\(E(X) =\\) \\(\\alpha\\int_\\Omega XdP_1+(1-\\alpha)\\int_\\Omega X dP_2=\\) \\(\\dfrac{1}{3}\\left\\{0*\\dfrac{1}{5}+1*\\dfrac{4}{5}\\right\\}+\\) \\(\\dfrac{2}{3}\\int_{-\\infty}^\\infty x f_X(x)dx=\\) \\(\\dfrac{1}{3}*\\dfrac{4}{5}+\\dfrac{2}{3}\\int_0^1 xdx=\\) \\(\\dfrac{4}{15}\\dfrac{5}{15}=\\dfrac{9}{15}.\\) Exemplo \\((\\Omega=[0,1]^2, \\mathcal{A}=\\mathcal{B}([0,1]^2),P=\\lambda)\\) \\(X(\\boldsymbol w)=\\left\\{\\begin{array}{lll} x_1, &amp; w_1 \\leq 1/2 &amp; (A_1)\\\\ x_2, &amp; w_2 &gt; 1/2 &amp; (A_2)\\end{array}\\right.\\) \\(Y(\\boldsymbol w)=\\left\\{\\begin{array}{lll} y_1, &amp; w_1 \\leq w_2 &amp; (B_1)\\\\ y_2, &amp; w_1 &gt; w_2&amp; (B_2)\\end{array}\\right.\\) IMAGEM DAS PARTIÇÕES \\(P_X(x_1)=\\) \\(P(X^{-1}(\\{x_1\\}))=\\) \\(P(\\boldsymbol w \\in A_1)=\\) \\(\\lambda(A_1)=1/2\\) \\(P_Y(y_1)=\\) \\(P(Y^{-1}(\\{y_1\\}))=\\) \\(P(\\boldsymbol w \\in B_1)=\\) \\(\\lambda(B_1)=1/2\\) \\(\\sigma_X =\\) \\(\\{\\phi,A_1,A_2,\\Omega\\} \\subseteq \\mathcal{B}([0,1]^2)\\) (é sub-\\(\\sigma\\)-álgebra) \\(\\sigma_Y =\\) \\(\\{\\phi,B_1,B_2,\\Omega\\} \\subseteq \\mathcal{B}([0,1]^2)\\) Seja \\(\\boldsymbol Z(\\boldsymbol w)=\\) \\((X(\\boldsymbol w), Y(\\boldsymbol w))=\\) \\((X,Y)(\\boldsymbol w),\\) \\(Z: \\Omega\\longrightarrow \\mathbb{R}^2\\) \\(Z(\\boldsymbol w)=\\) \\(\\sum_{i=1}^4 \\boldsymbol z_i ~\\mathbb{I}_{C_i}(\\boldsymbol w)\\) é função simples. \\(Z(\\boldsymbol w)=\\left\\{\\begin{array}{ll} (x_1,y_1)=z_1, &amp; \\boldsymbol w \\in A_1 \\cap B_1=C_1\\\\ (x_1,y_2)=z_2, &amp; \\boldsymbol w \\in A_1 \\cap B_2=C_2\\\\ (x_2,y_1)=z_3, &amp; \\boldsymbol w \\in A_2 \\cap B_1=C_3\\\\ (x_2,y_2)=z_4, &amp; \\boldsymbol w \\in A_2 \\cap B_2=C_4 \\end{array}\\right.\\) \\(P_Z((\\underbrace{x_1,y_2}_{z_2}))=\\) \\(P_Z((\\underbrace{x_2,y_1}_{z_3}))=\\) \\(\\dfrac{1}{8}=\\) \\(\\lambda(\\underbrace{A_1\\cap B_2}_{C_2})=\\) \\(\\lambda(\\underbrace{A_2\\cap B_1}_{C_3})\\) \\(P_Z((\\underbrace{x_1,y_1}_{z_1}))=\\) \\(P_Z((\\underbrace{x_2,y_2}_{z_4}))=\\) \\(\\dfrac{3}{8}=\\) \\(\\lambda(\\underbrace{A_1\\cap B_1}_{C_1})=\\) \\(\\lambda(\\underbrace{A_2\\cap B_2}_{C_4})\\) \\(P_Z(\\boldsymbol z_1| \\boldsymbol z_1 \\cap \\boldsymbol z_3)=\\) \\(\\dfrac{P_Z(\\boldsymbol z_1 \\cap (\\boldsymbol z_1 \\cup \\boldsymbol z_3))}{P_Z(\\boldsymbol z_1 \\cup \\boldsymbol z_3)}=\\) \\(\\dfrac{P_Z(\\boldsymbol z_1)}{P_Z(\\boldsymbol z_1)+P_Z(\\boldsymbol z_3)}=\\) \\(\\dfrac{3/8}{3/8 + 1/8}=\\) \\(\\dfrac{3}{4}=\\) \\(P_Z((X=x_1,Y=y_1)|\\overbrace{X \\in \\{x_1,x_2\\}}^{\\Omega}, Y=y_1)=\\) \\(P_{X|Y=y_1}(X=x_1|Y=y_1)=\\) \\(1-P_{X|y_1}(X=x_2|Y=y_1).\\) \\(P_{X|y_1}(X=x_1|Y=y_2)= \\dfrac{1/8}{4/8}=\\dfrac{1}{4}\\) Pela aula passada, podeos calcular \\(E[X|Y=y_1]\\) como \\(E[X|Y=y_1]=\\) \\(\\int x dP_{X|Y=y_1}(x)=\\) \\(\\sum_{i=1}^2x_i P_{X|Y=y_1}(x_i|y_1)\\) Por exemplo, se \\(x_1=y_1=1,\\) \\(x_2=y_2=2,\\) temos \\(E[X|Y=1]=\\) \\(1*\\dfrac{3}{4}+2*\\dfrac{1}{4}=\\dfrac{5}{4}\\) Analogamente, \\(E[X|Y=2]=\\) \\(1*\\dfrac{1}{4}+2*\\dfrac{3}{4}=\\dfrac{7}{4}\\) \\(E[X|Y](w)=\\left\\{\\begin{array}{ll} 5/4, &amp; w \\in B_1\\\\ 7/4, &amp; w \\in B_2 \\end{array}\\right.\\) \\(E[X|Y]=E[X|\\sigma_X].\\) A.4 Probabilidade Condicional Motivação \\(P(A|B)=\\) \\(\\dfrac{P(A\\cap B)}{P(B)}\\) é bem definido se \\(P(B)&gt;0.\\) Exemplo Seja \\(X: \\Omega \\longrightarrow \\mathbb{R}\\) v.a. e considere um experimento em dois estagios onde seleciona-se \\(X\\sim F_X\\) e, dado \\(X=x,\\) \\(0\\leq x\\leq 1,\\) uma moeda com probabilidade \\(x\\) é lançada \\(n\\) vezes. Nesse caso, é natural definir \\(Y|X=x\\sim Bin(n,x)\\) mesmo que \\(P(X=x)=0,\\) \\(\\forall x \\in [0,1].\\) A.4.1 Teorema da Medida Produto (para medidas de probabilidade) Seja \\((\\Omega_1, \\mathcal{A}_1,P_1)\\) um espaço de probabilidade e \\((\\Omega_2,\\mathcal{A}_2)\\) um espaço mensurável. Para cada \\(w_1 \\in \\Omega_1,\\) defina uma medida de probabilidade \\(\\mu(w_1,.)\\) em \\(\\mathcal{A}_2.\\) Assuma que, para cada \\(B \\in \\mathcal{A}_2,\\) \\(\\mu(.,B)\\) também é \\(\\mathcal{A}_1\\)-mensurável. Então, existe uma única medida de probabilidade \\(P\\) em \\(\\mathcal{A}=\\mathcal{A}_1\\times \\mathcal{A}_2\\) tal que \\(P(A\\times B)=\\) \\(\\int_A \\mu(w_1,B)dP_1(w_1),\\) \\(\\forall A\\in \\mathcal{A}_1,\\) \\(\\forall B\\in \\mathcal{A}_2.\\) Se \\(D(w_1)\\) denota uma secção de \\(D\\) em \\(w_1,\\) isto é, \\(D(w_1)=\\) \\(\\{w_2\\in \\Omega_2: (w_1,w_2)\\in D\\},\\) \\(D\\in \\mathcal{A}=\\mathcal{A}_1\\times\\mathcal{A}_2,\\) então \\(P(D)=\\) \\(\\int_{\\Omega_1} \\mu(w_1,D(w_1))dP_1(w_1).\\) Voltando à probabilidade condicional, Vamos interpretar (informalmneto por enquanto) \\(\\mu(x,B)\\) como \\(P(Y\\in B| X=x).\\) Ainda informalmente, vamos pensar no evento \\(\\{X=x\\}.\\) Intuitivamente, a probabilidade que \\(X\\in (x,x+dx]\\) é \\(dF(x).\\) Então, sabendo que \\(\\{X=x\\},\\) o evento \\(\\{(X,Y)\\in C\\}\\) ocorre se, e somente, \\(Y \\in C(x)=\\) \\(\\{y:(x,y)\\in C\\}\\) e a probabilidade desse evento é \\(\\mu(x,C(x)).\\) Pela regra da probabilidade total, \\(P(C)=\\) \\(\\int_{-\\infty}^{\\infty}\\mu(x,C(x))dF(x).\\) Se \\(C=\\{(x,y): x\\in A, y \\in B\\}=\\) \\(A\\times B,\\) \\(C(x)=B\\) se \\(x\\in A\\) e \\(C(x)=\\phi\\) se \\(x \\notin A,\\) então \\(P(C)=\\) \\(P(A\\times B)=\\) \\(\\int_A \\mu(x,B)dF(x)\\) Se \\(\\mu(x,B)\\) é mensurável em \\(x\\) para cada \\(B\\in \\mathcal{B}(\\mathbb{R}),\\) antão pelo Teorema anterior, \\(P\\) é único. Exemplo: Se \\(X \\sim Beta(a,b)\\) e \\(Y|X=x \\sim Ben(n,x)\\) \\((\\Omega_1=[0,1],\\mathcal{A}_1=\\mathcal{B}([0,1]),P_X),\\) onde \\(P_X(A)=\\) \\(\\int_A dF_X(x)=\\) \\(\\int_A f_X(x)dx=\\) \\(\\int_A \\dfrac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}x^{a-1}(1-x)^{b-1}dx\\) para \\(A \\in \\mathcal{A}_1.\\) Além disso, considere \\(\\Omega_2=\\{0,1,...,n\\},\\) \\(\\mathcal{A}_2=\\mathcal{P}(\\Omega_2)\\) e, para cada \\(x \\in [0,1],\\) \\(\\mu(x,B)=\\) \\(P(Y \\in B| X=x).\\) Então, pra \\(k=0,1,...,n;\\) \\(\\mu(x,B)=\\) \\(P(Y\\in B| X=x)=\\) \\(\\binom{n}{k}x^k(1-x)^{n-k}\\) (que é mensurável em \\(x\\)). Tomando \\(\\Omega=\\Omega_1 \\times \\Omega_2,\\) \\(\\mathcal{A}=\\mathcal{A}_1 \\times \\mathcal{A}_2,\\) \\(P\\) é a única medida de probabilidade determinada por \\(P_X (ou \\; F_X)\\) e \\(\\mu(x,.).\\) \\(P(C)=\\) \\(\\int_{\\Omega_1}\\mu(x,C(x))dP_X=\\) \\(\\int_0^1 \\mu(x,C(x))dF_X(x)=\\) \\(\\int_0^1 \\mu(x,C(x))f_X(x)dx,\\) \\(C \\in\\mathcal{A}.\\) Por exemplo, se \\(C=\\Omega_1 \\times \\{k\\},\\) temos \\(P(Y=k)=\\) \\(P(\\Omega_1 \\times \\{k\\})=\\) \\(\\int_0^1P(Y=k|X=x)dF(x)=\\) \\(\\int_0^1 \\binom{n}{k}x^k(1-x)^{n-k}\\) \\(\\dfrac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}x^{a-1}(1-x)^{b-1}dx=\\) \\(\\dfrac{\\binom{n}{k}\\dfrac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}}{\\dfrac{\\Gamma(a+b+n)}{\\Gamma(a+k)\\Gamma(b+n-k)}}\\) \\(\\int_0^1\\dfrac{\\Gamma(a+b+n)}{\\Gamma(a+k)\\Gamma(b+n-k)}\\) \\(x^{a+k-1}(1-x)^{b+n-k-1}dx=\\) \\(\\binom{n}{k}\\dfrac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}\\dfrac{\\Gamma(a+k)\\Gamma(b+n-k)}{\\Gamma(a+b+n)}.\\) \\((Y \\sim Beta Bin (n,a,b))\\) Teorema \\(X: (\\Omega,\\mathcal{A}) \\longrightarrow (\\mathfrak{X},\\mathcal{F})\\) em \\((\\Omega,\\mathcal{A},P)\\) e \\(B \\in \\mathcal{A}.\\) Então \\(\\exists g:\\mathfrak{X} \\longrightarrow \\mathbb{R}\\) tal que, para cada \\(A \\in \\mathcal{F},\\) \\(P(\\{x\\in A\\}\\cap B)=\\) \\(\\int_Ag(x)dP_X(x).\\) Além disso, \\(g\\) é única \\(P_X\\)-q.c. (\\(g(x)=P(B|X=x)\\) é única \\(P_X\\)-q.c. para um dado \\(B\\)) Demo: segue diretamente do Teorema de Radom-Nikodim (se \\(\\mu(A)=\\) \\(P(\\{x\\in A\\}\\cap B)\\) então \\(\\lambda\\) é medida finita em \\(\\mathcal{F}\\) com \\(\\lambda &lt;&lt; P_X\\)) Exemplo1: \\(\\mathfrak{X}\\{x_1,x_2,...\\}\\) com \\(p_i=P(\\{X=x_i\\})&gt;0.\\) Defina \\(g(x_i)=\\) \\(P(B|X=x_i)=\\) \\(\\dfrac{P(B\\cap \\{X=x_i\\})}{P(\\{X=x_i\\})},\\) \\(i=1,2,...\\) (\\(g\\) é uma “proposta” para \\(P(B|\\{X=x_i\\})\\)) Se \\(A \\in \\mathcal{F}=\\) \\(\\mathcal{P}(\\mathfrak{X}),\\) \\(\\int_A g(x)dP_X(x)=\\) \\(\\int_{\\mathfrak{X}}g(x)~\\mathbb{I}_A(x)dP_X(x)=\\) \\(\\sum_{i=1}^\\infty g(x_i)~\\mathbb{I}_A(x_i)P_X(\\{x_i\\})=\\) \\(\\sum_{x_i \\in A}g(x_i)P(\\{X=x_i\\})=\\) \\(\\sum_{x_i \\in A}P(B \\cap \\{X=x_i\\})=\\) \\(P(\\{X\\in A\\}\\cap B).\\) Exemplo 2 \\(\\Omega=\\mathbb{R}^2,\\) \\(\\mathcal{A}= \\mathcal{B}(\\mathbb{R}^2),\\) \\(X(x,y)=x,\\) \\(Y(x,y)=y\\) \\((X,Y)\\) v.a. com densidade \\(f\\) (\\(P(A)=\\int \\int_A f(x,y)dxdy,\\) \\(A \\in \\mathcal{A}\\)). Nesse caso \\(P(\\{X=x\\})=0, \\forall x.\\) Seja \\(f_1(x)=\\int_{-\\infty}^{\\infty} f(x,y)dy\\) a densidade de \\(X\\). Defina \\(f(y|x)=\\dfrac{f(x,y)}{f_1(x)}\\) como a densidade condicional de \\(Y\\) dado \\(X=x.\\) Note que \\(f(y|x)\\) só está definido quando \\(f_1(x) \\neq 0.\\) Contudo, se \\(S=\\{(x,y): f_1(x)=0\\}\\) então \\(P(\\{(X,Y)\\in S\\})=0\\) \\(P(\\{(X,Y)\\in S\\})=\\) \\(\\int \\int_S f(x,y)dxdy=\\) \\(\\int_{\\{x:f_1(x)=0\\}}\\left[\\int_{-\\infty}^\\infty f(x,y)dy\\right]dx=\\) \\(\\int_{\\{x:f_1(x)=0\\}} f_1(x)dx=0.\\) de modo que podemos ignorar o conjunto onde \\(f(y|x)\\) não está definida. Se \\(X=x,\\) \\(\\forall B \\in \\mathcal{A},\\) \\(B\\) ocorre se e soente se \\(Y \\in B(x)=\\) \\(\\{y:(x,y) \\in B\\}.\\) Assim, vamos propor \\(g(x)=\\) \\(P(\\{Y \\in B(x)|X=x\\})=\\) \\(\\int_{B(x)}f(y|x)dy=\\) \\(\\int_{-\\infty}^\\infty \\mathbb{I}_B(x,y)f(y|x)dy,\\) Então, se \\(A \\in \\mathcal{B}(\\mathbb{R}),\\) \\(P(\\{X \\in A\\}\\cap B)=\\) \\(\\underset{\\underset{(x,y)\\in B}{x\\in A}}{\\int \\int}f(x,y)dxdy=\\) \\(\\int_{-\\infty}^{\\infty}\\left[\\int_{-\\infty}^{\\infty}\\mathbb{I}_B(x,y)f(y|x)dy\\right]~\\mathbb{I}_A(x)f_1(x)dx=\\) \\(\\int_Af_1(x)dx\\underbrace{\\int_Bf(y|x)dy}_{g(x)}dx=\\) \\(\\int_Ag(x)f_1(x)dx=\\) \\(\\int_Ag(x)dP_X(x)\\) \\(\\Rightarrow g(x)=P(B|X=x)\\) \\(P(X\\in A,Y \\in B)=\\) \\(\\int_A \\int_Bf(x,y)dxdy=\\) \\(\\int_A \\int_Bf(y|x)f_1(x)dydx=\\) \\(\\int_B \\int_Af(x|y)f_2(y)dxdy\\) Referências "],
["referências.html", "Referências", " Referências "]
]
